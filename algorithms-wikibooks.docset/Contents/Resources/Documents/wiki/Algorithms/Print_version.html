<!DOCTYPE html>
<html lang="en" dir="ltr" class="client-nojs">
<head>
<meta charset="UTF-8" /><title>Algorithms/Print version - Wikibooks, open books for an open world</title>
<meta name="generator" content="MediaWiki 1.23wmf7" />
<link rel="alternate" type="application/x-wiki" title="Edit" href="/w/index.php?title=Algorithms/Print_version&amp;action=edit" />
<link rel="edit" title="Edit" href="/w/index.php?title=Algorithms/Print_version&amp;action=edit" />
<link rel="shortcut icon" href="//bits.wikimedia.org/favicon/wikibooks.ico" />
<link rel="search" type="application/opensearchdescription+xml" href="/w/opensearch_desc.php" title="Wikibooks (en)" />
<link rel="EditURI" type="application/rsd+xml" href="//en.wikibooks.org/w/api.php?action=rsd" />
<link rel="copyright" href="//creativecommons.org/licenses/by-sa/3.0/" />
<link rel="alternate" type="application/atom+xml" title="Wikibooks Atom feed" href="/w/index.php?title=Special:RecentChanges&amp;feed=atom" />
<link rel="canonical" href="http://en.wikibooks.org/wiki/Algorithms/Print_version" />
<link rel="stylesheet" href="//bits.wikimedia.org/en.wikibooks.org/load.php?debug=false&amp;lang=en&amp;modules=ext.flaggedRevs.basic%7Cext.gadget.extlinks%7Cext.geshi.local%7Cext.rtlcite%2Cwikihiero%7Cext.uls.nojs%7Cmediawiki.legacy.commonPrint%2Cshared%7Cmw.PopUpMediaTransform%7Cskins.vector&amp;only=styles&amp;skin=vector&amp;*" />
<meta name="ResourceLoaderDynamicStyles" content="" />
<link rel="stylesheet" href="//bits.wikimedia.org/en.wikibooks.org/load.php?debug=false&amp;lang=en&amp;modules=site&amp;only=styles&amp;skin=vector&amp;*" />
<style>a:lang(ar),a:lang(kk-arab),a:lang(mzn),a:lang(ps),a:lang(ur){text-decoration:none}
/* cache key: enwikibooks:resourceloader:filter:minify-css:7:4969bf752d40e7c60e4c1bc8e4153549 */</style>

<script src="//bits.wikimedia.org/en.wikibooks.org/load.php?debug=false&amp;lang=en&amp;modules=startup&amp;only=scripts&amp;skin=vector&amp;*"></script>
<script>if(window.mw){
mw.config.set({"wgCanonicalNamespace":"","wgCanonicalSpecialPageName":false,"wgNamespaceNumber":0,"wgPageName":"Algorithms/Print_version","wgTitle":"Algorithms/Print version","wgCurRevisionId":2564849,"wgRevisionId":2564849,"wgArticleId":20033,"wgIsArticle":true,"wgIsRedirect":false,"wgAction":"view","wgUserName":null,"wgUserGroups":["*"],"wgCategories":["Algorithms","Ada Programming"],"wgBreakFrames":false,"wgPageContentLanguage":"en","wgPageContentModel":"wikitext","wgSeparatorTransformTable":["",""],"wgDigitTransformTable":["",""],"wgDefaultDateFormat":"dmy","wgMonthNames":["","January","February","March","April","May","June","July","August","September","October","November","December"],"wgMonthNamesShort":["","Jan","Feb","Mar","Apr","May","Jun","Jul","Aug","Sep","Oct","Nov","Dec"],"wgRelevantPageName":"Algorithms/Print_version","wgIsProbablyEditable":true,"wgRestrictionEdit":[],"wgRestrictionMove":[],"wgWikiEditorEnabledModules":{"toolbar":true,"dialogs":true,"hidesig":true,"templateEditor":false,"templates":false,"preview":false,"previewDialog":false,"publish":false,"toc":false},"wgBetaFeaturesFeatures":[],"wgULSAcceptLanguageList":[],"wgFlaggedRevsParams":{"tags":{"value":{"levels":3,"quality":2,"pristine":3}}},"wgStableRevisionId":2502040,"wgCategoryTreePageCategoryOptions":"{\"mode\":0,\"hideprefix\":20,\"showcount\":true,\"namespaces\":false}","Geo":{"city":"","country":""},"wgNoticeProject":"wikibooks"});
}</script><script>if(window.mw){
mw.loader.implement("user.options",function(){mw.user.options.set({"ccmeonemails":0,"cols":80,"date":"default","diffonly":0,"disablemail":0,"editfont":"default","editondblclick":0,"editsection":1,"editsectiononrightclick":0,"enotifminoredits":0,"enotifrevealaddr":0,"enotifusertalkpages":1,"enotifwatchlistpages":0,"extendwatchlist":0,"fancysig":0,"forceeditsummary":0,"gender":"unknown","hideminor":0,"hidepatrolled":0,"imagesize":2,"justify":0,"math":0,"minordefault":0,"newpageshidepatrolled":0,"noconvertlink":0,"norollbackdiff":0,"numberheadings":0,"previewonfirst":0,"previewontop":1,"rcdays":7,"rclimit":50,"rememberpassword":0,"rows":25,"searchlimit":20,"showhiddencats":false,"shownumberswatching":1,"showtoc":1,"showtoolbar":1,"skin":"vector","stubthreshold":0,"thumbsize":4,"underline":2,"uselivepreview":0,"usenewrc":0,"vector-simplesearch":1,"watchcreations":1,"watchdefault":0,"watchdeletion":0,"watchlistdays":3,"watchlisthideanons":0,"watchlisthidebots":0,"watchlisthideliu":0,
"watchlisthideminor":0,"watchlisthideown":0,"watchlisthidepatrolled":0,"watchmoves":0,"wllimit":250,"useeditwarning":1,"prefershttps":1,"flaggedrevssimpleui":0,"flaggedrevsstable":0,"flaggedrevseditdiffs":true,"flaggedrevsviewdiffs":false,"usebetatoolbar":1,"usebetatoolbar-cgd":1,"echo-notify-show-link":true,"echo-show-alert":true,"echo-email-frequency":0,"echo-email-format":"html","echo-subscriptions-email-system":true,"echo-subscriptions-web-system":true,"echo-subscriptions-email-other":false,"echo-subscriptions-web-other":true,"echo-subscriptions-email-edit-user-talk":false,"echo-subscriptions-web-edit-user-talk":true,"echo-subscriptions-email-reverted":false,"echo-subscriptions-web-reverted":true,"echo-subscriptions-email-article-linked":false,"echo-subscriptions-web-article-linked":false,"echo-subscriptions-email-mention":false,"echo-subscriptions-web-mention":true,"echo-subscriptions-web-edit-thank":true,"echo-subscriptions-email-edit-thank":false,"uls-preferences":"","language":
"en","variant-gan":"gan","variant-iu":"iu","variant-kk":"kk","variant-ku":"ku","variant-shi":"shi","variant-sr":"sr","variant-tg":"tg","variant-uz":"uz","variant-zh":"zh","searchNs0":true,"searchNs1":false,"searchNs2":false,"searchNs3":false,"searchNs4":true,"searchNs5":false,"searchNs6":false,"searchNs7":false,"searchNs8":false,"searchNs9":false,"searchNs10":false,"searchNs11":false,"searchNs12":false,"searchNs13":false,"searchNs14":false,"searchNs15":false,"searchNs102":false,"searchNs103":false,"searchNs108":false,"searchNs109":false,"searchNs110":false,"searchNs111":false,"searchNs112":true,"searchNs113":false,"searchNs828":false,"searchNs829":false,"gadget-extlinks":1,"gadget-commons-file":1,"gadget-toolboxcompat":1,"variant":"en"});},{},{});mw.loader.implement("user.tokens",function(){mw.user.tokens.set({"editToken":"+\\","patrolToken":false,"watchToken":false});},{},{});
/* cache key: enwikibooks:resourceloader:filter:minify-js:7:654df7e16c6905f951b4f215c0323024 */
}</script>
<script>if(window.mw){
mw.loader.load(["mediawiki.page.startup","mediawiki.legacy.wikibits","mediawiki.legacy.ajax","ext.centralauth.centralautologin","ext.uls.init","ext.uls.interface","ext.centralNotice.bannerController","skins.vector.js"]);
}</script>
<style type="text/css">/*<![CDATA[*/
.source-python {line-height: normal;}
.source-python li, .source-python pre {
	line-height: normal; border: 0px none white;
}
/**
 * GeSHi Dynamically Generated Stylesheet
 * --------------------------------------
 * Dynamically generated stylesheet for python
 * CSS class: source-python, CSS id: 
 * GeSHi (C) 2004 - 2007 Nigel McNie, 2007 - 2008 Benny Baumann
 * (http://qbnz.com/highlighter/ and http://geshi.org/)
 * --------------------------------------
 */
.python.source-python .de1, .python.source-python .de2 {font: normal normal 1em/1.2em monospace; margin:0; padding:0; background:none; vertical-align:top;font-family: monospace, monospace;}
.python.source-python  {font-family:monospace;}
.python.source-python .imp {font-weight: bold; color: red;}
.python.source-python li, .python.source-python .li1 {font-weight: normal; vertical-align:top;}
.python.source-python .ln {width:1px;text-align:right;margin:0;padding:0 2px;vertical-align:top;}
.python.source-python .li2 {font-weight: bold; vertical-align:top;}
.python.source-python .kw1 {color: #ff7700;font-weight:bold;}
.python.source-python .kw2 {color: #008000;}
.python.source-python .kw3 {color: #dc143c;}
.python.source-python .kw4 {color: #0000cd;}
.python.source-python .co1 {color: #808080; font-style: italic;}
.python.source-python .coMULTI {color: #808080; font-style: italic;}
.python.source-python .es0 {color: #000099; font-weight: bold;}
.python.source-python .br0 {color: black;}
.python.source-python .sy0 {color: #66cc66;}
.python.source-python .st0 {color: #483d8b;}
.python.source-python .nu0 {color: #ff4500;}
.python.source-python .me1 {color: black;}
.python.source-python .ln-xtra, .python.source-python li.ln-xtra, .python.source-python div.ln-xtra {background-color: #ffc;}
.python.source-python span.xtra { display:block; }

/*]]>*/
</style><script src="//bits.wikimedia.org/geoiplookup"></script><link rel="dns-prefetch" href="//meta.wikimedia.org" /><!--[if lt IE 7]><style type="text/css">body{behavior:url("/w/static-1.23wmf7/skins/vector/csshover.min.htc")}</style><![endif]--></head>
<body class="mediawiki ltr sitedir-ltr ns-0 ns-subject page-Algorithms_Print_version skin-vector action-view vector-animateLayout">
		<div id="mw-page-base" class="noprint"></div>
		<div id="mw-head-base" class="noprint"></div>
		<div id="content" class="mw-body" role="main">
			<a id="top"></a>
			<div id="mw-js-message" style="display:none;"></div>
						<div id="siteNotice"><!-- CentralNotice --></div>
						<h1 id="firstHeading" class="firstHeading" lang="en"><span dir="auto">Algorithms/Print version</span></h1>
			<div id="bodyContent">
								<div id="siteSub">From Wikibooks, open books for an open world</div>
								<div id="contentSub"><span class="subpages">&lt; <a href="/wiki/Algorithms" title="Algorithms">Algorithms</a></span><div id="mw-fr-revisiontag" class="flaggedrevs_basic plainlinks noprint"><img class="flaggedrevs-icon" src="//bits.wikimedia.org/static-1.23wmf7/extensions/FlaggedRevs/frontend/modules/img/1.png" alt="Unreviewed changes are displayed on this page" title="Unreviewed changes are displayed on this page" />The <a class="external text" href="//en.wikibooks.org/w/index.php?title=Algorithms/Print_version&amp;stable=1">latest reviewed version</a> was <a class="external text" href="//en.wikibooks.org/w/index.php?title=Special:Log&amp;type=review&amp;page=Algorithms/Print_version">checked</a> on <i>15 March 2013</i>. There is <a class="external text" href="//en.wikibooks.org/w/index.php?title=Algorithms/Print_version&amp;oldid=2502040&amp;diff=cur&amp;diffonly=0">1 pending change</a> awaiting review.</div>
</div>
												<div id="jump-to-nav" class="mw-jump">
					Jump to:					<a href="#mw-navigation">navigation</a>, 					<a href="#p-search">search</a>
				</div>
				<div id="mw-content-text" lang="en" dir="ltr" class="mw-content-ltr"><table class="metadata plainlinks ambox ambox-notice" style="">
<tr>
<td class="mbox-image">
<div style="width: 52px;"><a href="/wiki/File:Printer.svg" class="image"><img alt="Printer.svg" src="//upload.wikimedia.org/wikipedia/commons/thumb/2/23/Printer.svg/40px-Printer.svg.png" width="40" height="40" srcset="//upload.wikimedia.org/wikipedia/commons/thumb/2/23/Printer.svg/60px-Printer.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/2/23/Printer.svg/80px-Printer.svg.png 2x" /></a></div>
</td>
<td class="mbox-text" style=""><b>This is the <a href="/wiki/Help:Print_versions" title="Help:Print versions">print version</a> of <a href="/wiki/Algorithms" title="Algorithms">Algorithms</a></b><br />
You won't see this message or any elements not part of the book's content when you print or <a class="external text" href="//en.wikibooks.org/w/index.php?title=Algorithms/Print_version&amp;action=purge&amp;printable=yes">preview</a> this page.</td>
</tr>
</table>
<center>[Image:AlgorithmsTitleImage.png]]</center>
<p>Permission is granted to copy, distribute and/or modify this document under the terms of the GNU Free Documentation License, Version 1.2 or any later version published by the Free Software Foundation; with no Invariant Sections, no Front-Cover Texts, and no Back-Cover Texts. A copy of the license is included in the section entitled "GNU Free Documentation License".</p>
<h1><span class="mw-headline" id="Contents">Contents</span></h1>
<p><span class="noprint">If you have saved this file to your computer, click on a link in the contents to go to that section.</span></p>
<ul>
<li><a href="#Introduction">Chapter 1: Introduction</a></li>
<li><a href="#Mathematical_Background">Chapter 2: Mathematical Background</a></li>
<li><a href="#Divide_and_Conquer">Chapter 3: Divide and Conquer</a></li>
<li><a href="#Randomization">Chapter 4: Randomization</a></li>
<li><a href="#Backtracking">Chapter 5: Backtracking</a></li>
<li><a href="#Dynamic_Programming">Chapter 6: Dynamic Programming</a></li>
<li><a href="#Greedy_Algorithms">Chapter 7: Greedy Algorithms</a></li>
<li><a href="#Hill_Climbing">Chapter 8: Hill Climbing</a></li>
<li><a href="#Ada_Implementation">Appendix A: Ada Implementation</a></li>
<li><a href="#GNU_Free_Documentation_License">GNU Free Documentation License</a></li>
</ul>
<h1><span class="mw-headline" id="Introduction">Introduction</span></h1>
<p>This book covers techniques for the design and analysis of algorithms. The algorithmic techniques covered include: divide and conquer, backtracking, dynamic programming, greedy algorithms, and hill-climbing.</p>
<p>Any solvable problem generally has at least one algorithm of each of the following types:</p>
<ol>
<li>the obvious way;</li>
<li>the methodical way;</li>
<li>the clever way; and</li>
<li>the miraculous way.</li>
</ol>
<p>On the first and most basic level, the "obvious" solution might try to exhaustively search for the answer. Intuitively, the obvious solution is the one that comes easily if you're familiar with a programming language and the basic problem solving techniques.</p>
<p>The second level is the methodical level and is the heart of this book: after understanding the material presented here you should be able to methodically turn most obvious algorithms into better performing algorithms.</p>
<p>The third level, the clever level, requires more understanding of the elements involved in the problem and their properties or even a reformulation of the algorithm (e.g., numerical algorithms exploit mathematical properties that are not obvious). A clever algorithm may be hard to understand by being non-obvious that it is correct, or it may be hard to understand that it actually runs faster than what it would seem to require.</p>
<p>The fourth and final level of an algorithmic solution is the miraculous level: this is reserved for the rare cases where a breakthrough results in a highly non-intuitive solution.</p>
<p>Naturally, all of these four levels are relative, and some clever algorithms are covered in this book as well, in addition to the methodical techniques. Let's begin.</p>
<h2><span class="mw-headline" id="Prerequisites">Prerequisites</span></h2>
<p>To understand the material presented in this book you need to know a programming language well enough to translate the pseudocode in this book into a working solution. You also need to know the basics about the following data structures: arrays, stacks, queues, linked-lists, trees, heaps (also called priority queues), disjoint sets, and graphs.</p>
<p>Additionally, you should know some basic algorithms like binary search, a sorting algorithm (merge sort, heap sort, insertion sort, or others), and breadth-first or depth-first search.</p>
<p>If you are unfamiliar with any of these prerequisites you should review the material in the <i><a href="/wiki/Computer_Science:Data_Structures" title="Computer Science:Data Structures" class="mw-redirect">Data Structures</a></i> book first.</p>
<h2><span class="mw-headline" id="When_is_Efficiency_Important.3F">When is Efficiency Important?</span></h2>
<p>Not every problem requires the most efficient solution available. For our purposes, the term efficient is concerned with the time and/or space needed to perform the task. When either time or space is abundant and cheap, it may not be worth it to pay a programmer to spend a day or so working to make a program faster.</p>
<p>However, here are some cases where efficiency matters:</p>
<ul>
<li>When resources are limited, a change in algorithms could create great savings and allow limited machines (like cell phones, embedded systems, and sensor networks) to be stretched to the frontier of possibility.</li>
</ul>
<ul>
<li>When the data is large a more efficient solution can mean the difference between a task finishing in two days versus two weeks. Examples include physics, genetics, web searches, massive online stores, and network traffic analysis.</li>
</ul>
<ul>
<li>Real time applications: the term "real time applications" actually refers to computations that give time guarantees, versus meaning "fast." However, the quality can be increased further by choosing the appropriate algorithm.</li>
</ul>
<ul>
<li>Computationally expensive jobs, like fluid dynamics, partial differential equations, VLSI design, and cryptanalysis can sometimes only be considered when the solution is found efficiently enough.</li>
</ul>
<ul>
<li>When a subroutine is common and frequently used, time spent on a more efficient implementation can result in benefits for every application that uses the subroutine. Examples include sorting, searching, pseudorandom number generation, kernel operations (not to be confused with the operating system kernel), database queries, and graphics.</li>
</ul>
<p>In short, it's important to save time when you do not have any time to spare.</p>
<p>When is efficiency unimportant? Examples of these cases include prototypes that are used only a few times, cases where the input is small, when simplicity and ease of maintenance is more important, when the area concerned is not the bottle neck, or when there's another process or area in the code that would benefit far more from efficient design and attention to the algorithm(s).</p>
<h2><span class="mw-headline" id="Inventing_an_Algorithm">Inventing an Algorithm</span></h2>
<p>Because we assume you have some knowledge of a programming language, let's start with how we translate an idea into an algorithm. Suppose you want to write a function that will take a string as input and output the string in lowercase:</p>
<pre>
// <i>tolower -- translates all alphabetic, uppercase characters in str to lowercase</i>
function <b>tolower</b>(string <i>str</i>): string
</pre>
<p>What first comes to your mind when you think about solving this problem? Perhaps these two considerations crossed your mind:</p>
<ol>
<li>Every character in <i>str</i> needs to be looked at</li>
<li>A routine for converting a single character to lower case is required</li>
</ol>
<p>The first point is "obvious" because a character that needs to be converted might appear anywhere in the string. The second point follows from the first because, once we consider each character, we need to do something with it. There are many ways of writing the <b>tolower</b> function for characters:</p>
<pre>
function <b>tolower</b>(character <i>c</i>): character
</pre>
<p>There are several ways to implement this function, including:</p>
<ul>
<li>look <i>c</i> up in a table -- a character indexed array of characters that holds the lowercase version of each character.</li>
</ul>
<ul>
<li>check if <i>c</i> is in the range 'A' ≤ <i>c</i> ≤ 'Z', and then add a numerical offset to it.</li>
</ul>
<p>These techniques depend upon the character encoding. (As an issue of separation of concerns, perhaps the table solution is stronger because it's clearer you only need to change one part of the code.)</p>
<p>However such a subroutine is implemented, once we have it, the implementation of our original problem comes immediately:</p>
<pre>
// <i>tolower -- translates all alphabetic, uppercase characters in str to lowercase</i>
function <b>tolower</b>(string <i>str</i>): string
  let <i>result</i> := ""
  for-each <i>c</i> in <i>str</i>:
    <i>result</i>.append(<b>tolower</b>(<i>c</i>))
  repeat
  return <i>result</i>
end
</pre>
<div id="toc"><small>This code sample is also available in <a href="/wiki/Ada_Programming/Algorithms#To_Lower" title="Ada Programming/Algorithms">Ada</a>.</small></div>
<p>The loop is the result of our ability to translate "every character needs to be looked at" into our native programming language. It became obvious that the <b>tolower</b> subroutine call should be in the loop's body. The final step required to bring the high-level task into an implementation was deciding how to build the resulting string. Here, we chose to start with the empty string and append characters to the end of it.</p>
<p>Now suppose you want to write a function for comparing two strings that tests if they are equal, ignoring case:</p>
<pre>
// <i>equal-ignore-case -- returns true if s and t are equal, ignoring case</i>
function <b>equal-ignore-case</b>(string <i>s</i>, string <i>t</i>): boolean
</pre>
<p>These ideas might come to mind:</p>
<ol>
<li>Every character in strings <i>s</i> and <i>t</i> will have to be looked at</li>
<li>A single loop iterating through both might accomplish this</li>
<li>But such a loop should be careful that the strings are of equal length first</li>
<li>If the strings aren't the same length, then they cannot be equal because the consideration of ignoring case doesn't affect how long the string is</li>
<li>A tolower subroutine for characters can be used again, and only the lowercase versions will be compared</li>
</ol>
<p>These ideas come from familiarity both with strings and with the looping and conditional constructs in your language. The function you thought of may have looked something like this:</p>
<pre>
// <i>equal-ignore-case -- returns true if s or t are equal, ignoring case</i>
function <b>equal-ignore-case</b>(string <i>s</i>[1..<i>n</i>], string <i>t</i>[1..<i>m</i>]): boolean
  if <i>n</i> != <i>m</i>:
    return false               <i>\if they aren't the same length, they aren't equal\</i>
  fi
  
  for <i>i</i> := 1 to <i>n</i>:
    if <b>tolower</b>(<i>s</i>[<i>i</i>]) != <b>tolower</b>(<i>t</i>[<i>i</i>]):
      return false
    fi
  repeat
  return true
end
</pre>
<div id="toc"><small>This code sample is also available in <a href="/wiki/Ada_Programming/Algorithms#Equal_Ignore_Case" title="Ada Programming/Algorithms">Ada</a>.</small></div>
<p>Or, if you thought of the problem in terms of functional decomposition instead of iterations, you might have thought of a function more like this:</p>
<pre>
// <i>equal-ignore-case -- returns true if s or t are equal, ignoring case</i>
function <b>equal-ignore-case</b>(string <i>s</i>, string <i>t</i>): boolean
  return <b>tolower</b>(<i>s</i>).equals(<b>tolower</b>(<i>t</i>))
end
</pre>
<p>Alternatively, you may feel neither of these solutions is efficient enough, and you would prefer an algorithm that only ever made one pass of <i>s</i> or <i>t</i>. The above two implementations each require two-passes: the first version computes the lengths and then compares each character, while the second version computes the lowercase versions of the string and then compares the results to each other. (Note that for a pair of strings, it is also possible to have the length precomputed to avoid the second pass, but that can have its own drawbacks at times.) You could imagine how similar routines can be written to test string equality that not only ignore case, but also ignore accents.</p>
<p>Already you might be getting the spirit of the pseudocode in this book. The pseudocode language is not meant to be a real programming language: it abstracts away details that you would have to contend with in any language. For example, the language doesn't assume generic types or dynamic versus static types: the idea is that it should be clear what is intended and it should not be too hard to convert it to your native language. (However, in doing so, you might have to make some design decisions that limit the implementation to one particular type or form of data.)</p>
<p>There was nothing special about the techniques we used so far to solve these simple string problems: such techniques are perhaps already in your toolbox, and you may have found better or more elegant ways of expressing the solutions in your programming language of choice. In this book, we explore general algorithmic techniques to expand your toolbox even further. Taking a naive algorithm and making it more efficient might not come so immediately, but after understanding the material in this book you should be able to methodically apply different solutions, and, most importantly, you will be able to ask yourself more questions about your programs. Asking questions can be just as important as answering questions, because asking the right question can help you reformulate the problem and think outside of the box.</p>
<h2><span class="mw-headline" id="Understanding_an_Algorithm">Understanding an Algorithm</span></h2>
<p>Computer programmers need an excellent ability to reason with multiple-layered abstractions. For example, consider the following code:</p>
<pre>
function <b>foo</b>(integer <i>a</i>):
  if (<i>a</i> / 2) * 2 == <i>a</i>:
     print "The value " <i>a</i> " is even."
  fi
end
</pre>
<p>To understand this example, you need to know that integer division uses truncation and therefore when the if-condition is true then the least-significant bit in <i>a</i> is zero (which means that <i>a</i> must be even). Additionally, the code uses a string printing API and is itself the definition of a function to be used by different modules. Depending on the programming task, you may think on the layer of hardware, on down to the level of processor branch-prediction or the cache.</p>
<p>Often an understanding of binary is crucial, but many modern languages have abstractions far enough away "from the hardware" that these lower-levels are not necessary. Somewhere the abstraction stops: most programmers don't need to think about logic gates, nor is the physics of electronics necessary. Nevertheless, an essential part of programming is multiple-layer thinking.</p>
<p>But stepping away from computer programs toward algorithms requires another layer: mathematics. A program may exploit properties of binary representations. An algorithm can exploit properties of set theory or other mathematical constructs. Just as binary itself is not explicit in a program, the mathematical properties used in an algorithm are not explicit.</p>
<p>Typically, when an algorithm is introduced, a discussion (separate from the code) is needed to explain the mathematics used by the algorithm. For example, to really understand a greedy algorithm (such as Dijkstra's algorithm) you should understand the mathematical properties that show how the greedy strategy is valid for all cases. In a way, you can think of the mathematics as its own kind of subroutine that the algorithm invokes. But this "subroutine" is not present in the code because there's nothing to call. As you read this book try to think about mathematics as an implicit subroutine.</p>
<h2><span class="mw-headline" id="Overview_of_the_Techniques">Overview of the Techniques</span></h2>
<p>The techniques this book covers are highlighted in the following overview.</p>
<ul>
<li><b>Divide and Conquer</b>: Many problems, particularly when the input is given in an array, can be solved by cutting the problem into smaller pieces (<i>divide</i>), solving the smaller parts recursively (<i>conquer</i>), and then combining the solutions into a single result. Examples include the merge sort and quicksort algorithms.</li>
</ul>
<ul>
<li><b>Randomization</b>: Increasingly, randomization techniques are important for many applications. This chapter presents some classical algorithms that make use of random numbers.</li>
</ul>
<ul>
<li><b>Backtracking</b>: Almost any problem can be cast in some form as a backtracking algorithm. In backtracking, you consider all possible choices to solve a problem and recursively solve subproblems under the assumption that the choice is taken. The set of recursive calls generates a tree in which each set of choices in the tree is considered consecutively. Consequently, if a solution exists, it will eventually be found.
<p>Backtracking is generally an inefficient, brute-force technique, but there are optimizations that can be performed to reduce both the depth of the tree and the number of branches. The technique is called backtracking because after one leaf of the tree is visited, the algorithm will go back up the call stack (undoing choices that didn't lead to success), and then proceed down some other branch. To be solved with backtracking techniques, a problem needs to have some form of "self-similarity," that is, smaller instances of the problem (after a choice has been made) must resemble the original problem. Usually, problems can be generalized to become self-similar.</p>
</li>
</ul>
<ul>
<li><b>Dynamic Programming</b>: Dynamic programming is an optimization technique for backtracking algorithms. When subproblems need to be solved repeatedly (i.e., when there are many duplicate branches in the backtracking algorithm) time can be saved by solving all of the subproblems first (bottom-up, from smallest to largest) and storing the solution to each subproblem in a table. Thus, each subproblem is only visited and solved once instead of repeatedly. The "programming" in this technique's name comes from programming in the sense of writing things down in a table; for example, television programming is making a table of what shows will be broadcast when.</li>
</ul>
<ul>
<li><b>Greedy Algorithms</b>: A greedy algorithm can be useful when enough information is known about possible choices that "the best" choice can be determined without considering all possible choices. Typically, greedy algorithms are not challenging to write, but they are difficult to prove correct.</li>
</ul>
<ul>
<li><b>Hill Climbing</b>: The final technique we explore is hill climbing. The basic idea is to start with a poor solution to a problem, and then repeatedly apply optimizations to that solution until it becomes optimal or meets some other requirement. An important case of hill climbing is network flow. Despite the name, network flow is useful for many problems that describe relationships, so it's not just for computer networks. Many matching problems can be solved using network flow.</li>
</ul>
<p><br /></p>
<h2><span class="mw-headline" id="Algorithm_and_code_example">Algorithm and code example</span></h2>
<h3><span class="mw-headline" id="Level_1_.28easiest.29">Level 1 (easiest)</span></h3>
<p>1. <i><a href="/wiki/Algorithms/Find_maximum" title="Algorithms/Find maximum">Find maximum</a></i> With algorithm and several different programming languages</p>
<p>2. <i><a href="/w/index.php?title=Algorithms/Find_minimum&amp;action=edit&amp;redlink=1" class="new" title="Algorithms/Find minimum (does not exist)">Find minimum</a></i> With algorithm and several different programming languages</p>
<p>3. <i><a href="/w/index.php?title=Algorithms/Find_average&amp;action=edit&amp;redlink=1" class="new" title="Algorithms/Find average (does not exist)">Find average</a></i> With algorithm and several different programming languages</p>
<p>4. <i><a href="/w/index.php?title=Algorithms/Find_mode&amp;action=edit&amp;redlink=1" class="new" title="Algorithms/Find mode (does not exist)">Find mode</a></i> With algorithm and several different programming languages</p>
<p>5. <i><a href="/w/index.php?title=Algorithms/Find_total&amp;action=edit&amp;redlink=1" class="new" title="Algorithms/Find total (does not exist)">Find total</a></i> With algorithm and several different programming languages</p>
<p>6. <i><a href="/w/index.php?title=Algorithms/Counting&amp;action=edit&amp;redlink=1" class="new" title="Algorithms/Counting (does not exist)">Counting</a></i> With algorithm and several different programming languages</p>
<h3><span class="mw-headline" id="Level_2">Level 2</span></h3>
<p>1. <i><a href="/w/index.php?title=Algorithms/Talking_to_computer_Lv_1&amp;action=edit&amp;redlink=1" class="new" title="Algorithms/Talking to computer Lv 1 (does not exist)">Talking to computer Lv 1</a></i> With algorithm and several different programming languages</p>
<p>2. <i><a href="/wiki/Algorithms/Sorting-bubble_sort" title="Algorithms/Sorting-bubble sort">Sorting-bubble sort</a></i> With algorithm and several different programming languages</p>
<p>3.</p>
<h3><span class="mw-headline" id="Level_3">Level 3</span></h3>
<p>1. <i><a href="/w/index.php?title=Algorithms/Talking_to_computer_Lv_2&amp;action=edit&amp;redlink=1" class="new" title="Algorithms/Talking to computer Lv 2 (does not exist)">Talking to computer Lv 2</a></i> With algorithm and several different programming languages</p>
<h3><span class="mw-headline" id="Level_4">Level 4</span></h3>
<p>1. <i><a href="/w/index.php?title=Algorithms/Talking_to_computer_Lv_3&amp;action=edit&amp;redlink=1" class="new" title="Algorithms/Talking to computer Lv 3 (does not exist)">Talking to computer Lv 3</a></i> With algorithm and several different programming languages</p>
<p>2. <i><a href="/wiki/Algorithms/Find_approximate_maximum" title="Algorithms/Find approximate maximum">Find approximate maximum</a></i> With algorithm and several different programming languages</p>
<h3><span class="mw-headline" id="Level_5">Level 5</span></h3>
<p>1. <i><a href="/wiki/Algorithm_Implementation/Sorting/Quicksort" title="Algorithm Implementation/Sorting/Quicksort">Quicksort</a></i></p>
<h1><span class="mw-headline" id="Mathematical_Background">Mathematical Background</span></h1>
<p>Before we begin learning algorithmic techniques, we take a detour to give ourselves some necessary mathematical tools. First, we cover mathematical definitions of terms that are used later on in the book. By expanding your mathematical vocabulary you can be more precise and you can state or formulate problems more simply. Following that, we cover techniques for analysing the running time of an algorithm. After each major algorithm covered in this book we give an analysis of its running time as well as a proof of its correctness</p>
<p><br /></p>
<h2><span class="mw-headline" id="Asymptotic_Notation">Asymptotic Notation</span></h2>
<p>In addition to correctness another important characteristic of a useful algorithm is its time and memory consumption. Time and memory are both valuable resources and there are important differences (even when both are abundant) in how we can use them.</p>
<p>How can you measure resource consumption? One way is to create a function that describes the usage in terms of some characteristic of the input. One commonly used characteristic of an input dataset is its size. For example, suppose an algorithm takes an input as an array of <img class="tex" alt="n" src="//upload.wikimedia.org/math/7/b/8/7b8b965ad4bca0e41ab51de7b31363a1.png" /> integers. We can describe the time this algorithm takes as a function <img class="tex" alt="f" src="//upload.wikimedia.org/math/8/f/a/8fa14cdd754f91cc6554c9e71929cce7.png" /> written in terms of <img class="tex" alt="n" src="//upload.wikimedia.org/math/7/b/8/7b8b965ad4bca0e41ab51de7b31363a1.png" />. For example, we might write:</p>
<dl>
<dd><img class="tex" alt="f(n) = n^2 + 3n + 14" src="//upload.wikimedia.org/math/0/5/0/050021f28ebab921b207d3b0d55840c1.png" /></dd>
</dl>
<p>where the value of <img class="tex" alt="f(n)" src="//upload.wikimedia.org/math/a/8/9/a8988ce0f88f5292aa28b6e49f114d45.png" /> is some unit of time (in this discussion the main focus will be on time, but we could do the same for memory consumption). Rarely are the units of time actually in seconds, because that would depend on the machine itself, the system it's running, and its load. Instead, the units of time typically used are in terms of the number of some fundamental operation performed. For example, some fundamental operations we might care about are: the number of additions or multiplications needed; the number of element comparisons; the number of memory-location swaps performed; or the raw number of machine instructions executed. In general we might just refer to these fundamental operations performed as steps taken.</p>
<p>Is this a good approach to determine an algorithm's resource consumption? Yes and no. When two different algorithms are similar in time consumption a precise function might help to determine which algorithm is faster under given conditions. But in many cases it is either difficult or impossible to calculate an analytical description of the exact number of operations needed, especially when the algorithm performs operations conditionally on the values of its input. Instead, what really is important is not the precise time required to complete the function, but rather the degree that resource consumption changes depending on its inputs. Concretely, consider these two functions, representing the computation time required for each size of input dataset:</p>
<dl>
<dd><img class="tex" alt="f(n) = n^3-12n^2+20n+110" src="//upload.wikimedia.org/math/2/7/d/27d4b0bc138cf41ea6b68717ba9eb535.png" /></dd>
<dd><img class="tex" alt="g(n) = n^3+n^2+5n+5" src="//upload.wikimedia.org/math/e/3/1/e3185300c35282c87d2765f827597e58.png" /></dd>
</dl>
<p>They look quite different, but how do they behave? Let's look at a few plots of the function (<img class="tex" alt="f(n)" src="//upload.wikimedia.org/math/a/8/9/a8988ce0f88f5292aa28b6e49f114d45.png" /> is in red, <img class="tex" alt="g(n)" src="//upload.wikimedia.org/math/e/a/c/eac896151a22d31a60cceba6deea3cbb.png" /> in blue):</p>
<table border="0">
<tr>
<td>
<div class="thumb tright">
<div class="thumbinner" style="width:290px;"><a href="/wiki/File:Algorithms-Asymptotic-ExamplePlot1.png" class="image"><img alt="" src="//upload.wikimedia.org/wikibooks/en/0/0f/Algorithms-Asymptotic-ExamplePlot1.png" width="288" height="177" class="thumbimage" /></a>
<div class="thumbcaption">Plot of f and g, in range 0 to 5</div>
</div>
</div>
</td>
<td>
<div class="thumb tright">
<div class="thumbinner" style="width:290px;"><a href="/wiki/File:Algorithms-Asymptotic-ExamplePlot2.png" class="image"><img alt="" src="//upload.wikimedia.org/wikibooks/en/b/bb/Algorithms-Asymptotic-ExamplePlot2.png" width="288" height="177" class="thumbimage" /></a>
<div class="thumbcaption">Plot of f and g, in range 0 to 15</div>
</div>
</div>
</td>
</tr>
<tr>
<td>
<div class="thumb tright">
<div class="thumbinner" style="width:290px;"><a href="/wiki/File:Algorithms-Asymptotic-ExamplePlot3.png" class="image"><img alt="" src="//upload.wikimedia.org/wikibooks/en/f/f7/Algorithms-Asymptotic-ExamplePlot3.png" width="288" height="177" class="thumbimage" /></a>
<div class="thumbcaption">Plot of f and g, in range 0 to 100</div>
</div>
</div>
</td>
<td>
<div class="thumb tright">
<div class="thumbinner" style="width:290px;"><a href="/wiki/File:Algorithms-Asymptotic-ExamplePlot4.png" class="image"><img alt="" src="//upload.wikimedia.org/wikibooks/en/6/67/Algorithms-Asymptotic-ExamplePlot4.png" width="288" height="177" class="thumbimage" /></a>
<div class="thumbcaption">Plot of f and g, in range 0 to 1000</div>
</div>
</div>
<br /></td>
</tr>
</table>
<p>In the first, very-limited plot the curves appear somewhat different. In the second plot they start going in sort of the same way, in the third there is only a very small difference, and at last they are virtually identical. In fact, they approach <img class="tex" alt="n^3" src="//upload.wikimedia.org/math/e/5/5/e55ad3a069f00d4c8d543e9477467208.png" />, the dominant term. As n gets larger, the other terms become much less significant in comparison to n<sup>3</sup>.</p>
<p>As you can see, modifying a polynomial-time algorithm's low-order coefficients doesn't help much. What really matters is the highest-order coefficient. This is why we've adopted a notation for this kind of analysis. We say that:</p>
<dl>
<dd><img class="tex" alt="f(n) = n^3-12n^2+20n+110 = O(n^3)" src="//upload.wikimedia.org/math/4/6/3/463bc80434ee9c7fcf4e4242b374c996.png" /></dd>
</dl>
<p>We ignore the low-order terms. We can say that:</p>
<dl>
<dd><img class="tex" alt="O(\log {n}) \le O(\sqrt{n}) \le O(n) \le O(n \log {n}) \le O(n^2) \le O(n^3) \le O(2^n)" src="//upload.wikimedia.org/math/b/3/2/b32084fda5112b82f2272944d9278889.png" /></dd>
</dl>
<p>This gives us a way to more easily compare algorithms with each other. Running an insertion sort on <img class="tex" alt="n" src="//upload.wikimedia.org/math/7/b/8/7b8b965ad4bca0e41ab51de7b31363a1.png" /> elements takes steps on the order of <img class="tex" alt="O(n^2)" src="//upload.wikimedia.org/math/1/8/9/189317b4b935a745fcfaf95940d2b4f0.png" />. Merge sort sorts in <img class="tex" alt="O(n \log {n})" src="//upload.wikimedia.org/math/7/9/b/79b37ec4ae5768b555aa26efeae487b3.png" /> steps. Therefore, once the input dataset is large enough, merge sort is faster than insertion sort.</p>
<p>In general, we write</p>
<dl>
<dd><img class="tex" alt="f(n) = O(g(n))" src="//upload.wikimedia.org/math/e/c/b/ecb5957b16ba0696c0fcb44a3061686e.png" /></dd>
</dl>
<p>when</p>
<dl>
<dd><img class="tex" alt="\exists c&gt;0, \exists n_0&gt; 0, \forall n\ge n_{0}: 0\le f(n)\le c\cdot g(n)." src="//upload.wikimedia.org/math/a/1/0/a10dc691df3a762faf7c69af332d1c25.png" /></dd>
</dl>
<p>That is, <img class="tex" alt="f(n) = O(g(n))" src="//upload.wikimedia.org/math/e/c/b/ecb5957b16ba0696c0fcb44a3061686e.png" /> holds if and only if there exists some constants <img class="tex" alt="c" src="//upload.wikimedia.org/math/4/a/8/4a8a08f09d37b73795649038408b5f33.png" /> and <img class="tex" alt="n_0" src="//upload.wikimedia.org/math/7/1/3/713046b065aa81fbe96db237e539e431.png" /> such that for all <img class="tex" alt="n&gt;n_0" src="//upload.wikimedia.org/math/c/4/b/c4b6ab2f66c379f9346f6b80ef336e2c.png" /> <img class="tex" alt="f(n)" src="//upload.wikimedia.org/math/a/8/9/a8988ce0f88f5292aa28b6e49f114d45.png" /> is positive and less than or equal to <img class="tex" alt="c g(n)" src="//upload.wikimedia.org/math/d/1/8/d181c9833ae70295b494e43e076d3d5d.png" />.</p>
<p>Note that the equal sign used in this notation describes a relationship between <img class="tex" alt="f(n)" src="//upload.wikimedia.org/math/a/8/9/a8988ce0f88f5292aa28b6e49f114d45.png" /> and <img class="tex" alt="g(n)" src="//upload.wikimedia.org/math/e/a/c/eac896151a22d31a60cceba6deea3cbb.png" /> instead of reflecting a true equality. In light of this, some define Big-O in terms of a set, stating that:</p>
<dl>
<dd><img class="tex" alt="f(n)\in O(g(n))" src="//upload.wikimedia.org/math/d/9/b/d9b0c3a5fdb436804c7a00f5571443b2.png" /></dd>
</dl>
<p>when</p>
<dl>
<dd><img class="tex" alt="f(n)\in \{f(n)&#160;: \exists c&gt;0, \exists n_0&gt; 0, \forall n\ge n_0: 0\le f(n)\le c\cdot g(n)\}." src="//upload.wikimedia.org/math/4/9/8/49847c6faed608b1d6b88f985b1a29ad.png" /></dd>
</dl>
<p>Big-O notation is only an upper bound; these two are both true:</p>
<dl>
<dd><img class="tex" alt="n^3 = O(n^4)" src="//upload.wikimedia.org/math/5/9/a/59a15aac0e201816496a04238ba97235.png" /></dd>
<dd><img class="tex" alt="n^4 = O(n^4)" src="//upload.wikimedia.org/math/0/d/8/0d8cd2d2762161e93b816bbc56b186af.png" /></dd>
</dl>
<p>If we use the equal sign as an equality we can get very strange results, such as:</p>
<dl>
<dd><img class="tex" alt="n^3 = n^4" src="//upload.wikimedia.org/math/c/7/e/c7eb71ec3213a51156fc17756a9ec712.png" /></dd>
</dl>
<p>which is obviously nonsense. This is why the set-definition is handy. You can avoid these things by thinking of the equal sign as a one-way equality, i.e.:</p>
<dl>
<dd><img class="tex" alt="n^3 = O(n^4)" src="//upload.wikimedia.org/math/5/9/a/59a15aac0e201816496a04238ba97235.png" /></dd>
</dl>
<p>does not imply</p>
<dl>
<dd><img class="tex" alt="O(n^4) = n^3" src="//upload.wikimedia.org/math/b/0/6/b06d17d234e3a5b90dd734931685f3df.png" /></dd>
</dl>
<p>Always keep the O on the right hand side.</p>
<h3><span class="mw-headline" id="Big_Omega">Big Omega</span></h3>
<p>Sometimes, we want more than an upper bound on the behavior of a certain function. Big Omega provides a lower bound. In general, we say that</p>
<dl>
<dd><img class="tex" alt="f(n) = \Omega(g(n))" src="//upload.wikimedia.org/math/7/f/d/7fd23648d5ef2a21c2e2027c9af87775.png" /></dd>
</dl>
<p>when</p>
<dl>
<dd><img class="tex" alt="\exists c&gt;0, \exists n_0&gt; 0, \forall n\ge n_{0}: 0\le c\cdot g(n)\le f(n)." src="//upload.wikimedia.org/math/a/d/8/ad89fdbff992972fed3fdbeec611ebe6.png" /></dd>
</dl>
<p>i.e. <img class="tex" alt="f(n) = \Omega(g(n))" src="//upload.wikimedia.org/math/7/f/d/7fd23648d5ef2a21c2e2027c9af87775.png" /> if and only if there exist constants c and n<sub>0</sub> such that for all n&gt;n<sub>0</sub> f(n) is positive and <b>greater</b> than or equal to cg(n).</p>
<p>So, for example, we can say that</p>
<dl>
<dd><img class="tex" alt="n^2-2n = \Omega(n^2)" src="//upload.wikimedia.org/math/5/7/9/5792b7c1848ed658eee17c5eeaaadd75.png" />, (c=1/2, n<sub>0</sub>=4) or</dd>
<dd><img class="tex" alt="n^2-2n = \Omega(n)" src="//upload.wikimedia.org/math/b/a/c/bacdbac72089b9fbcb22f83fea6d4e45.png" />, (c=1, n<sub>0</sub>=3),</dd>
</dl>
<p>but it is false to claim that</p>
<dl>
<dd><img class="tex" alt="n^2-2n = \Omega(n^3)." src="//upload.wikimedia.org/math/4/5/c/45ca311f15f098c73e0d8fb9303b922e.png" /></dd>
</dl>
<h3><span class="mw-headline" id="Big_Theta">Big Theta</span></h3>
<p>When a given function is both O(g(n)) and Ω(g(n)), we say it is Θ(g(n)), and we have a tight bound on the function. A function f(n) is Θ(g(n)) when</p>
<dl>
<dd><img class="tex" alt="\exists c_1&gt;0, \exists c_2&gt;0, \exists n_0&gt; 0, \forall n\ge n_0&#160;: 0\le c_1\cdot g(n)\le f(n)\le c_2\cdot g(n)," src="//upload.wikimedia.org/math/1/8/1/1813e763d50f4a43c21a83dad8e05bde.png" /></dd>
</dl>
<p>but most of the time, when we're trying to prove that a given <img class="tex" alt="f(n) = \Theta(g(n))" src="//upload.wikimedia.org/math/c/7/3/c73335632503a8e2ef79bc5ad686716b.png" />, instead of using this definition, we just show that it is both O(g(n)) and Ω(g(n)).</p>
<h3><span class="mw-headline" id="Little-O_and_Omega">Little-O and Omega</span></h3>
<p>When the asymptotic bound is not tight, we can express this by saying that <img class="tex" alt="f(n) = o(g(n))" src="//upload.wikimedia.org/math/5/f/4/5f454678eb90eb556ecc38b2e613559e.png" /> or <img class="tex" alt="f(n) = \omega(g(n))." src="//upload.wikimedia.org/math/e/e/b/eeb4cc03236efa00bcd483e663f4184b.png" /> The definitions are:</p>
<dl>
<dd>f(n) is o(g(n)) iff <img class="tex" alt="\forall c&gt;0, \exists n_0&gt; 0, \forall n\ge n_0: 0\le f(n) &lt; c\cdot g(n)" src="//upload.wikimedia.org/math/0/8/9/089ef81ee4f24e6304c5ffc8ba430fe5.png" /> and</dd>
<dd>f(n) is ω(g(n)) iff <img class="tex" alt="\forall c&gt;0, \exists n_0&gt; 0, \forall n\ge n_0: 0\le c\cdot g(n) &lt; f(n)." src="//upload.wikimedia.org/math/b/c/f/bcf3491613ca7f42729a40ed3c6117ab.png" /></dd>
</dl>
<p>Note that a function f is in o(g(n)) when for any coefficient of g, g eventually gets larger than f, while for O(g(n)), there only has to exist a single coefficient for which g eventually gets at least as big as f.</p>
<p>[TODO: define what T(n,m) = O(f(n,m)) means. That is, when the running time of an algorithm has two dependent variables. Ex, a graph with n nodes and m edges. It's important to get the quantifiers correct!]</p>
<h2><span class="mw-headline" id="Algorithm_Analysis:_Solving_Recurrence_Equations">Algorithm Analysis: Solving Recurrence Equations</span></h2>
<p>Merge sort of n elements: <img class="tex" alt="T(n) = 2*T(n/2) + c(n)" src="//upload.wikimedia.org/math/d/a/9/da9a49814d893569d560d14963b8455a.png" /> This describes one iteration of the merge sort: the problem space <img class="tex" alt="n" src="//upload.wikimedia.org/math/7/b/8/7b8b965ad4bca0e41ab51de7b31363a1.png" /> is reduced to two halves (<img class="tex" alt="2*T(n/2)" src="//upload.wikimedia.org/math/5/3/e/53eed1a9c9e90aa244a38bef68f7d6df.png" />), and then merged back together at the end of all the recursive calls (<img class="tex" alt="c(n)" src="//upload.wikimedia.org/math/6/f/9/6f92aad59cd2c0646a2f0c5844875990.png" />). This notation system is the bread and butter of algorithm analysis, so get used to it.</p>
<p>There are some theorems you can use to estimate the big Oh time for a function if its recurrence equation fits a certain pattern.</p>
<p>[TODO: write this section]</p>
<h3><span class="mw-headline" id="Substitution_method">Substitution method</span></h3>
<p>Formulate a guess about the big Oh time of your equation. Then use proof by induction to prove the guess is correct.</p>
<p>[TODO: write this section]</p>
<h3><span class="mw-headline" id="Summations">Summations</span></h3>
<p>[TODO: show the closed forms of commonly needed summations and prove them]</p>
<h3><span class="mw-headline" id="Draw_the_Tree_and_Table">Draw the Tree and Table</span></h3>
<p>This is really just a way of getting an intelligent guess. You still have to go back to the substitution method in order to prove the big Oh time.</p>
<p>[TODO: write this section]</p>
<h3><span class="mw-headline" id="The_Master_Theorem">The Master Theorem</span></h3>
<p>Consider a recurrence equation that fits the following formula:</p>
<dl>
<dd><img class="tex" alt="T(n) = a T\left({\frac{n}{b}}\right) + O(n^k)" src="//upload.wikimedia.org/math/8/8/d/88d67a55d33bc1f20a7f74552a4f77a2.png" /></dd>
</dl>
<p>for <i>a</i> ≥ 1, <i>b</i> &gt; 1 and <i>k</i> ≥ 0. Here, <i>a</i> is the number of recursive calls made per call to the function, <i>n</i> is the input size, <i>b</i> is how much smaller the input gets, and <i>k</i> is the polynomial order of an operation that occurs each time the function is called (except for the base cases). For example, in the merge sort algorithm covered later, we have</p>
<dl>
<dd><img class="tex" alt="T(n) = 2 T\left({\frac{n}{2}}\right) + O(n)" src="//upload.wikimedia.org/math/b/b/2/bb2e5486d3a0a18302dcdd70ea32aab1.png" /></dd>
</dl>
<p>because two subproblems are called for each non-base case iteration, and the size of the array is divided in half each time. The <img class="tex" alt="O(n)" src="//upload.wikimedia.org/math/7/b/a/7ba55e7c64a9405a0b39a1107e90ca94.png" /> at the end is the "conquer" part of this divide and conquer algorithm: it takes linear time to merge the results from the two recursive calls into the final result.</p>
<p>Thinking of the recursive calls of <i>T</i> as forming a tree, there are three possible cases to determine where most of the algorithm is spending its time ("most" in this sense is concerned with its asymptotic behaviour):</p>
<ol>
<li>the tree can be <b>top heavy</b>, and most time is spent during the initial calls near the root;</li>
<li>the tree can have a <b>steady state</b>, where time is spread evenly; or</li>
<li>the tree can be <b>bottom heavy</b>, and most time is spent in the calls near the leaves</li>
</ol>
<p>Depending upon which of these three states the tree is in <i>T</i> will have different complexities:</p>
<div style="background-color: #FFFFEE; border: solid 1px #FFC92E; padding: 1em; width: 80%;"><b>The Master Theorem</b><br />
<p>Given <img class="tex" alt="T(n) = a T\left({\frac{n}{b}}\right) + O(n^k)" src="//upload.wikimedia.org/math/8/8/d/88d67a55d33bc1f20a7f74552a4f77a2.png" /> for <i>a</i> ≥ 1, <i>b</i> &gt; 1 and <i>k</i> ≥ 0:</p>
<ul>
<li>If <img class="tex" alt="a &lt; b^k" src="//upload.wikimedia.org/math/9/f/a/9fa0f59cb5f61746d639ac52774900b6.png" />, then <img class="tex" alt="T(n) = O(n^k)\ " src="//upload.wikimedia.org/math/2/4/d/24dfe716ba4a28c56eb928b5bb82342c.png" /> (top heavy)</li>
<li>If <img class="tex" alt="a = b^k" src="//upload.wikimedia.org/math/a/4/6/a46303eecfef670c9e04cd771b08b68a.png" />, then <img class="tex" alt="T(n) = O(n^k\cdot \log n)" src="//upload.wikimedia.org/math/0/a/e/0ae2e7e36b46ea10151b023e7bc7703e.png" /> (steady state)</li>
<li>If <img class="tex" alt="a &gt; b^k" src="//upload.wikimedia.org/math/0/9/e/09e52454d505ed55078d6427e1960646.png" />, then <img class="tex" alt="T(n) = O(n^{\log_b a})" src="//upload.wikimedia.org/math/d/7/4/d74876e088d802538656f7b08082cbb2.png" /> (bottom heavy)</li>
</ul>
</div>
<p>For the merge sort example above, where</p>
<dl>
<dd><img class="tex" alt="T(n) = 2 T\left({\frac{n}{2}}\right) + O(n)" src="//upload.wikimedia.org/math/b/b/2/bb2e5486d3a0a18302dcdd70ea32aab1.png" /></dd>
</dl>
<p>we have</p>
<dl>
<dd><img class="tex" alt="a=2, b=2, k=1\implies b^k = 2" src="//upload.wikimedia.org/math/1/1/9/1197d41b015c797288b9550ec1dc7c07.png" /></dd>
</dl>
<p>thus, <img class="tex" alt="a = b^k" src="//upload.wikimedia.org/math/a/4/6/a46303eecfef670c9e04cd771b08b68a.png" /> and so this is also in the "steady state": By the master theorem, the complexity of merge sort is thus</p>
<dl>
<dd><img class="tex" alt="T(n) = O(n^1\log n) = O(n \log n)" src="//upload.wikimedia.org/math/c/b/7/cb7344ac4ab22272a557b416e3e77fe0.png" />.</dd>
</dl>
<h2><span class="mw-headline" id="Amortized_Analysis">Amortized Analysis</span></h2>
<p>[Start with an adjacency list representation of a graph and show two nested for loops: one for each node n, and nested inside that one loop for each edge e. If there are n nodes and m edges, this could lead you to say the loop takes O(nm) time. However, only once could the innerloop take that long, and a tighter bound is O(n+m).]</p>
<p><br /></p>
<h1><span class="mw-headline" id="Divide_and_Conquer">Divide and Conquer</span></h1>
<p>The first major algorithmic technique we cover is <b>divide and conquer</b>. Part of the trick of making a good divide and conquer algorithm is determining how a given problem could be separated into two or more similar, but smaller, subproblems. More generally, when we are creating a divide and conquer algorithm we will take the following steps:</p>
<table width="80%">
<tr>
<td style="background-color: #FFFFEE; border: solid 1px #FFC92E; padding: 1em;" valign="top"><b>Divide and Conquer Methodology</b><br />
<ol>
<li>Given a problem, identify a small number of significantly smaller subproblems of the same type</li>
<li>Solve each subproblem recursively (the smallest possible size of a subproblem is a base-case)</li>
<li>Combine these solutions into a solution for the main problem</li>
</ol>
</td>
</tr>
</table>
<p>The first algorithm we'll present using this methodology is the merge sort.</p>
<h2><span class="mw-headline" id="Merge_Sort">Merge Sort</span></h2>
<p>The problem that <b>merge sort</b> solves is general sorting: given an unordered array of elements that have a total ordering, create an array that has the same elements sorted. More precisely, for an array <i>a</i> with indexes 1 through <i>n</i>, if the condition</p>
<dl>
<dd>for all <i>i</i>, <i>j</i> such that 1 ≤ <i>i</i> &lt; <i>j</i> ≤ <i>n</i> then <i>a</i>[<i>i</i>] ≤ <i>a</i>[<i>j</i>]</dd>
</dl>
<p>holds, then <i>a</i> is said to be <b>sorted</b>. Here is the interface:</p>
<pre>
<i>// sort -- returns a sorted copy of array a</i>
function <b>sort</b>(array <i>a</i>): array
</pre>
<p>Following the divide and conquer methodology, how can <i>a</i> be broken up into smaller subproblems? Because <i>a</i> is an array of <i>n</i> elements, we might want to start by breaking the array into two arrays of size <i>n</i>/2 elements. These smaller arrays will also be unsorted and it is meaningful to sort these smaller problems; thus we can consider these smaller arrays "similar". Ignoring the base case for a moment, this reduces the problem into a different one: Given two sorted arrays, how can they be combined to form a single sorted array that contains all the elements of both given arrays:</p>
<pre>
<i>// merge -- given a and b (assumed to be sorted) returns a merged array that</i>
// preserves order
function <b>merge</b>(array <i>a</i>, array <i>b</i>): array
</pre>
<p>So far, following the methodology has led us to this point, but what about the base case? The base case is the part of the algorithm concerned with what happens when the problem cannot be broken into smaller subproblems. Here, the base case is when the array only has one element. The following is a sorting algorithm that faithfully sorts arrays of only zero or one elements:</p>
<pre>
<i>// base-sort -- given an array of one element (or empty), return a copy of the</i>
// array sorted
function <b>base-sort</b>(array <i>a</i>[1..<i>n</i>]): array
  assert (<i>n</i> &lt;= 1)
  return <i>a</i>.copy()
end
</pre>
<p>Putting this together, here is what the methodology has told us to write so far:</p>
<pre>
<i>// sort -- returns a sorted copy of array a</i>
function <b>sort</b>(array <i>a</i>[1..<i>n</i>]): array
  if <i>n</i> &lt;= 1: return <i>a</i>.copy()
  else:
    let <i>sub_size</i> := <i>n</i> / 2
    let <i>first_half</i> := <b>sort</b>(<i>a</i>[1,..,<i>sub_size</i>])
    let <i>second_half</i> := <b>sort</b>(<i>a</i>[<i>sub_size</i> + 1,..,<i>n</i>])
    
    return <b>merge</b>(<i>first_half</i>, <i>second_half</i>)
  fi
end
</pre>
<p>And, other than the unimplemented merge subroutine, this sorting algorithm is done! Before we cover how this algorithm works, here is how merge can be written:</p>
<pre>
<i>// merge -- given a and b (assumed to be sorted) returns a merged array that</i>
// preserves order
function <b>merge</b>(array <i>a</i>[1..<i>n</i>], array <i>b</i>[1..<i>m</i>]): array
  let <i>result</i> := new array[<i>n</i> + <i>m</i>]
  let <i>i</i>, <i>j</i> := 1
  
  for <i>k</i> := 1 to <i>n</i> + <i>m</i>:
    if <i>i</i> &gt;= <i>n</i>: <i>result</i>[<i>k</i>] := <i>b</i>[<i>j</i>]; <i>j</i> += 1
    else-if <i>j</i> &gt;= <i>m</i>: <i>result</i>[<i>k</i>] := <i>a</i>[<i>i</i>]; <i>i</i> += 1
    else:
      if <i>a</i>[<i>i</i>] &lt; <i>b</i>[<i>j</i>]:
        <i>result</i>[<i>k</i>] := <i>a</i>[<i>i</i>]; <i>i</i> += 1
      else:
        <i>result</i>[<i>k</i>] := <i>b</i>[<i>j</i>]; <i>j</i> += 1
      fi
    fi
  repeat
end
</pre>
<p>[TODO: how it works; including correctness proof] This algorithm uses the fact that, given two sorted arrays, the smallest element is always in one of two places. It's either at the head of the first array, or the head of the second.</p>
<h3><span class="mw-headline" id="Analysis">Analysis</span></h3>
<p>Let <img class="tex" alt="T(n)" src="//upload.wikimedia.org/math/5/1/4/514884be093e9ab7909b0d394e7b74d2.png" /> be the number of steps the algorithm takes to run on input of size <img class="tex" alt="n" src="//upload.wikimedia.org/math/7/b/8/7b8b965ad4bca0e41ab51de7b31363a1.png" />.</p>
<p>Merging takes linear time and we recurse each time on two sub-problems of half the original size, so</p>
<dl>
<dd><img class="tex" alt="T(n) = 2\cdot T\left(\frac{n}{2}\right) + O(n)." src="//upload.wikimedia.org/math/f/7/2/f72a53c8f8f6d3035c197a35096a0c4e.png" /></dd>
</dl>
<p>By the master theorem, we see that this recurrence has a "steady state" tree. Thus, the runtime is:</p>
<dl>
<dd><img class="tex" alt="T(n) = O(n \cdot \log n)." src="//upload.wikimedia.org/math/f/9/6/f96289c2cbde730474573330629fb8df.png" /></dd>
</dl>
<p>This can be seen intuitivey by asking how may times does n need to be divided by 2 before the size of the array for sorting is 1? Why m times of course&#160;!</p>
<p>More directly, 2<sup>m</sup> = n , equivalent to log 2<sup>m</sup> = log n, equivalent to m x log<sub>2</sub>2 = log <sub>2</sub> n , and since log<sub>2</sub> 2 = 1, equivalent to m = log<sub>2</sub>n.</p>
<p>Since m is the number of halvings of an array before the array is chopped up into bite sized pieces of 1-element arrays, and then it will take m levels of merging a sub-array with its neighbor where the sum size of sub-arrays will be n at each level, it will be exactly n/2 comparisons for merging at each level, with m ( log<sub>2</sub>n ) levels, thus O(n/2 x log n ) &lt;=&gt; <b>O ( n log n).</b></p>
<h3><span class="mw-headline" id="Iterative_Version">Iterative Version</span></h3>
<p>This merge sort algorithm can be turned into an iterative algorithm by iteratively merging each subsequent pair, then each group of four, et cetera. Due to a lack of function overhead, iterative algorithms tend to be faster in practice. However, because the recursive version's call tree is logarithmically deep, it does not require much run-time stack space: Even sorting 4 gigs of items would only require 32 call entries on the stack, a very modest amount considering if even each call required 256 bytes on the stack, it would only require 8 kilobytes.</p>
<p>The iterative version of mergesort is a minor modification to the recursive version - in fact we can reuse the earlier merging function. The algorithm works by merging small, sorted subsections of the original array to create larger subsections of the array which are sorted. To accomplish this, we iterate through the array with successively larger "strides".</p>
<pre>
<i>// sort -- returns a sorted copy of array a</i>
function <b>sort_iterative</b>(array <i>a</i>[1..<i>n</i>]): array
   let <i>result</i> := <i>a</i>.copy()
   for <i>power</i> := 0 to log2(<i>n</i>-1)
     let <i>unit</i> := 2^power
     for <i>i</i> := 1 to <i>n</i> by <i>unit</i>*2
       if i+<i>unit</i>-1 &lt; n: 
         let <i>a1</i>[1..<i>unit</i>] := <i>result</i>[i..i+<i>unit</i>-1]
         let <i>a2</i>[1..<i>unit</i>] := <i>result</i>[i+<i>unit</i>..min(i+<i>unit</i>*2-1, <i>n</i>)]
         <i>result</i>[i..i+<i>unit</i>*2-1] := <b>merge</b>(<i>a1</i>,<i>a2</i>)
       fi
     repeat
   repeat
   
   return <i>result</i>
end
</pre>
<p>This works because each sublist of length 1 in the array is, by definition, sorted. Each iteration through the array (using counting variable <i>i</i>) doubles the size of sorted sublists by merging adjacent sublists into sorted larger versions. The current size of sorted sublists in the algorithm is represented by the <i>unit</i> variable.</p>
<h3><span class="mw-headline" id="space_inefficiency">space inefficiency</span></h3>
<p>Straight forward merge sort requires a space of 2 x n , n to store the 2 sorted smaller arrays , and n to store the final result of merging. But merge sort still lends itself for batching of merging.</p>
<h2><span class="mw-headline" id="Binary_Search">Binary Search</span></h2>
<p>Once an array is sorted, we can quickly locate items in the array by doing a binary search. Binary search is different from other divide and conquer algorithms in that it is mostly divide based (nothing needs to be conquered). The concept behind binary search will be useful for understanding the partition and quicksort algorithms, presented in the randomization chapter.</p>
<p>Finding an item in an already sorted array is similar to finding a name in a phonebook: you can start by flipping the book open toward the middle. If the name you're looking for is on that page, you stop. If you went too far, you can start the process again with the first half of the book. If the name you're searching for appears later than the page, you start from the second half of the book instead. You repeat this process, narrowing down your search space by half each time, until you find what you were looking for (or, alternatively, find where what you were looking for would have been if it were present).</p>
<p>The following algorithm states this procedure precisely:</p>
<pre>
<i>// binary-search -- returns the index of value in the given array, or</i>
<i>// -1 if value cannot be found. Assumes array is sorted in ascending order</i>
function <b>binary-search</b>(<i>value</i>, array <i>A</i>[1..<i>n</i>]): integer
  return <b>search-inner</b>(<i>value</i>, <i>A</i>, 1, <i>n</i> + 1)
end

<i>// search-inner -- search subparts of the array; end is one past the</i>
<i>// last element </i>
function <b>search-inner</b>(<i>value</i>, array <i>A</i>, <i>start</i>, <i>end</i>): integer
  if <i>start</i> == <i>end</i>: 
     return -1                   <i>// not found</i>
  fi

  let <i>length</i> := <i>end</i> - <i>start</i>
  if <i>length</i> == 1:
    if <i>value</i> == <i>A</i>[<i>start</i>]:
      return <i>start</i>
    else:
      return -1 
    fi
  fi
  
  let <i>mid</i> := <i>start</i> + (<i>length</i> / 2)
  if <i>value</i> == <i>A</i>[<i>mid</i>]:
    return <i>mid</i>
  else-if <i>value</i> &gt; <i>A</i>[<i>mid</i>]:
    return <b>search-inner</b>(<i>value</i>, <i>A</i>, <i>mid</i> + 1, <i>end</i>)
  else:
    return <b>search-inner</b>(<i>value</i>, <i>A</i>, <i>start</i>, <i>mid</i>)
  fi
end
</pre>
<p>Note that all recursive calls made are tail-calls, and thus the algorithm is iterative. We can explicitly remove the tail-calls if our programming language does not do that for us already by turning the argument values passed to the recursive call into assignments, and then looping to the top of the function body again:</p>
<pre>
<i>// binary-search -- returns the index of value in the given array, or</i>
<i>// -1 if value cannot be found. Assumes array is sorted in ascending order</i>
function <b>binary-search</b>(<i>value</i>, array <i>A</i>[1,..<i>n</i>]): integer
  let <i>start</i> := 1
  let <i>end</i> := <i>n</i> + 1
  
  loop:
    if <i>start</i> == <i>end</i>: return -1 fi                 <i>// not found</i>
  
    let <i>length</i> := <i>end</i> - <i>start</i>
    if <i>length</i> == 1:
      if <i>value</i> == <i>A</i>[<i>start</i>]: return <i>start</i>
      else: return -1 fi
    fi
  
    let <i>mid</i> := <i>start</i> + (<i>length</i> / 2)
    if <i>value</i> == <i>A</i>[<i>mid</i>]:
      return <i>mid</i>
    else-if <i>value</i> &gt; <i>A</i>[<i>mid</i>]:
      <i>start</i> := <i>mid</i> + 1
    else:
      <i>end</i> := <i>mid</i>
    fi
  repeat
end
</pre>
<p>Even though we have an iterative algorithm, it's easier to reason about the recursive version. If the number of steps the algorithm takes is <img class="tex" alt="T(n)" src="//upload.wikimedia.org/math/5/1/4/514884be093e9ab7909b0d394e7b74d2.png" />, then we have the following recurrence that defines <img class="tex" alt="T(n)" src="//upload.wikimedia.org/math/5/1/4/514884be093e9ab7909b0d394e7b74d2.png" />:</p>
<dl>
<dd><img class="tex" alt="T(n) = 1\cdot T\left(\frac{n}{2}\right) + O(1)." src="//upload.wikimedia.org/math/6/a/5/6a51f0f28450408d3e83e7bb56b0de56.png" /></dd>
</dl>
<p>The size of each recursive call made is on half of the input size (<img class="tex" alt="n" src="//upload.wikimedia.org/math/7/b/8/7b8b965ad4bca0e41ab51de7b31363a1.png" />), and there is a constant amount of time spent outside of the recursion (i.e., computing <i>length</i> and <i>mid</i> will take the same amount of time, regardless of how many elements are in the array). By the master theorem, this recurrence has values <img class="tex" alt="a=1, b=2, k=0" src="//upload.wikimedia.org/math/c/6/0/c603c64df2de3b4846131fd3bd788af4.png" />, which is a "steady state" tree, and thus we use the steady state case that tells us that</p>
<dl>
<dd><img class="tex" alt="T(n) = \Theta(n^k\cdot\log n) = \Theta(\log n)." src="//upload.wikimedia.org/math/2/6/e/26e74401bcd43f9e5f18ff17100fd624.png" /></dd>
</dl>
<p>Thus, this algorithm takes logarithmic time. Typically, even when <i>n</i> is large, it is safe to let the stack grow by <img class="tex" alt="\log n" src="//upload.wikimedia.org/math/0/d/2/0d2e858bd7f89eed5461e5637d6e0a50.png" /> activation records through recursive calls.</p>
<h4><span class="mw-headline" id="difficulty_in_initially_correct_binary_search_implementations">difficulty in initially correct binary search implementations</span></h4>
<p>The article on wikipedia on Binary Search also mentions the difficulty in writing a correct binary search algorithm: for instance, the java Arrays.binarySearch(..) overloaded function implementation does an interative binary search which didn't work when large integers overflowed a simple expression of mid calculation mid = ( end + start) / 2 i.e. end + start &gt; max_positive_integer . Hence the above algorithm is more correct in using a length = end - start, and adding half length to start. The java binary Search algorithm gave a return value useful for finding the position of the nearest key greater than the search key, i.e. the position where the search key could be inserted.</p>
<p>i.e. it returns <i>- (keypos+1)</i> , if the search key wasn't found exactly, but an insertion point was needed for the search key ( insertion_point = <i>-return_value - 1</i>). Looking at <a href="/w/index.php?title=Boundary_values&amp;action=edit&amp;redlink=1" class="new" title="Boundary values (does not exist)">boundary values</a>, an insertion point could be at the front of the list ( ip = 0, return value = -1 ), to the position just after the last element, ( ip = length(A), return value = <i>- length(A) - 1</i>) .</p>
<p>As an exercise, trying to implement this functionality on the above iterative binary search can be useful for further comprehension.</p>
<h2><span class="mw-headline" id="Integer_Multiplication">Integer Multiplication</span></h2>
<p>If you want to perform arithmetic with small integers, you can simply use the built-in arithmetic hardware of your machine. However, if you wish to multiply integers larger than those that will fit into the standard "word" integer size of your computer, you will have to implement a multiplication algorithm in software or use a software implementation written by someone else. For example, RSA encryption needs to work with integers of very large size (that is, large relative to the 64-bit word size of many machines) and utilizes special multiplication algorithms.<sup id="cite_ref-1" class="reference"><a href="#cite_note-1">[1]</a></sup></p>
<h3><span class="mw-headline" id="Grade_School_Multiplication">Grade School Multiplication</span></h3>
<p>How do we represent a large, multi-word integer? We can have a binary representation by using an array (or an allocated block of memory) of words to represent the bits of the large integer. Suppose now that we have two integers, <img class="tex" alt="X" src="//upload.wikimedia.org/math/0/2/1/02129bb861061d1a052c592e2dc6b383.png" /> and <img class="tex" alt="Y" src="//upload.wikimedia.org/math/5/7/c/57cec4137b614c87cb4e24a3d003a3e0.png" />, and we want to multiply them together. For simplicity, let's assume that both <img class="tex" alt="X" src="//upload.wikimedia.org/math/0/2/1/02129bb861061d1a052c592e2dc6b383.png" /> and <img class="tex" alt="Y" src="//upload.wikimedia.org/math/5/7/c/57cec4137b614c87cb4e24a3d003a3e0.png" /> have <img class="tex" alt="n" src="//upload.wikimedia.org/math/7/b/8/7b8b965ad4bca0e41ab51de7b31363a1.png" /> bits each (if one is shorter than the other, we can always pad on zeros at the beginning). The most basic way to multiply the integers is to use the grade school multiplication algorithm. This is even easier in binary, because we only multiply by 1 or 0:</p>
<pre>
         x6 x5 x4 x3 x2 x1 x0
      ×  y6 y5 y4 y3 y2 y1 y0
      -----------------------
         x6 x5 x4 x3 x2 x1 x0 (when y0 is 1; 0 otherwise)
      x6 x5 x4 x3 x2 x1 x0  0 (when y1 is 1; 0 otherwise)
   x6 x5 x4 x3 x2 x1 x0  0  0 (when y2 is 1; 0 otherwise)
x6 x5 x4 x3 x2 x1 x0  0  0  0 (when y3 is 1; 0 otherwise)
  ... et cetera
</pre>
<p>As an algorithm, here's what multiplication would look like:</p>
<pre>
<i>// multiply -- return the product of two binary integers, both of length n</i>
function <b>multiply</b>(bitarray <i>x</i>[1,..<i>n</i>], bitarray <i>y</i>[1,..<i>n</i>]): bitarray
  bitarray <i>p</i> = 0
  for <i>i</i>:=1 to <i>n</i>:
    if <i>y</i>[<i>i</i>] == 1:
      <i>p</i> := <b>add</b>(<i>p</i>, <i>x</i>)
    fi
    <i>x</i> := <b>pad</b>(<i>x</i>, 0)         <i>// add another zero to the end of x</i>
  repeat
  return <i>p</i>
end
</pre>
<p>The subroutine <b>add</b> adds two binary integers and returns the result, and the subroutine <b>pad</b> adds an extra digit to the end of the number (padding on a zero is the same thing as shifting the number to the left; which is the same as multiplying it by two). Here, we loop <i>n</i> times, and in the worst-case, we make <i>n</i> calls to <b>add</b>. The numbers given to <b>add</b> will at most be of length <img class="tex" alt="2n" src="//upload.wikimedia.org/math/2/1/e/21e2c0c0472b331622877accbe29b91b.png" />. Further, we can expect that the <b>add</b> subroutine can be done in linear time. Thus, if <i>n</i> calls to a <img class="tex" alt="O(n)" src="//upload.wikimedia.org/math/7/b/a/7ba55e7c64a9405a0b39a1107e90ca94.png" /> subroutine are made, then the algorithm takes <img class="tex" alt="O(n^2)" src="//upload.wikimedia.org/math/1/8/9/189317b4b935a745fcfaf95940d2b4f0.png" /> time.</p>
<h3><span class="mw-headline" id="Divide_and_Conquer_Multiplication">Divide and Conquer Multiplication</span></h3>
<p>As you may have figured, this isn't the end of the story. We've presented the "obvious" algorithm for multiplication; so let's see if a divide and conquer strategy can give us something better. One route we might want to try is breaking the integers up into two parts. For example, the integer <i>x</i> could be divided into two parts, <img class="tex" alt="x_{h}" src="//upload.wikimedia.org/math/a/0/2/a026dab4c61211a27de40531d9a99a39.png" /> and <img class="tex" alt="x_{l}" src="//upload.wikimedia.org/math/f/3/d/f3d897253574b4388b44258f6f5c637f.png" />, for the high-order and low-order halves of <img class="tex" alt="x" src="//upload.wikimedia.org/math/9/d/d/9dd4e461268c8034f5c8564e155c67a6.png" />. For example, if <img class="tex" alt="x" src="//upload.wikimedia.org/math/9/d/d/9dd4e461268c8034f5c8564e155c67a6.png" /> has <i>n</i> bits, we have</p>
<dl>
<dd><img class="tex" alt="x = x_{h}\cdot 2^{n/2} + x_{l}" src="//upload.wikimedia.org/math/a/3/c/a3ccd80bed13472ec9d81dc4640c59ea.png" /></dd>
</dl>
<p>We could do the same for <img class="tex" alt="y" src="//upload.wikimedia.org/math/4/1/5/415290769594460e2e485922904f345d.png" />:</p>
<dl>
<dd><img class="tex" alt="y = y_{h}\cdot 2^{n/2} + y_{l}" src="//upload.wikimedia.org/math/8/c/6/8c6acf834f6b7f60fbc1e79d4bd3fb2c.png" /></dd>
</dl>
<p>But from this division into smaller parts, it's not clear how we can multiply these parts such that we can combine the results for the solution to the main problem. First, let's write out <img class="tex" alt="x\times y" src="//upload.wikimedia.org/math/8/9/d/89df7401551d525a04db9dc12e4684ba.png" /> would be in such a system:</p>
<dl>
<dd><img class="tex" alt="x\times y = x_h\times y_h\cdot (2^{n/2})^2 + (x_h\times y_l + x_l\times y_h)\cdot (2^{n/2}) + x_l\times y_l" src="//upload.wikimedia.org/math/1/2/a/12a3ed0209478453aa81a13fe0f05e8b.png" /></dd>
</dl>
<p>This comes from simply multiplying the new hi/lo representations of <img class="tex" alt="x" src="//upload.wikimedia.org/math/9/d/d/9dd4e461268c8034f5c8564e155c67a6.png" /> and <img class="tex" alt="y" src="//upload.wikimedia.org/math/4/1/5/415290769594460e2e485922904f345d.png" /> together. The multiplication of the smaller pieces are marked by the "<img class="tex" alt="\times" src="//upload.wikimedia.org/math/9/e/e/9eedd61e32f7a8e70e171028a7e5dc08.png" />" symbol. Note that the multiplies by <img class="tex" alt="2^{n/2}" src="//upload.wikimedia.org/math/4/a/d/4addf4efa85422bf46470f4c8a39a260.png" /> and <img class="tex" alt="(2^{n/2})^2 = 2^n" src="//upload.wikimedia.org/math/3/e/8/3e89ad3e123416796baf08275856c496.png" /> does not require a real multiplication: we can just pad on the right number of zeros instead. This suggests the following divide and conquer algorithm:</p>
<pre>
<i>// multiply -- return the product of two binary integers, both of length n</i>
function <b>multiply</b>(bitarray <i>x</i>[1,..<i>n</i>], bitarray <i>y</i>[1,..<i>n</i>]): bitarray
  if <i>n</i> == 1: return <i>x</i>[1] * <i>y</i>[1] fi          <i>// multiply single digits: O(1)</i>
  
  let <i>xh</i> := <i>x</i>[<i>n</i>/2 + 1, .., <i>n</i>]               <i>// array slicing, O(n)</i>
  let <i>xl</i> := <i>x</i>[0, .., <i>n</i> / 2]                 <i>// array slicing, O(n)</i>
  let <i>yh</i> := <i>y</i>[<i>n</i>/2 + 1, .., <i>n</i>]               <i>// array slicing, O(n)</i>
  let <i>yl</i> := <i>y</i>[0, .., <i>n</i> / 2]                 <i>// array slicing, O(n)</i>
  
  let <i>a</i> := <b>multiply</b>(<i>xh</i>, <i>yh</i>)                 <i>// recursive call; T(n/2)</i>
  let <i>b</i> := <b>multiply</b>(<i>xh</i>, <i>yl</i>)                 <i>// recursive call; T(n/2)</i>
  let <i>c</i> := <b>multiply</b>(<i>xl</i>, <i>yh</i>)                 <i>// recursive call; T(n/2)</i>
  let <i>d</i> := <b>multiply</b>(<i>xl</i>, <i>yl</i>)                 <i>// recursive call; T(n/2)</i>
  
  <i>b</i> := <b>add</b>(<i>b</i>, <i>c</i>)                            <i>// regular addition; O(n)</i>
  <i>a</i> := <b>shift</b>(<i>a</i>, <i>n</i>)                          <i>// pad on zeros; O(n)</i>
  <i>b</i> := <b>shift</b>(<i>b</i>, <i>n</i>/2)                        <i>// pad on zeros; O(n)</i>
  return <b>add</b>(<i>a</i>, <i>b</i>, <i>d</i>)                       <i>// regular addition; O(n)</i>
end
</pre>
<p>We can use the master theorem to analyze the running time of this algorithm. Assuming that the algorithm's running time is <img class="tex" alt="T(n)" src="//upload.wikimedia.org/math/5/1/4/514884be093e9ab7909b0d394e7b74d2.png" />, the comments show how much time each step takes. Because there are four recursive calls, each with an input of size <img class="tex" alt="n/2" src="//upload.wikimedia.org/math/a/2/f/a2f070a31330443ceb0dcf352fe50035.png" />, we have:</p>
<dl>
<dd><img class="tex" alt="T(n) = 4T(n/2) + O(n)" src="//upload.wikimedia.org/math/4/c/6/4c61b6c528f67b912518c7969afcaf72.png" /></dd>
</dl>
<p>Here, <img class="tex" alt="a=4, b=2, k=1" src="//upload.wikimedia.org/math/8/f/b/8fb390b1b471c382d30f1bee05731091.png" />, and given that <img class="tex" alt="4&gt;2^1" src="//upload.wikimedia.org/math/3/c/5/3c538367fc6b1b4730094c0f27fbcf56.png" /> we are in the "bottom heavy" case and thus plugging in these values into the bottom heavy case of the master theorem gives us:</p>
<dl>
<dd><img class="tex" alt="T(n)=O(n^{\log_2 4}) = O(n^2)." src="//upload.wikimedia.org/math/a/8/0/a8099bbfe928f65bd19d30753d12a48c.png" /></dd>
</dl>
<p>Thus, after all of that hard work, we're still no better off than the grade school algorithm! Luckily, numbers and polynomials are a data set we know additional information about. In fact, we can reduce the running time by doing some mathematical tricks.</p>
<p>First, let's replace the <img class="tex" alt="2^{n/2}" src="//upload.wikimedia.org/math/4/a/d/4addf4efa85422bf46470f4c8a39a260.png" /> with a variable, <i>z</i>:</p>
<dl>
<dd><img class="tex" alt="x\times y = x_h*y_h z^2 + (x_h*y_l + x_l*y_h)z + x_l*y_l" src="//upload.wikimedia.org/math/6/7/5/67523685a5432f740134b41a0fab0020.png" /></dd>
</dl>
<p>This appears to be a quadratic formula, and we know that you only need three co-efficients or points on a graph in order to uniquely describe a quadratic formula. However, in our above algorithm we've been using four multiplications total. Let's try recasting <img class="tex" alt="x" src="//upload.wikimedia.org/math/9/d/d/9dd4e461268c8034f5c8564e155c67a6.png" /> and <img class="tex" alt="y" src="//upload.wikimedia.org/math/4/1/5/415290769594460e2e485922904f345d.png" /> as linear functions:</p>
<dl>
<dd><img class="tex" alt="P_x(z) = x_h\cdot z + x_l" src="//upload.wikimedia.org/math/8/4/2/842944f091d992c6a8c4ebaf1722c417.png" /></dd>
<dd><img class="tex" alt="P_y(z) = y_h\cdot z + y_l" src="//upload.wikimedia.org/math/4/7/a/47af5f8bb624ab676323d5dfc314c864.png" /></dd>
</dl>
<p>Now, for <img class="tex" alt="x\times y" src="//upload.wikimedia.org/math/8/9/d/89df7401551d525a04db9dc12e4684ba.png" /> we just need to compute <img class="tex" alt="(P_x\cdot P_y)(2^{n/2})" src="//upload.wikimedia.org/math/a/d/0/ad093341e2145cdb4d083e35f1e5c636.png" />. We'll evaluate <img class="tex" alt="P_x(z)" src="//upload.wikimedia.org/math/c/3/e/c3eabb62407978ba0f90e3d5b82ebb92.png" /> and <img class="tex" alt="P_y(z)" src="//upload.wikimedia.org/math/6/0/2/6020abdcae8a0792c4d330ef653786cb.png" /> at three points. Three convenient points to evaluate the function will be at <img class="tex" alt="(P_x\cdot P_y)(1), (P_x\cdot P_y)(0), (P_x\cdot P_y)(-1)" src="//upload.wikimedia.org/math/8/4/1/841da1606b2cb5bb91bcda70f212db40.png" />:</p>
<p>[TODO: show how to make the two-parts breaking more efficient; then mention that the best multiplication uses the FFT, but don't actually cover that topic (which is saved for the advanced book)]</p>
<h2><span class="mw-headline" id="Base_Conversion">Base Conversion</span></h2>
<p>[TODO: Convert numbers from decimal to binary quickly using DnC.]</p>
<p>Along with the binary, the science of computers employs bases 8 and 16 for it's very easy to convert between the three while using bases 8 and 16 shortens considerably number representations.</p>
<p>To represent 8 first digits in the binary system we need 3 bits. Thus we have, 0=000, 1=001, 2=010, 3=011, 4=100, 5=101, 6=110, 7=111. Assume M=(2065)<sub>8</sub>. In order to obtain its binary representation, replace each of the four digits with the corresponding triple of bits: 010 000 110 101. After removing the leading zeros, binary representation is immediate: M=(10000110101)<sub>2</sub>. (For the hexadecimal system conversion is quite similar, except that now one should use 4-bit representation of numbers below 16.) This fact follows from the general conversion algorithm and the observation that 8=<img class="tex" alt="2^3" src="//upload.wikimedia.org/math/6/3/a/63a1e1a5a5a28b0cf5e7687836075240.png" /> (and, of course, 16=<img class="tex" alt="2^4" src="//upload.wikimedia.org/math/5/5/f/55fb55173e87cbecee6d8ae1616dc74c.png" />). Thus it appears that the shortest way to convert numbers into the binary system is to first convert them into either octal or hexadecimal representation. Now let see how to implement the general algorithm programmatically.</p>
<p>For the sake of reference, representation of a number in a system with base (radix) N may only consist of digits that are less than N.</p>
<p>More accurately, if</p>
<dl>
<dd><img class="tex" alt="(1) M = a_kN^k+a_{k-1}N^{k-1}+...+a_1N^1+a_0" src="//upload.wikimedia.org/math/d/2/c/d2c0912710e206b66c1d2f8f88e4d999.png" /></dd>
</dl>
<p>with <img class="tex" alt="0 &lt;= a_i &lt; N" src="//upload.wikimedia.org/math/e/7/f/e7fa931c3b9e0975737f7ec41ae98af8.png" /> we have a representation of M in base N system and write</p>
<dl>
<dd><img class="tex" alt="M = (a_ka_{k-1}...a_0)N" src="//upload.wikimedia.org/math/e/6/9/e697ac6c52214f8b69cc508e44cdcff7.png" /></dd>
</dl>
<p>If we rewrite (1) as</p>
<dl>
<dd><img class="tex" alt="(2) M = a_0+N*(a_1+N*(a_2+N*...))" src="//upload.wikimedia.org/math/2/e/9/2e97d6709796a736ee343df3b1ff26d2.png" /></dd>
</dl>
<p>the algorithm for obtaining coefficients ai becomes more obvious. For example, <img class="tex" alt="a_0=M\ modulo\ n" src="//upload.wikimedia.org/math/6/2/1/6213514d2ee8e332b5219f82f591eb48.png" /> and <img class="tex" alt="a_1=(M/N)\ modulo\ n" src="//upload.wikimedia.org/math/b/6/2/b62d8290b3587b53101ae00b2d979e92.png" />, and so on.</p>
<h3><span class="mw-headline" id="Recursive_Implementation">Recursive Implementation</span></h3>
<p>Let's represent the algorithm mnemonically: (result is a string or character variable where I shall accumulate the digits of the result one at a time)</p>
<pre>
result = "" 
if M &lt; N, result = 'M' + result. Stop. 
S = M mod N, result = 'S' + result
M = M/N 
goto 2 
</pre>
<p>A few words of explanation.</p>
<p>"" is an empty string. You may remember it's a zero element for string concatenation. Here we check whether the conversion procedure is over. It's over if M is less than N in which case M is a digit (with some qualification for N&gt;10) and no additional action is necessary. Just prepend it in front of all other digits obtained previously. The '+' plus sign stands for the string concatenation. If we got this far, M is not less than N. First we extract its remainder of division by N, prepend this digit to the result as described previously, and reassign M to be M/N. This says that the whole process should be repeated starting with step 2. I would like to have a function say called Conversion that takes two arguments M and N and returns representation of the number M in base N. The function might look like this</p>
<pre>
1 String Conversion(int M, int N) // return string, accept two integers 
2 {  
3     if (M &lt; N) // see if it's time to return 
4         return new String(""+M); // ""+M makes a string out of a digit 
5     else // the time is not yet ripe 
6         return Conversion(M/N, N) +
           new String(""+(M mod N)); // continue 
7 }  
</pre>
<p>This is virtually a working Java function and it would look very much the same in C++ and require only a slight modification for C. As you see, at some point the function calls itself with a different first argument. One may say that the function is defined in terms of itself. Such functions are called recursive. (The best known recursive function is factorial: n!=n*(n-1)!.) The function calls (applies) itself to its arguments, and then (naturally) applies itself to its new arguments, and then ... and so on. We can be sure that the process will eventually stop because the sequence of arguments (the first ones) is decreasing. Thus sooner or later the first argument will be less than the second and the process will start emerging from the recursion, still a step at a time.</p>
<h3><span class="mw-headline" id="Iterative_Implementation">Iterative Implementation</span></h3>
<p>Not all programming languages allow functions to call themselves recursively. Recursive functions may also be undesirable if process interruption might be expected for whatever reason. For example, in the Tower of Hanoi puzzle, the user may want to interrupt the demonstration being eager to test his or her understanding of the solution. There are complications due to the manner in which computers execute programs when one wishes to jump out of several levels of recursive calls.</p>
<p>Note however that the string produced by the conversion algorithm is obtained in the wrong order: all digits are computed first and then written into the string the last digit first. Recursive implementation easily got around this difficulty. With each invocation of the Conversion function, computer creates a new environment in which passed values of M, N, and the newly computed S are stored. Completing the function call, i.e. returning from the function we find the environment as it was before the call. Recursive functions store a sequence of computations implicitly. Eliminating recursive calls implies that we must manage to store the computed digits explicitly and then retrieve them in the reversed order.</p>
<p>In Computer Science such a mechanism is known as LIFO - Last In First Out. It's best implemented with a stack data structure. Stack admits only two operations: push and pop. Intuitively stack can be visualized as indeed a stack of objects. Objects are stacked on top of each other so that to retrieve an object one has to remove all the objects above the needed one. Obviously the only object available for immediate removal is the top one, i.e. the one that got on the stack last.</p>
<p>Then iterative implementation of the Conversion function might look as the following.</p>
<pre>
 1 String Conversion(int M, int N) // return string, accept two integers 
 2 {  
 3     Stack stack = new Stack(); // create a stack 
 4     while (M &gt;= N) // now the repetitive loop is clearly seen 
 5     {  
 6         stack.push(M mod N); // store a digit 
 7         M = M/N; // find new M 
 8     }  
 9     // now it's time to collect the digits together  
10     String str = new String(""+M); // create a string with a single digit M 
11     while (stack.NotEmpty())  
12         str = str+stack.pop() // get from the stack next digit 
13     return str;  
14 }  
</pre>
<p>The function is by far longer than its recursive counterpart; but, as I said, sometimes it's the one you want to use, and sometimes it's the only one you may actually use.</p>
<h2><span class="mw-headline" id="Closest_Pair_of_Points">Closest Pair of Points</span></h2>
<p>For a set of points on a two-dimensional plane, if you want to find the closest two points, you could compare all of them to each other, at <img class="tex" alt="O(n^2)" src="//upload.wikimedia.org/math/1/8/9/189317b4b935a745fcfaf95940d2b4f0.png" /> time, or use a divide and conquer algorithm.</p>
<p>[TODO: explain the algorithm, and show the n^2 algorithm]</p>
<p>[TODO: write the algorithm, include intuition, proof of correctness, and runtime analysis]</p>
<p>Use this link for the original document.</p>
<p><a rel="nofollow" class="external free" href="http://www.cs.mcgill.ca/~cs251/ClosestPair/ClosestPairDQ.html">http://www.cs.mcgill.ca/~cs251/ClosestPair/ClosestPairDQ.html</a></p>
<h2><span class="mw-headline" id="Closest_Pair:_A_Divide-and-Conquer_Approach">Closest Pair: A Divide-and-Conquer Approach</span></h2>
<h3><span class="mw-headline" id="Introduction_2">Introduction</span></h3>
<p>The brute force approach to the closest pair problem (i.e. checking every possible pair of points) takes quadratic time. We would now like to introduce a faster divide-and-conquer algorithm for solving the closest pair problem. Given a set of points in the plane S, our approach will be to split the set into two roughly equal halves (S1 and S2) for which we already have the solutions, and then to merge the halves in linear time to yield an O(nlogn) algorithm. However, the actual solution is far from obvious. It is possible that the desired pair might have one point in S1 and one in S2, does this not force us once again to check all possible pairs of points? The divide-and-conquer approach presented here generalizes directly from the one dimensional algorithm we presented in the previous section.</p>
<h3><span class="mw-headline" id="Closest_Pair_in_the_Plane">Closest Pair in the Plane</span></h3>
<p>Alright, we'll generalize our 1-D algorithm as directly as possible (see figure 3.2). Given a set of points S in the plane, we partition it into two subsets S1 and S2 by a vertical line l such that the points in S1 are to the left of l and those in S2 are to the right of l.</p>
<p>We now recursively solve the problem on these two sets obtaining minimum distances of d1 (for S1), and d2 (for S2). We let d be the minimum of these.</p>
<p>Now, identical to the 1-D case, if the closes pair of the whole set consists of one point from each subset, then these two points must be within d of l. This area is represented as the two strips P1 and P2 on either side of l</p>
<p>Up to now, we are completely in step with the 1-D case. At this point, however, the extra dimension causes some problems. We wish to determine if some point in say P1 is less than d away from another point in P2. However, in the plane, we don't have the luxury that we had on the line when we observed that only one point in each set can be within d of the median. In fact, in two dimensions, all of the points could be in the strip! This is disastrous, because we would have to compare n2 pairs of points to merge the set, and hence our divide-and-conquer algorithm wouldn't save us anything in terms of efficiency. Thankfully, we can make another life saving observation at this point. For any particular point p in one strip, only points that meet the following constraints in the other strip need to be checked:</p>
<ul>
<li>those points within d of p in the direction of the other strip</li>
<li>those within d of p in the positive and negative y directions</li>
</ul>
<p>Simply because points outside of this bounding box cannot be less than d units from p (see figure 3.3). It just so happens that because every point in this box is at least d apart, there can be at most six points within it.</p>
<p>Now we don't need to check all n2 points. All we have to do is sort the points in the strip by their y-coordinates and scan the points in order, checking each point against a maximum of 6 of its neighbors. This means at most 6*n comparisons are required to check all candidate pairs. However, since we sorted the points in the strip by their y-coordinates the process of merging our two subsets is not linear, but in fact takes O(nlogn) time. Hence our full algorithm is not yet O(nlogn), but it is still an improvement on the quadratic performance of the brute force approach (as we shall see in the next section). In section 3.4, we will demonstrate how to make this algorithm even more efficient by strengthening our recursive sub-solution.</p>
<h3><span class="mw-headline" id="Summary_and_Analysis_of_the_2-D_Algorithm">Summary and Analysis of the 2-D Algorithm</span></h3>
<p>We present here a step by step summary of the algorithm presented in the previous section, followed by a performance analysis. The algorithm is simply written in list form because I find pseudo-code to be burdensome and unnecessary when trying to understand an algorithm. Note that we pre-sort the points according to their x coordinates, and maintain another structure which holds the points sorted by their y values(for step 4), which in itself takes O(nlogn) time.</p>
<p>ClosestPair of a set of points:</p>
<ol>
<li>Divide the set into two equal sized parts by the line l, and recursively compute the minimal distance in each part.</li>
<li>Let d be the minimal of the two minimal distances.</li>
<li>Eliminate points that lie farther than d apart from l.</li>
<li>Consider the remaining points according to their y-coordinates, which we have precomputed.</li>
<li>Scan the remaining points in the y order and compute the distances of each point to all of its neighbors that are distanced no more than d(that's why we need it sorted according to y). Note that there are no more than 5(there is no figure 3.3 , so this 5 or 6 doesnt make sense without that figure . Please include it .) such points(see previous section).</li>
<li>If any of these distances is less than d then update d.</li>
</ol>
<p>Analysis:</p>
<ul>
<li>Let us note T(n) as the efficiency of out algorithm</li>
<li>Step 1 takes 2T(n/2) (we apply our algorithm for both halves)</li>
<li>Step 3 takes O(n) time</li>
<li>Step 5 takes O(n) time (as we saw in the previous section)</li>
</ul>
<p>so,</p>
<p><img class="tex" alt="T(n) = 2T(n/2) + O(n)" src="//upload.wikimedia.org/math/2/7/a/27a628ce0934d40b979b734829102a48.png" /></p>
<p>which, according the Master Theorem, result</p>
<p><img class="tex" alt="T(n) \isin O(nlogn)" src="//upload.wikimedia.org/math/b/d/b/bdb5ce0b113654fea48e8dc8086c0d82.png" /></p>
<p>Hence the merging of the sub-solutions is dominated by the sorting at step 4, and hence takes O(nlogn) time.</p>
<p>This must be repeated once for each level of recursion in the divide-and-conquer algorithm,</p>
<p>hence the whole of algorithm ClosestPair takes O(logn*nlogn) = O(nlog2n) time.</p>
<h3><span class="mw-headline" id="Improving_the_Algorithm">Improving the Algorithm</span></h3>
<p>We can improve on this algorithm slightly by reducing the time it takes to achieve the y-coordinate sorting in Step 4. This is done by asking that the recursive solution computed in Step 1 returns the points in sorted order by their y coordinates. This will yield two sorted lists of points which need only be merged (a linear time operation) in Step 4 in order to yield a complete sorted list. Hence the revised algorithm involves making the following changes: Step 1: Divide the set into..., and recursively compute the distance in each part, returning the points in each set in sorted order by y-coordinate. Step 4: Merge the two sorted lists into one sorted list in O(n) time. Hence the merging process is now dominated by the linear time steps thereby yielding an O(nlogn) algorithm for finding the closest pair of a set of points in the plane.</p>
<h2><span class="mw-headline" id="Towers_Of_Hanoi_Problem">Towers Of Hanoi Problem</span></h2>
<p>[TODO: Write about the towers of hanoi algorithm and a program for it]</p>
<p>There are n distinct sized discs and three pegs such that discs are placed at the left peg in the order of their sizes. The smallest one is at the top while the largest one is at the bottom. This game is to move all the discs from the left peg</p>
<h3><span class="mw-headline" id="Rules">Rules</span></h3>
<p>1) Only one disc can be moved in each step.</p>
<p>2) Only the disc at the top can be moved.</p>
<p>3) Any disc can only be placed on the top of a larger disc.</p>
<h3><span class="mw-headline" id="Solution">Solution</span></h3>
<h4><span class="mw-headline" id="Intuitive_Idea">Intuitive Idea</span></h4>
<p>In order to move the largest disc from the left peg to the middle peg, the smallest discs must be moved to the right peg first. After the largest one is moved. The smaller discs are then moved from the right peg to the middle peg.</p>
<h4><span class="mw-headline" id="Recurrence">Recurrence</span></h4>
<p>Suppose n is the number of discs.</p>
<p>To move n discs from peg a to peg b,</p>
<p>1) If n&gt;1 then move n-1 discs from peg a to peg c</p>
<p>2) Move n-th disc from peg a to peg b</p>
<p>3) If n&gt;1 then move n-1 discs from peg c to peg a</p>
<h4><span class="mw-headline" id="Pseudocode">Pseudocode</span></h4>
<pre>
void hanoi(n,src,dst){
  if (n&gt;1)
    hanoi(n-1,src,pegs-{src,dst});
  print "move n-th disc from src to dst";
  if (n&gt;1)
    hanoi(n-1,pegs-{src,dst},dst);
}
</pre>
<h4><span class="mw-headline" id="Analysis_2">Analysis</span></h4>
<p>The analysis is trivial. <img class="tex" alt=" T(n) = 2T(n-1) + O(1) = O(2^n)" src="//upload.wikimedia.org/math/2/5/1/25167f223a9c315d4061359514e6b5e2.png" /></p>
<p><br /></p>
<h1><span class="mw-headline" id="Randomization">Randomization</span></h1>
<p>As deterministic algorithms are driven to their limits when one tries to solve hard problems with them, a useful technique to speed up the computation is <b>randomization</b>. In randomized algorithms, the algorithm has access to a <i>random source</i>, which can be imagined as tossing coins during the computation. Depending on the outcome of the toss, the algorithm may split up its computation path.</p>
<p>There are two main types of randomized algorithms: Las Vegas algorithms and Monte-Carlo algorithms. In Las Vegas algorithms, the algorithm may use the randomness to speed up the computation, but the algorithm must always return the correct answer to the input. Monte-Carlo algorithms do not have the former restriction, that is, they are allowed to give <i>wrong</i> return values. However, returning a wrong return value must have a <i>small probability</i>, otherwise that Monte-Carlo algorithm would not be of any use.</p>
<p>Many approximation algorithms use randomization.</p>
<h2><span class="mw-headline" id="Ordered_Statistics">Ordered Statistics</span></h2>
<p>Before covering randomized techniques, we'll start with a deterministic problem that leads to a problem that utilizes randomization. Suppose you have an unsorted array of values and you want to find</p>
<ul>
<li>the maximum value,</li>
<li>the minimum value, and</li>
<li>the median value.</li>
</ul>
<p>In the immortal words of one of our former computer science professors, "How can you do?"</p>
<h3><span class="mw-headline" id="find-max">find-max</span></h3>
<p>First, it's relatively straightforward to find the largest element:</p>
<pre>
<i>// find-max -- returns the maximum element</i>
function <b>find-max</b>(array <i>vals</i>[1..<i>n</i>]): element
  let <i>result</i> := <i>vals[1]</i>
  for <i>i</i> from <i>2</i> to <i>n</i>:
    <i>result</i> := max(<i>result</i>, <i>vals[i]</i>)
  repeat
  
  return <i>result</i>
end
</pre>
<p>An initial assignment of <img class="tex" alt="-\infty" src="//upload.wikimedia.org/math/b/e/a/beab416080922c84a90ba092f7734fe5.png" /> to <i>result</i> would work as well, but this is a useless call to the max function since the first element compared gets set to <i>result</i>. By initializing result as such the function only requires <i>n-1</i> comparisons. (Moreover, in languages capable of metaprogramming, the data type may not be strictly numerical and there might be no good way of assigning <img class="tex" alt="-\infty" src="//upload.wikimedia.org/math/b/e/a/beab416080922c84a90ba092f7734fe5.png" />; using vals[1] is type-safe.)</p>
<p>A similar routine to find the minimum element can be done by calling the min function instead of the max function.</p>
<h3><span class="mw-headline" id="find-min-max">find-min-max</span></h3>
<p>But now suppose you want to find the min and the max at the same time; here's one solution:</p>
<pre>
<i>// find-min-max -- returns the minimum and maximum element of the given array</i>
function <b>find-min-max</b>(array <i>vals</i>): pair
  return pair {<b>find-min</b>(<i>vals</i>), <b>find-max</b>(<i>vals</i>)}
end
</pre>
<p>Because <b>find-max</b> and <b>find-min</b> both make <i>n-1</i> calls to the max or min functions (when <i>vals</i> has <i>n</i> elements), the total number of comparisons made in <b>find-min-max</b> is <img class="tex" alt="2n-2" src="//upload.wikimedia.org/math/3/3/1/3317d29db4b05b3d1136a5f75203de3e.png" />.</p>
<p>However, some redundant comparisons are being made. These redundancies can be removed by "weaving" together the min and max functions:</p>
<pre>
<i>// find-min-max -- returns the minimum and maximum element of the given array</i>
function <b>find-min-max</b>(array <i>vals</i>[1..<i>n</i>]): pair
  let <i>min</i> := <img class="tex" alt="\infty" src="//upload.wikimedia.org/math/d/2/4/d245777abca64ece2d5d7ca0d19fddb6.png" />
  let <i>max</i> := <img class="tex" alt="-\infty" src="//upload.wikimedia.org/math/b/e/a/beab416080922c84a90ba092f7734fe5.png" />
  
  if <i>n</i> is odd:
    <i>min</i> := <i>max</i> := <i>vals</i>[1]
    <i>vals</i> := <i>vals</i>[2,..,<i>n</i>]          <i>// we can now assume n is even</i>
    <i>n</i> := <i>n</i> - 1
  fi
  
  for <i>i</i>:=1 to <i>n</i> by 2:             <i>// consider pairs of values in vals</i>
    if <i>vals</i>[<i>i</i>] &lt; <i>vals</i>[<i>i</i> + <i>n</i> by 2]:
      let <i>a</i> := <i>vals</i>[<i>i</i>]
      let <i>b</i> := <i>vals</i>[<i>i</i> + <i>n</i> by 2]
    else:
      let <i>a</i> := <i>vals</i>[<i>i</i> + <i>n</i> by 2]
      let <i>b</i> := <i>vals</i>[<i>i</i>]            <i>// invariant: a &lt;= b</i>
    fi
    
    if <i>a</i> &lt; <i>min</i>: <i>min</i> := <i>a</i> fi
    if <i>b</i> &gt; <i>max</i>: <i>max</i> := <i>b</i> fi
  repeat
  
  return pair {<i>min</i>, <i>max</i>}
end
</pre>
<p>Here, we only loop <img class="tex" alt="n/2" src="//upload.wikimedia.org/math/a/2/f/a2f070a31330443ceb0dcf352fe50035.png" /> times instead of <i>n</i> times, but for each iteration we make three comparisons. Thus, the number of comparisons made is <img class="tex" alt="(3/2)n = 1.5n" src="//upload.wikimedia.org/math/9/9/7/9979b58480ac5dac2ec8d9cd4dd2a940.png" />, resulting in a <img class="tex" alt="3/4" src="//upload.wikimedia.org/math/4/0/7/40735ef69decd7cebd3e8be7cc186c8f.png" /> speed up over the original algorithm.</p>
<p>Only three comparisons need to be made instead of four because, by construction, it's always the case that <img class="tex" alt="a\le b" src="//upload.wikimedia.org/math/d/7/3/d7356d20677cd7949b92ae77480fe9fe.png" />. (In the first part of the "if", we actually know more specifically that <img class="tex" alt="a &lt; b" src="//upload.wikimedia.org/math/1/a/3/1a382af93ed4b8a29ebd8e859a0168d7.png" />, but under the else part, we can only conclude that <img class="tex" alt="a\le b" src="//upload.wikimedia.org/math/d/7/3/d7356d20677cd7949b92ae77480fe9fe.png" />.) This property is utilized by noting that <i>a</i> doesn't need to be compared with the current maximum, because <i>b</i> is already greater than or equal to <i>a</i>, and similarly, <i>b</i> doesn't need to be compared with the current minimum, because <i>a</i> is already less than or equal to <i>b</i>.</p>
<p>In software engineering, there is a struggle between using libraries versus writing customized algorithms. In this case, the min and max functions weren't used in order to get a faster <b>find-min-max</b> routine. Such an operation would probably not be the bottleneck in a real-life program: however, if testing reveals the routine should be faster, such an approach should be taken. Typically, the solution that reuses libraries is better overall than writing customized solutions. Techniques such as open implementation and aspect-oriented programming may help manage this contention to get the best of both worlds, but regardless it's a useful distinction to recognize.</p>
<h3><span class="mw-headline" id="find-median">find-median</span></h3>
<p>Finally, we need to consider how to find the median value. One approach is to sort the array then extract the median from the position <tt><i>vals</i>[<i>n</i>/2]</tt>:</p>
<pre>
<i>// find-median -- returns the median element of vals</i>
function <b>find-median</b>(array <i>vals</i>[1..<i>n</i>]): element
  assert (<i>n</i> &gt; 0)
  
  sort(<i>vals</i>)
  return <i>vals</i>[<i>n</i> / 2]
end
</pre>
<p>If our values are not numbers close enough in value (or otherwise cannot be sorted by a radix sort) the sort above is going to require <img class="tex" alt="O(n\log n)" src="//upload.wikimedia.org/math/f/4/9/f49341ab621f12e8cb93d0146ea51d34.png" /> steps.</p>
<p>However, it is possible to extract the <i>n</i>th-ordered statistic in <img class="tex" alt="O(n)" src="//upload.wikimedia.org/math/7/b/a/7ba55e7c64a9405a0b39a1107e90ca94.png" /> time. The key is eliminating the sort: we don't actually require the entire array to be sorted in order to find the median, so there is some waste in sorting the entire array first. One technique we'll use to accomplish this is randomness.</p>
<p>Before presenting a non-sorting <b>find-median</b> function, we introduce a divide and conquer-style operation known as <b>partitioning</b>. What we want is a routine that finds a random element in the array and then partitions the array into three parts:</p>
<ol>
<li>elements that are less than or equal to the random element;</li>
<li>elements that are equal to the random element; and</li>
<li>elements that are greater than or equal to the random element.</li>
</ol>
<p>These three sections are denoted by two integers: <i>j</i> and <i>i</i>. The partitioning is performed "in place" in the array:</p>
<pre>
<i>// partition -- break the array three partitions based on a randomly picked element</i>
function <b>partition</b>(array <i>vals</i>): pair{<i>j</i>, <i>i</i>}
</pre>
<p>Note that when the random element picked is actually represented three or more times in the array it's possible for entries in all three partitions to have the same value as the random element. While this operation may not sound very useful, it has a powerful property that can be exploited: When the partition operation completes, the randomly picked element will be in the same position in the array as it would be if the array were fully sorted!</p>
<p>This property might not sound so powerful, but recall the optimization for the <b>find-min-max</b> function: we noticed that by picking elements from the array in pairs and comparing them to each other first we could reduce the total number of comparisons needed (because the current min and max values need to be compared with only one value each, and not two). A similar concept is used here.</p>
<p>While the code for <b>partition</b> is not magical, it has some tricky boundary cases:</p>
<pre>
<i>// partition -- break the array into three ordered partitions from a random element</i>
function <b>partition</b>(array <i>vals</i>): pair{<i>j</i>, <i>i</i>}
  let <i>m</i> := 0
  let <i>n</i> := <i>vals</i>.length - 2   //  for an array vals, vals[vals.length-1] is the last element, which holds the partition, 
                                     // so the last sort element is vals[vals.length-2]
  let <i>irand</i> := random(<i>m</i>, <i>n</i>)   <i>// returns any value from m to n</i>
  let <i>x</i> := <i>vals</i>[<i>irand</i>]
  swap( <i>irand</i>,<i>n</i>+ 1 ) // n+1 = vals.length-1 , which is the right most element, and acts as store for partition element and sentinel for m
  // values in <i>vals</i>[<i>n</i>..] are greater than <i>x</i>
  // values in <i>vals</i>[0..<i>m</i>] are less than <i>x</i>
  while (m &lt;= n  ) // see explanation in quick sort why should be m &lt;= n instead of m &lt; n
                  // in the 2 element case, vals.length -2 = 0 = n = m, but if the 2-element case is out-of-order vs. in-order, there must be a different action.
                  // by implication, the different action occurs within this loop, so must process the m = n case before exiting.
     while <i>vals</i>[<i>m</i>] &lt;= <i>x</i>  // in the 2-element case, second element is partition, first element at m. If in-order, m will increment
        <i>m</i>++
     endwhile
     while <i>x</i> &lt;  <i>vals</i>[<i>n</i>] &amp;&amp; <i>n</i> &gt; 0   // stops if vals[n] belongs in left partition or hits start of array
        <i>n</i>--
     endwhile
     if ( m &gt;= n) break;
     swap(<i>m</i>,<i>n</i>)                // exchange <i>vals</i>[<i>n</i>] and <i>vals</i>[<i>m</i>]
     <i>m</i>++   // don't rescan swapped elements
     <i>n</i>--
     
  endwhile
  // partition: [0..<i>m</i>-1]   []   [<i>n</i>+1..]   note that <i>m</i>=<i>n</i>+1
  // if you need non empty sub-arrays:
  swap(<i>m</i>,<i>vals</i>.length - 1)  // put the partition element in the between left and right partitions
                                   // in 2-element out-of-order case, m=0 (not incremented in loop), and the first and last(second) element will swap.
  // partition: [0..<i>n</i>-1]   [<i>n</i>..<i>n</i>]   [<i>n</i>+1..]
end
</pre>
<p>We can use <b>partition</b> as a subroutine for a general <b>find</b> operation:</p>
<pre>
<i>// find -- moves elements in vals such that location k holds the value it would when sorted</i>
function <b>find</b>(array <i>vals</i>, integer <i>k</i>)
  assert (0 &lt;= <i>k</i> &lt; <i>vals</i>.length)        <i>// k it must be a valid index</i>
  if <i>vals</i>.length &lt;= 1:
    return
  fi
  
  let pair (<i>j</i>, <i>i</i>) := <b>partition</b>(<i>vals</i>)
  if <i>k</i> &lt;= <i>i</i>:
    <b>find</b>(<i>a</i>[0,..,<i>i</i>], <i>k</i>)
  else-if <i>j</i> &lt;= <i>k</i>:
    <b>find</b>(<i>a</i>[<i>j</i>,..,<i>n</i>], <i>k</i> - <i>j</i>)
  fi
  TODO: debug this!
end
</pre>
<p>Which leads us to the punch-line:</p>
<pre>
 <i>// find-median -- returns the median element of vals</i>
function <b>find-median</b>(array <i>vals</i>): element
  assert (<i>vals</i>.length &gt; 0)
  
  let <i>median_index</i> := <i>vals</i>.length / 2;
  <b>find</b>(<i>vals</i>, <i>median_index</i>)
  return <i>vals</i>[<i>median_index</i>]
end
</pre>
<p>One consideration that might cross your mind is "is the random call really necessary?" For example, instead of picking a random pivot, we could always pick the middle element instead. Given that our algorithm works with all possible arrays, we could conclude that the running time on average for <i>all of the possible inputs</i> is the same as our analysis that used the random function. The reasoning here is that under the set of all possible arrays, the middle element is going to be just as "random" as picking anything else. But there's a pitfall in this reasoning: Typically, the input to an algorithm in a program isn't random at all. For example, the input has a higher probability of being sorted than just by chance alone. Likewise, because it is real data from real programs, the data might have other patterns in it that could lead to suboptimal results.</p>
<p>To put this another way: for the randomized median finding algorithm, there is a very small probability it will run suboptimally, independent of what the input is; while for a deterministic algorithm that just picks the middle element, there is a greater chance it will run poorly on some of the most frequent input types it will receive. This leads us to the following guideline:</p>
<table width="80%">
<tr>
<td style="background-color: #FFFFEE; border: solid 1px #FFC92E; padding: 1em;" valign="top"><b>Randomization Guideline:</b><br />
If your algorithm depends upon randomness, be sure you introduce the randomness yourself instead of depending upon the data to be random.</td>
</tr>
</table>
<p>Note that there are "derandomization" techniques that can take an average-case fast algorithm and turn it into a fully deterministic algorithm. Sometimes the overhead of derandomization is so much that it requires very large datasets to get any gains. Nevertheless, derandomization in itself has theoretical value.</p>
<p>The randomized <b>find</b> algorithm was invented by C. A. R. "Tony" Hoare. While Hoare is an important figure in computer science, he may be best known in general circles for his quicksort algorithm, which we discuss in the next section.</p>
<h2><span class="mw-headline" id="Quicksort">Quicksort</span></h2>
<p>The median-finding partitioning algorithm in the previous section is actually very close to the implementation of a full blown sorting algorithm. Building a Quicksort Algorithm is left as an exercise for the reader, and is recommended first, before reading the next section ( Quick sort is diabolical compared to Merge sort, which is a sort not improved by a randomization step ) .</p>
<p>A key part of quick sort is choosing the right median. But to get it up and running quickly, start with the assumption that the array is unsorted, and the rightmost element of each array is as likely to be the median as any other element, and that we are entirely optimistic that the rightmost doesn't happen to be the largest key , which would mean we would be removing one element only ( the partition element) at each step, and having no right array to sort, and a n-1 left array to sort.</p>
<p>This is where <b>randomization</b> is important for quick sort, i.e. <i>choosing the more optimal partition key</i>, which is pretty important for quick sort to work efficiently.</p>
<p>Compare the number of comparisions that are required for quick sort vs. insertion sort.</p>
<p>With insertion sort, the average number of comparisons for finding the lowest first element in an ascending sort of a randomized array is n /2 .</p>
<p>The second element's average number of comparisons is (n-1)/2;</p>
<p>the third element ( n- 2) / 2.</p>
<p>The total number of comparisons is [ n + (n - 1) + (n - 2) + (n - 3) .. + (n - [n-1]) ] divided by 2, which is [ n x n - (n-1)! ] /2 or about O(n squared) .</p>
<p>In Quicksort, the number of comparisons will halve at each partition step if the true median is chosen, since the left half partition doesn't need to be compared with the right half partition, but at each step , the number elements of all partitions created by the previously level of partitioning will still be n.</p>
<p>The number of levels of comparing n elements is the number of steps of dividing n by two , until n = 1. Or in reverse, 2 ^ m ~ n, so m = log<sub>2</sub> n.</p>
<p>So the total number of comparisons is n (elements) x m (levels of scanning) or n x log<sub>2</sub>n ,</p>
<p>So the number of comparison is O(n x log <sub>2</sub>(n) ) , which is smaller than insertion sort's O(n^2) or O( n x n ).</p>
<p>(Comparing O(n x log <sub>2</sub>(n) ) with O( n x n ) , the common factor n can be eliminated , and the comparison is log<sub>2</sub>(n) vs n , which is exponentially different as n becomes larger. e.g. compare n = 2^16 , or 16 vs 32768, or 32 vs 4 gig ).</p>
<p>To implement the partitioning in-place on a part of the array determined by a previous recursive call, what is needed a scan from each end of the part , swapping whenever the value of the left scan's current location is greater than the partition value, and the value of the right scan's current location is less than the partition value. So the initial step is&#160;:-</p>
<pre>
 Assign the partition value to the right most element, swapping if necessary.
</pre>
<p>So the partitioning step is&#160;:-</p>
<pre>
 increment the left scan pointer while the current value is less than the partition value.
 decrement the right scan pointer while the current value is more than the partition value , 
 or the location is equal to or more than the left most location.
 exit if the pointers have crossed ( l &gt;= r), 
 OTHERWISE
 perform a swap where the left and right pointers have stopped ,
 on values where the left pointer's value is greater than the partition,
 and the right pointer's value is less than the partition.

 Finally, after exiting the loop because the left and right pointers  have crossed,
 <i>swap the </i>rightmost<i> partition value, </i>
 with the last location of the <b>left</b> forward scan pointer <i>,   </i>
 and hence ends up between the left and right partitions. 
</pre>
<p>Make sure at this point , that after the final swap, the cases of a 2 element in-order array, and a 2 element out-of-order array , are handled correctly, which should mean all cases are handled correctly. This is a good debugging step for getting quick-sort to work.</p>
<p><b>For the in-order two-element case</b>, the left pointer stops on the partition or second element , as the partition value is found. The right pointer , scanning backwards, starts on the first element before the partition, and stops because it is in the leftmost position.</p>
<p>The pointers cross, and the loop exits before doing a loop swap. Outside the loop, the contents of the left pointer at the rightmost position and the partition , also at the right most position , are swapped, achieving no change to the in-order two-element case.</p>
<p><b>For the out-of-order two-element case</b>, The left pointer scans and stops at the first element, because it is greater than the partition (left scan value stops to swap values greater than the partition value).</p>
<p>The right pointer starts and stops at the first element because it has reached the leftmost element.</p>
<p>The loop exits because left pointer and right pointer are equal at the first position, and the contents of the left pointer at the first position and the partition at the rightmost (other) position , are swapped , putting previously out-of-order elements , into order.</p>
<p>Another implementation issue, is to how to move the pointers during scanning. Moving them at the end of the outer loop seems logical.</p>
<pre>
partition(a,l,r) {
  v = a[r];
  i = l;
  j = r -1;
 while ( i &lt;= j ) {  // need to also scan when i = j as well as i &lt; j , 
                           // in the 2 in-order case, 
                           // so that i is incremented to the  partition 
                           // and nothing happens in the final swap with the partition at r.
    while ( a[i] &lt; v) ++i;
    while ( v &lt;= a[j] &amp;&amp; j &gt; 0  ) --j;
    if ( i &gt;= j) break;
    swap(a,i,j);
    ++i; --j;
 }
 swap(a, i, r);
 return i;
</pre>
<p>With the pre-increment/decrement unary operators, scanning can be done just before testing within the test condition of the while loops, but this means the pointers should be offset -1 and +1 respectively at the start&#160;: so the algorithm then looks like:-</p>
<pre>
partition (a, l, r ) {
 v=a[r]; // v is partition value, at a[r]
 i=l-1;
 j=r;
 while(true) {
  while(  a[++i] &lt; v ); 
  while( v &lt;= a[--j]  &amp;&amp; j &gt; l );
  if (i &gt;= j) break;
  swap ( a, i, j);
 }
 swap (a,i,r);
 return i;
}
</pre>
<p>And the qsort algorithm is</p>
<pre>
qsort( a, l, r)  {
  if (l &gt;= r) return ;
  p = partition(a, l, r)
  qsort(a , l, p-1)
  qsort( a, p+1, r)
</pre>
<p>}</p>
<p>Finally, randomization of the partition element.</p>
<pre>
random_partition (a,l,r) {
 p = random_int( r-l) + l;
 // median of a[l], a[p] , a[r]
 if (a[p] &lt; a[l]) p =l;
 if ( a[r]&lt; a[p]) p = r;
 swap(a, p, r);
}
</pre>
<p>this can be called just before calling partition in qsort().</p>
<h2><span class="mw-headline" id="Shuffling_an_Array">Shuffling an Array</span></h2>
<pre>
  <b>This keeps data in during shuffle</b>
  temporaryArray = { }
  <b>This records if an item has been shuffled</b>
  usedItemArray = { }
  <b>Number of item in array</b>
  itemNum = 0
  while ( itemNum != lengthOf( inputArray) ){
      usedItemArray[ itemNum ] = false <b>None of the items have been shuffled</b>
      itemNum = itemNum + 1
  }
  itemNum = 0 <b>we'll use this again</b>
  itemPosition = randdomNumber( 0 --- (lengthOf(inputArray) - 1 ))
  while( itemNum != lengthOf( inputArray ) ){
      while( usedItemArray[ itemPosition ] != false ){
          itemPosition = randdomNumber( 0 --- (lengthOf(inputArray) - 1 ))
      }
      temporaryArray[ itemPosition ] = inputArray[ itemNum ]
      itemNum = itemNum + 1
  }
  inputArray = temporaryArray
</pre>
<h2><span class="mw-headline" id="Equal_Multivariate_Polynomials">Equal Multivariate Polynomials</span></h2>
<p>[TODO: as of now, there is no known deterministic polynomial time solution, but there is a randomized polytime solution. The canonical example used to be IsPrime, but a deterministic, polytime solution has been found.]</p>
<h2><span class="mw-headline" id="Hash_tables">Hash tables</span></h2>
<p>Hashing relies on a hashcode function to randomly distribute keys to available slots evenly. In java , this is done in a fairly straight forward method of adding a moderate sized prime number (31 * 17 ) to a integer key , and then modulus by the size of the hash table. For string keys, the initial hash number is obtained by adding the products of each character's ordinal value multiplied by 31.</p>
<p>The wikibook Data Structures/Hash Tables chapter covers the topic well.</p>
<h2><span class="mw-headline" id="Skip_Lists">Skip Lists</span></h2>
<p>[TODO: Talk about skips lists. The point is to show how randomization can sometimes make a structure easier to understand, compared to the complexity of balanced trees.]</p>
<p>Dictionary or Map , is a general concept where a value is inserted under some key, and retrieved by the key. For instance, in some languages , the dictionary concept is built-in (Python), in others , it is in core libraries ( C++ S.T.L. , and Java standard collections library ). The library providing languages usually lets the programmer choose between a hash algorithm, or a balanced binary tree implementation (red-black trees). Recently, skip lists have been offered, because they offer advantages of being implemented to be highly concurrent for multiple threaded applications.</p>
<p>Hashing is a technique that depends on the randomness of keys when passed through a hash function, to find a hash value that corresponds to an index into a linear table. Hashing works as fast as the hash function, but works well only if the inserted keys spread out evenly in the array, as any keys that hash to the same index , have to be deal with as a hash collision problem e.g. by keeping a linked list for collisions for each slot in the table, and iterating through the list to compare the full key of each key-value pair vs the search key.</p>
<p>The disadvantage of hashing is that in-order traversal is not possible with this data structure.</p>
<p>Binary trees can be used to represent dictionaries, and in-order traversal of binary trees is possible by visiting of nodes ( visit left child, visit current node, visit right child, recursively ). Binary trees can suffer from poor search when they are "unbalanced" e.g. the keys of key-value pairs that are inserted were inserted in ascending or descending order, so they effectively look like <i>linked lists</i> with no left child, and all right children. <i>self-balancing</i> binary trees can be done probabilistically (using randomness) or deterministically ( using child link coloring as red or black ) , through local 3-node tree <b>rotation</b> operations. A rotation is simply swapping a parent with a child node, but preserving order e.g. for a left child rotation, the left child's right child becomes the parent's left child, and the parent becomes the left child's right child.</p>
<p><b>Splay trees</b> are a random application of rotations during a search , so that a lopsided tree structure is randomized into a balanced one.</p>
<p><b>Red-black trees</b> can be understood more easily if corresponding <b>2-3-4 trees</b> are examined. A 2-3-4 tree is a tree where nodes can have 2 children, 3 children, or 4 children, with 3 children nodes having 2 keys between the 3 children, and 4 children-nodes having 3 keys between the 4 children. 4-nodes are actively split into 3 single key 2 -nodes, and the middle 2-node passed up to be merged with the parent node , which , if a one-key 2-node, becomes a two key 3-node; or if a two key 3-node, becomes a 4-node, which will be later split (on the way up). The act of splitting a three key 4-node is actually a re-balancing operation, that prevents a string of 3 nodes of grandparent, parent , child occurring , without a balancing rotation happening. 2-3-4 trees are a limited example of <b>B-trees</b>, which usually have enough nodes as to fit a physical disk block, to facilitate caching of very large indexes that can't fit in physical RAM ( which is much less common nowadays).</p>
<p>A <b>red-black tree</b> is a binary tree representation of a 2-3-4 tree, where 3-nodes are modeled by a parent with one red child, and 4 -nodes modeled by a parent with two red children. Splitting of a 4-node is represented by the parent with 2 red children, <b>flipping</b> the red children to black, and itself into red. There is never a case where the parent is already red, because there also occurs balancing operations where if there is a grandparent with a red parent with a red child , the grandparent is rotated to be a child of the parent, and parent is made black and the grandparent is made red; this unifies with the previous <b>flipping</b> scenario, of a 4-node represented by 2 red children. Actually, it may be this standardization of 4-nodes with mandatory rotation of skewed or zigzag 4-nodes that results in re-balancing of the binary tree.</p>
<p>A newer optimization is to left rotate any single right red child to a single left red child, so that only right rotation of left-skewed inline 4-nodes (3 red nodes inline ) would ever occur, simplifying the re-balancing code.</p>
<p><b>Skip lists</b> are modeled after single linked lists, except nodes are multilevel. Tall nodes are rarer, but the insert operation ensures nodes are connected at each level.</p>
<p>Implementation of skip lists requires creating randomly high multilevel nodes, and then inserting them.</p>
<p>Nodes are created using iteration of a random function where high level node occurs later in an iteration, and are rarer, because the iteration has survived a number of random thresholds (e.g. 0.5, if the random is between 0 and 1).</p>
<p>Insertion requires a temporary previous node array with the height of the generated inserting node. It is used to store the last pointer for a given level , which has a key less than the insertion key.</p>
<p>The scanning begins at the head of the skip list, at highest level of the head node, and proceeds across until a node is found with a key higher than the insertion key, and the previous pointer stored in the temporary previous node array. Then the next lower level is scanned from that node , and so on, walking zig-zag down, until the lowest level is reached.</p>
<p>Then a list insertion is done at each level of the temporary previous node array, so that the previous node's next node at each level is made the next node for that level for the inserting node, and the inserting node is made the previous node's next node.</p>
<p>Search involves iterating from the highest level of the head node to the lowest level, and scanning along the next pointer for each level until a node greater than the search key is found, moving down to the next level , and proceeding with the scan, until the higher keyed node at the lowest level has been found, or the search key found.</p>
<p>The creation of less frequent-when-taller , randomized height nodes, and the process of linking in all nodes at every level, is what gives skip lists their advantageous overall structure.</p>
<p>What follows is a implementation of skip lists in python.</p>
<div dir="ltr" class="mw-geshi mw-code mw-content-ltr">
<div class="python source-python">
<pre class="de1">
<span class="co1">#a python implementation of SkipLists, using references as pointers</span>
<span class="co1"># copyright 2013 , as much gnu as compatible with wikibooks</span>
<span class="co1"># as taken from reading pugh's paper , and sedgewick</span>
<span class="kw1">import</span> <span class="kw3">random</span> 
<span class="kw2">min</span> <span class="sy0">=</span> <span class="nu0">8</span>
thresh <span class="sy0">=</span> <span class="nu0">6</span>
SK_MAXV <span class="sy0">=</span> <span class="nu0">16</span>
<span class="kw1">class</span> SkNode:
  <span class="kw1">def</span> <span class="kw4">__init__</span><span class="br0">(</span><span class="kw2">self</span><span class="sy0">,</span> x<span class="sy0">,</span> v<span class="br0">)</span>:
	<span class="kw2">self</span>.<span class="me1">ht</span> <span class="sy0">=</span> SK_MAXV
  	<span class="kw1">for</span> i <span class="kw1">in</span> <span class="kw2">xrange</span><span class="br0">(</span><span class="nu0">1</span><span class="sy0">,</span>SK_MAXV<span class="br0">)</span>:
	  <span class="kw1">if</span> <span class="kw3">random</span>.<span class="me1">randint</span><span class="br0">(</span><span class="nu0">0</span><span class="sy0">,</span><span class="nu0">10</span><span class="br0">)</span> <span class="sy0">&lt;</span> <span class="nu0">5</span>:
  	    <span class="kw2">self</span>.<span class="me1">ht</span> <span class="sy0">=</span> i
            <span class="kw1">break</span>
        <span class="kw2">self</span>.<span class="me1">next</span> <span class="sy0">=</span> <span class="br0">[</span><span class="kw2">None</span><span class="br0">]</span> * <span class="kw2">self</span>.<span class="me1">ht</span>
        <span class="kw2">self</span>.<span class="me1">v</span> <span class="sy0">=</span> v 
	<span class="kw2">self</span>.<span class="me1">x</span> <span class="sy0">=</span> x
 
  <span class="kw1">def</span> increase_ht<span class="br0">(</span><span class="kw2">self</span><span class="sy0">,</span> h<span class="br0">)</span>:
	<span class="kw2">self</span>.<span class="me1">next</span>.<span class="me1">extend</span><span class="br0">(</span> <span class="br0">[</span><span class="kw2">None</span><span class="br0">]</span> * <span class="br0">(</span>h - <span class="kw2">self</span>.<span class="me1">ht</span><span class="br0">)</span><span class="br0">)</span>
        <span class="kw2">self</span>.<span class="me1">ht</span> <span class="sy0">=</span> h
 
<span class="kw1">class</span> SkipList:
 
  <span class="kw1">def</span> <span class="kw4">__init__</span><span class="br0">(</span><span class="kw2">self</span> <span class="br0">)</span>:
    <span class="kw2">self</span>.<span class="me1">head</span> <span class="sy0">=</span> <span class="kw2">None</span> 
    <span class="kw2">self</span>.<span class="me1">level</span> <span class="sy0">=</span> <span class="nu0">0</span>
 
  <span class="kw1">def</span> insert<span class="br0">(</span><span class="kw2">self</span><span class="sy0">,</span> x<span class="sy0">,</span> v<span class="br0">)</span>:
    n <span class="sy0">=</span> SkNode<span class="br0">(</span>x<span class="sy0">,</span> v<span class="br0">)</span> 	 
    <span class="kw1">if</span> <span class="kw2">self</span>.<span class="me1">head</span> <span class="kw1">is</span> <span class="kw2">None</span>:
      <span class="kw2">self</span>.<span class="me1">head</span> <span class="sy0">=</span> n
    <span class="kw1">else</span>:
      <span class="kw1">if</span> n.<span class="me1">ht</span> <span class="sy0">&gt;</span> <span class="kw2">self</span>.<span class="me1">head</span>.<span class="me1">ht</span>:
        <span class="kw2">self</span>.<span class="me1">head</span>.<span class="me1">increase_ht</span><span class="br0">(</span>n.<span class="me1">ht</span><span class="br0">)</span>   
 
      <span class="kw1">if</span> x <span class="sy0">&lt;</span> <span class="kw2">self</span>.<span class="me1">head</span>.<span class="me1">x</span>:  
        <span class="co1"># the key is less than the head's key, replace the head</span>
	<span class="kw1">for</span> j <span class="kw1">in</span> <span class="kw2">xrange</span><span class="br0">(</span><span class="nu0">0</span><span class="sy0">,</span>n.<span class="me1">ht</span><span class="br0">)</span>:
		n.<span class="me1">next</span><span class="br0">[</span>i<span class="br0">]</span> <span class="sy0">=</span> <span class="kw2">self</span>.<span class="me1">head</span>
        <span class="kw2">self</span>.<span class="me1">head</span> <span class="sy0">=</span> n
      <span class="kw1">else</span>:
        prev <span class="sy0">=</span> <span class="kw2">self</span>.<span class="me1">head</span>
 
        <span class="co1">#last holds the previous node for each level</span>
	last <span class="sy0">=</span> <span class="br0">[</span><span class="kw2">None</span><span class="br0">]</span>* <span class="kw2">self</span>.<span class="me1">head</span>.<span class="me1">ht</span> 
 
        <span class="co1"># starts at ht-1, scans to 0, stepping down ; this is "skipping" at higher j</span>
        <span class="co1"># when j = 0, the lowest level,  there is no skipping , and every next node is traversed.</span>
        <span class="co1"># tall nodes are less frequently inserted, and links between taller nodes at higher j skip over more</span>
        <span class="co1"># more frequent shorter nodes.</span>
        <span class="kw1">for</span> j <span class="kw1">in</span> <span class="kw2">xrange</span><span class="br0">(</span> <span class="kw2">self</span>.<span class="me1">head</span>.<span class="me1">ht</span>-<span class="nu0">1</span><span class="sy0">,</span> -<span class="nu0">1</span><span class="sy0">,</span> -<span class="nu0">1</span><span class="br0">)</span>:
 
	  <span class="co1"># while there is a next node with smaller x than inserting x, go to next node </span>
          <span class="kw1">while</span>   <span class="kw1">not</span> <span class="br0">(</span>prev.<span class="me1">next</span><span class="br0">[</span>j<span class="br0">]</span> <span class="kw1">is</span> <span class="kw2">None</span><span class="br0">)</span> <span class="kw1">and</span> prev.<span class="me1">next</span><span class="br0">[</span>j<span class="br0">]</span>.<span class="me1">x</span> <span class="sy0">&lt;</span> x:
            prev <span class="sy0">=</span> prev.<span class="me1">next</span><span class="br0">[</span>j<span class="br0">]</span>
 
            <span class="co1">#print "prev", prev</span>
 
	  last<span class="br0">[</span>j<span class="br0">]</span> <span class="sy0">=</span> prev <span class="co1">#record the previous node for this level which is points to node with higher x</span>
 
	<span class="co1">#weave in the node</span>
        <span class="co1">#only change pointers for the levels of the inserted node</span>
	<span class="kw1">for</span> j <span class="kw1">in</span> <span class="kw2">xrange</span> <span class="br0">(</span> <span class="nu0">0</span><span class="sy0">,</span> n.<span class="me1">ht</span><span class="br0">)</span>:  
	  tmp <span class="sy0">=</span> last<span class="br0">[</span>j<span class="br0">]</span>.<span class="me1">next</span><span class="br0">[</span>j<span class="br0">]</span>
          last<span class="br0">[</span>j<span class="br0">]</span>.<span class="me1">next</span><span class="br0">[</span>j<span class="br0">]</span> <span class="sy0">=</span> n
          n.<span class="me1">next</span><span class="br0">[</span>j<span class="br0">]</span> <span class="sy0">=</span>tmp 
 
 
  <span class="kw1">def</span> find<span class="br0">(</span><span class="kw2">self</span><span class="sy0">,</span> x<span class="br0">)</span>:
    c <span class="sy0">=</span> <span class="kw2">self</span>.<span class="me1">find_node</span><span class="br0">(</span>x<span class="br0">)</span>
    <span class="kw1">if</span> c <span class="kw1">is</span> <span class="kw2">None</span> <span class="kw1">or</span> c.<span class="me1">x</span> <span class="sy0">&lt;&gt;</span> x: 
      <span class="kw1">return</span> <span class="kw2">None</span>
 
    <span class="kw1">return</span> c.<span class="me1">x</span>
 
 
  <span class="kw1">def</span> find_node_and_prev<span class="br0">(</span><span class="kw2">self</span><span class="sy0">,</span> x<span class="br0">)</span>:
    <span class="kw1">if</span> <span class="kw2">self</span>.<span class="me1">head</span> <span class="kw1">is</span> <span class="kw2">None</span>:
      <span class="kw1">return</span> <span class="kw2">None</span>
    c <span class="sy0">=</span> <span class="kw2">self</span>.<span class="me1">head</span>
    prev <span class="sy0">=</span> <span class="br0">[</span> y <span class="kw1">for</span> y <span class="kw1">in</span> <span class="kw2">self</span>.<span class="me1">head</span> <span class="br0">]</span>
    <span class="kw1">for</span> i <span class="kw1">in</span> <span class="kw2">xrange</span><span class="br0">(</span><span class="kw2">self</span>.<span class="me1">head</span>.<span class="me1">ht</span> - <span class="nu0">1</span><span class="sy0">,</span> -<span class="nu0">1</span><span class="sy0">,</span> -<span class="nu0">1</span><span class="br0">)</span>:
      <span class="kw1">while</span> c.<span class="me1">x</span> <span class="sy0">&lt;</span> x <span class="kw1">and</span> <span class="kw1">not</span> c.<span class="me1">next</span><span class="br0">[</span>i<span class="br0">]</span> <span class="kw1">is</span> <span class="kw2">None</span> <span class="kw1">and</span> c.<span class="me1">next</span><span class="br0">[</span>i<span class="br0">]</span>.<span class="me1">x</span> <span class="sy0">&lt;=</span> x: <span class="co1"># must be &lt;= otherwise won't make c.x = x</span>
        prev<span class="br0">[</span>i<span class="br0">]</span> <span class="sy0">=</span> c
        c <span class="sy0">=</span> c.<span class="me1">next</span><span class="br0">[</span>i<span class="br0">]</span>
      <span class="co1">#print c.x, x</span>
      <span class="kw1">if</span> c.<span class="me1">x</span> <span class="sy0">&gt;=</span> x:
        <span class="kw1">return</span> <span class="br0">(</span>c<span class="sy0">,</span> prev<span class="br0">)</span>
    <span class="kw1">return</span> <span class="br0">(</span><span class="kw2">None</span><span class="sy0">,</span> <span class="kw2">None</span><span class="br0">)</span>
 
  <span class="kw1">def</span> find_node<span class="br0">(</span><span class="kw2">self</span><span class="sy0">,</span> x<span class="br0">)</span>:
    <span class="kw1">return</span> <span class="kw2">self</span>.<span class="me1">find_node_and_prev</span><span class="br0">(</span>x<span class="br0">)</span><span class="br0">[</span><span class="nu0">0</span><span class="br0">]</span>   
 
  <span class="kw1">def</span> delete<span class="br0">(</span><span class="kw2">self</span><span class="sy0">,</span> x<span class="br0">)</span>:
    c<span class="sy0">,</span> prev <span class="sy0">=</span> <span class="kw2">self</span>.<span class="me1">find_node_and_prev</span><span class="br0">(</span>x<span class="br0">)</span>
 
    <span class="kw1">if</span> c <span class="kw1">is</span> <span class="kw2">None</span>:
      <span class="kw1">return</span> <span class="kw2">False</span>
 
    <span class="kw1">for</span> i <span class="kw1">in</span> <span class="kw2">xrange</span><span class="br0">(</span><span class="nu0">0</span><span class="sy0">,</span> <span class="kw2">len</span><span class="br0">(</span>c.<span class="me1">next</span><span class="br0">)</span> <span class="br0">)</span>:
      prev<span class="br0">[</span>i<span class="br0">]</span> <span class="sy0">=</span> c.<span class="me1">next</span><span class="br0">[</span>i<span class="br0">]</span>
    <span class="kw1">return</span> <span class="kw2">True</span>
 
  <span class="co1"># efficient subranges         </span>
  <span class="kw1">def</span> find_range_nodes<span class="br0">(</span> <span class="kw2">self</span><span class="sy0">,</span> x1<span class="sy0">,</span> x2<span class="br0">)</span>:
    c1 <span class="sy0">=</span> <span class="kw2">self</span>.<span class="me1">find_node</span><span class="br0">(</span>x1<span class="br0">)</span>
    c2 <span class="sy0">=</span> <span class="kw2">self</span>.<span class="me1">find_node</span><span class="br0">(</span>x2<span class="br0">)</span>
    l <span class="sy0">=</span> <span class="br0">[</span><span class="br0">]</span>
    <span class="kw1">while</span> c1 <span class="sy0">&lt;&gt;</span> c2:
      l.<span class="me1">append</span><span class="br0">(</span>c1<span class="br0">)</span>
      c1<span class="sy0">=</span> c1.<span class="me1">next</span><span class="br0">[</span><span class="nu0">0</span><span class="br0">]</span>
    <span class="kw1">return</span> l 
 
  <span class="kw1">def</span> find_range_keys<span class="br0">(</span> <span class="kw2">self</span><span class="sy0">,</span> x1<span class="sy0">,</span> x2<span class="br0">)</span>:
    <span class="kw1">return</span> <span class="br0">[</span> n.<span class="me1">x</span> <span class="kw1">for</span> n <span class="kw1">in</span> <span class="kw2">self</span>.<span class="me1">find_range_nodes</span><span class="br0">(</span>x1<span class="sy0">,</span>x2<span class="br0">)</span> <span class="br0">]</span>
 
  <span class="kw1">def</span> find_range_values<span class="br0">(</span> <span class="kw2">self</span><span class="sy0">,</span> x1<span class="sy0">,</span> x2<span class="br0">)</span>:
    <span class="kw1">return</span> <span class="br0">[</span> n.<span class="me1">v</span> <span class="kw1">for</span> n <span class="kw1">in</span> <span class="kw2">self</span>.<span class="me1">find_range_nodes</span><span class="br0">(</span>x1<span class="sy0">,</span>x2<span class="br0">)</span> <span class="br0">]</span>
 
<span class="kw1">if</span> __name__ <span class="sy0">==</span> <span class="st0">"__main__"</span>:
  sk <span class="sy0">=</span> SkipList<span class="br0">(</span><span class="br0">)</span>
  <span class="kw1">for</span> i <span class="kw1">in</span> <span class="kw2">xrange</span><span class="br0">(</span><span class="nu0">0</span><span class="sy0">,</span><span class="nu0">100000</span><span class="br0">)</span>:
    <span class="co1">#x = random.randint(0,1000000)</span>
 
    sk.<span class="me1">insert</span><span class="br0">(</span>i<span class="sy0">,</span> i * <span class="nu0">10</span> <span class="br0">)</span>
 
  <span class="kw1">for</span> i <span class="kw1">in</span> <span class="kw2">xrange</span><span class="br0">(</span><span class="nu0">0</span><span class="sy0">,</span><span class="nu0">100000</span><span class="br0">)</span>:
    <span class="kw1">print</span> i<span class="sy0">,</span> sk.<span class="me1">find</span><span class="br0">(</span>i<span class="br0">)</span>
 
  <span class="kw1">print</span> sk.<span class="me1">find_range_keys</span><span class="br0">(</span><span class="nu0">0</span><span class="sy0">,</span><span class="nu0">100001</span><span class="br0">)</span>     
 
  <span class="kw1">print</span> sk.<span class="me1">find_range_values</span><span class="br0">(</span><span class="nu0">75500</span><span class="sy0">,</span> <span class="nu0">75528</span><span class="br0">)</span>
</pre></div>
</div>
<p><br /></p>
<h3><span class="mw-headline" id="Role_of_Randomness">Role of Randomness</span></h3>
<p>The idea of making higher nodes geometrically randomly less common, means there are less keys to compare with the higher the level of comparison, and since these are randomly selected, this should get rid of problems of degenerate input that makes it necessary to do tree balancing in tree algorithms. Since the higher level list have more widely separated elements, but the search algorithm moves down a level after each search terminates at a level, the higher levels help "skip" over the need to search earlier elements on lower lists. Because there are multiple levels of skipping, it becomes less likely that a meagre skip at a higher level won't be compensated by better skips at lower levels, and Pugh claims O(logN) performance overall.</p>
<p>Conceptually , is it easier to understand than balancing trees and hence easier to implement&#160;? The development of ideas from binary trees, balanced binary trees, 2-3 trees, red-black trees, and B-trees make a stronger conceptual network but is progressive in development, so arguably, once red-black trees are understood, they have more conceptual context to aid memory , or refresh of memory.</p>
<h3><span class="mw-headline" id="concurrent_access_application">concurrent access application</span></h3>
<p>Apart from using randomization to enhance a basic memory structure of linked lists, skip lists can also be extended as a global data structure used in a multiprocessor application. See supplementary topic at the end of the chapter.</p>
<h3><span class="mw-headline" id="Idea_for_an_exercise">Idea for an exercise</span></h3>
<p>Replace the Linux completely fair scheduler red-black tree implementation with a skip list , and see how your brand of Linux runs after recompiling.</p>
<h2><span class="mw-headline" id="Treaps">Treaps</span></h2>
<p>A treap is a two keyed binary tree, that uses a second randomly generated key and the previously discussed tree operation of parent-child rotation to randomly rotate the tree so that overall, a balanced tree is produced. Recall that binary trees work by having all nodes in the left subtree small than a given node, and all nodes in a right subtree greater. Also recall that node rotation does not break this order ( some people call it an invariant), but changes the relationship of parent and child, so that if the parent was smaller than a right child, then the parent becomes the left child of the formerly right child. The idea of a tree-heap or treap, is that a binary heap relationship is maintained between parents and child, and that is a parent node has higher priority than its children, which is not the same as the left , right order of keys in a binary tree, and hence a recently inserted leaf node in a binary tree which happens to have a high random priority, can be rotated so it is relatively higher in the tree, having no parent with a lower priority. See the preamble to skip lists about red-black trees on the details of <a href="/wiki/Algorithms/Left_rotation" title="Algorithms/Left rotation">left rotation</a>.</p>
<p>A treap is an alternative to both red-black trees, and skip lists, as a self-balancing sorted storage structure.</p>
<h2><span class="mw-headline" id="Derandomization">Derandomization</span></h2>
<p>[TODO: Deterministic algorithms for Quicksort exist that perform as well as quicksort in the average case and are guaranteed to perform at least that well in all cases. Best of all, no randomization is needed. Also in the discussion should be some perspective on using randomization: some randomized algorithms give you better confidence probabilities than the actual hardware itself! (e.g. sunspots can randomly flip bits in hardware, causing failure, which is a risk we take quite often)]</p>
<p>[Main idea: Look at all blocks of 5 elements, and pick the median (O(1) to pick), put all medians into an array (O(n)), recursively pick the medians of that array, repeat until you have &lt; 5 elements in the array. This recursive median constructing of every five elements takes time T(n)=T(n/5) + O(n), which by the master theorem is O(n). Thus, in O(n) we can find the right pivot. Need to show that this pivot is sufficiently good so that we're still O(n log n) no matter what the input is. This version of quicksort doesn't need rand, and it never performs poorly. Still need to show that element picked out is sufficiently good for a pivot.]</p>
<h2><span class="mw-headline" id="Exercises">Exercises</span></h2>
<ol>
<li>Write a <b>find-min</b> function and run it on several different inputs to demonstrate its correctness.</li>
</ol>
<h2><span class="mw-headline" id="Supplementary_Topic:_skip_lists_and_multiprocessor_algorithms">Supplementary Topic: skip lists and multiprocessor algorithms</span></h2>
<p>Multiprocessor hardware provides CAS ( compare-and-set) or CMPEXCHG( compare-and-exchange)(intel manual 253666.pdf, p 3-188) atomic operations, where an expected value is loaded into the accumulator register, which is compared to a target memory location's contents, and if the same, a source memory location's contents is loaded into the target memories contents, and the zero flag set, otherwise, if different, the target memory's contents is returned in the accumulator, and the zero flag is unset, signifying , for instance, a lock contention. In the intel architecture, a LOCK instruction is issued before CMPEXCHG , which either locks the cache from concurrent access if the memory location is being cached, or locks a shared memory location if not in the cache , for the next instruction.</p>
<p>The CMPEXCHG can be used to implement locking, where spinlocks , e.g. retrying until the zero flag is set, are simplest in design.</p>
<p>Lockless design increases efficiency by avoiding spinning waiting for a lock .</p>
<p>The java standard library has an implementation of non-blocking concurrent skiplists, based on a paper titled "a pragmatic implementation of non-blocking single-linked lists".</p>
<p>The skip list implementation is an extension of the lock-free single-linked list , of which a description follows&#160;:-</p>
<p>The <b>insert</b> operation is&#160;: X -&gt; Y insert N , N -&gt; Y, X -&gt; N&#160;; expected result is X -&gt; N -&gt; Y .</p>
<p>A race condition is if M is inserting between X and Y and M completes first , then N completes, so the situation is X -&gt; N -&gt; Y &lt;- M</p>
<p>M is not in the list. The CAS operation avoids this, because a copy of -&gt; Y is checked before updating X -&gt; , against the current value of X -&gt; .</p>
<p>If N gets to update X -&gt; first, then when M tries to update X -&gt; , its copy of X -&gt; Y , which it got before doing M -&gt; Y , does not match X -&gt; N , so CAS returns non-zero flag set. The process that tried to insert M then can retry the insertion after X, but now the CAS checks -&gt;N is X's next pointer, so after retry, X-&gt;M-&gt;N-&gt;Y , and neither insertions are lost.</p>
<p>If M updates X-&gt; first, N 's copy of X-&gt;Y does not match X -&gt; M , so the CAS will fail here too, and the above retry of the process inserting N, would have the serialized result of X -&gt;N -&gt; M -&gt; Y .</p>
<p>The <b>delete</b> operation depends on a separate 'logical' deletion step, before 'physical' deletion.</p>
<p>'Logical' deletion involves a CAS change of the next pointer into a 'marked' pointer. The java implementation substitutes with an atomic insertion of a proxy marker node to the next node.</p>
<p>This prevents future insertions from inserting after a node which has a next pointer 'marked' , making the latter node 'logically' deleted.</p>
<p>The <b>insert</b> operation relies on another function , <i>search</i> , returning <u>2</u> <b>unmarked</b> , at the time of the invocation, node pointers&#160;: the first pointing to a node , whose next pointer is equal to the second.</p>
<p>The first node is the node before the insertion point.</p>
<p>The <i>insert</i> CAS operation checks that the current next pointer of the first node, corresponds to the unmarked reference of the second, so will fail 'logically' if the first node's <i>next</i> pointer has become marked <i>after</i> the call to the <i>search</i> function above, because the first node has been concurrently logically deleted.</p>
<p><i>This meets the aim to prevent a insertion occurring concurrently after a node has been deleted.</i></p>
<p>If the insert operation fails the CAS of the previous node's next pointer, the search for the insertion point starts from the <b>start of the entire list</b> again, since a new unmarked previous node needs to be found, and there are no previous node pointers as the list nodes are singly-linked.</p>
<div class="thumb tright">
<div class="thumbinner" style="width:302px;"><a href="/wiki/File:CAS_insert.png" class="image"><img alt="CAS insert.png" src="//upload.wikimedia.org/wikipedia/commons/thumb/1/18/CAS_insert.png/300px-CAS_insert.png" width="300" height="233" class="thumbimage" srcset="//upload.wikimedia.org/wikipedia/commons/thumb/1/18/CAS_insert.png/450px-CAS_insert.png 1.5x, //upload.wikimedia.org/wikipedia/commons/1/18/CAS_insert.png 2x" /></a>
<div class="thumbcaption">
<div class="magnify"><a href="/wiki/File:CAS_insert.png" class="internal" title="Enlarge"><img src="//bits.wikimedia.org/static-1.23wmf7/skins/common/images/magnify-clip.png" width="15" height="11" alt="" /></a></div>
</div>
</div>
</div>
<p>The <b>delete</b> operation outlined above, also relies on the <i>search</i> operation returning two <i>unmarked</i> nodes, and the two CAS operations in delete, one for logical deletion or marking of the second pointer's next pointer, and the other for physical deletion by making the first node's next pointer point to the second node's unmarked next pointer.</p>
<p>The first CAS of delete happens only after a check that the copy of the original second nodes' next pointer is unmarked, and ensures that only one concurrent delete succeeds which reads the second node's current next pointer as being unmarked as well.</p>
<p>The second CAS checks that the previous node hasn't been logically deleted because its next pointer is not the same as the unmarked pointer to the current second node returned by the search function, so only an active previous node's next pointer is 'physically' updated to a copy of the original unmarked next pointer of the node being deleted ( whose next pointer is already marked by the first CAS).</p>
<p>If the second CAS fails, then the previous node is logically deleted and its next pointer is marked, and so is the current node's next pointer. A call to <i>search</i> function again, tidies things up, because in endeavouring to find the key of the current node and return adjacent unmarked previous and current pointers, and while doing so, it truncates strings of logically deleted nodes .</p>
<h4><span class="mw-headline" id="Lock-free_programming_issues">Lock-free programming issues</span></h4>
<p>Starvation could be possible , as failed inserts have to restart from the front of the list. Wait-freedom is a concept where the algorithm has all threads safe from starvation.</p>
<p>The ABA problem exists, where a garbage collector recycles the pointer A , but the address is loaded differently, and the pointer is re-added at a point where a check is done for A by another thread that read A and is doing a CAS to check A has not changed&#160;; the address is the same and is unmarked, but the contents of A has changed.</p>
<p><br /></p>
<h1><span class="mw-headline" id="Backtracking">Backtracking</span></h1>
<p><b>Backtracking</b> is a general algorithmic technique that considers searching every possible combination in order to solve an optimization problem. Backtracking is also known as <b>depth-first search</b> or <b>branch and bound</b>. By inserting more knowledge of the problem, the search tree can be pruned to avoid considering cases that don't look promising. While backtracking is useful for hard problems to which we do not know more efficient solutions, it is a poor solution for the everyday problems that other techniques are much better at solving.</p>
<p>However, dynamic programming and greedy algorithms can be thought of as optimizations to backtracking, so the general technique behind backtracking is useful for understanding these more advanced concepts. Learning and understanding backtracking techniques first provides a good stepping stone to these more advanced techniques because you won't have to learn several new concepts all at once.</p>
<table width="80%">
<tr>
<td style="background-color: #FFFFEE; border: solid 1px #FFC92E; padding: 1em;" valign="top"><b>Backtracking Methodology</b><br />
<ol>
<li>View picking a solution as a sequence of <b>choices</b></li>
<li>For each choice, consider every <b>option</b> recursively</li>
<li>Return the best solution found</li>
</ol>
</td>
</tr>
</table>
<p>This methodology is generic enough that it can be applied to most problems. However, even when taking care to improve a backtracking algorithm, it will probably still take exponential time rather than polynomial time. Additionally, exact time analysis of backtracking algorithms can be extremely difficult: instead, simpler upperbounds that may not be tight are given.</p>
<h2><span class="mw-headline" id="Longest_Common_Subsequence_.28exhaustive_version.29">Longest Common Subsequence (exhaustive version)</span></h2>
<p>Note that the solution to the longest common subsequence (LCS) problem discussed in this section is not efficient. However, it is useful for understanding the dynamic programming version of the algorithm that is covered later.</p>
<p>The LCS problem is similar to what the Unix "diff" program does. The diff command in Unix takes two text files, <i>A</i> and <i>B</i>, as input and outputs the differences line-by-line from <i>A</i> and <i>B</i>. For example, diff can show you that lines missing from <i>A</i> have been added to <i>B</i>, and lines present in <i>A</i> have been removed from <i>B</i>. The goal is to get a list of additions and removals that could be used to transform <i>A</i> to <i>B</i>. An overly conservative solution to the problem would say that all lines from <i>A</i> were removed, and that all lines from <i>B</i> were added. While this would solve the problem in a crude sense, we are concerned with the minimal number of additions and removals to achieve a correct transformation. Consider how you may implement a solution to this problem yourself.</p>
<p>The LCS problem, instead of dealing with lines in text files, is concerned with finding common items between two different arrays. For example,</p>
<pre>
let <i>a</i> := array {"The", "great", "square", "has", "no", "corners"}
let <i>b</i> := array {"The", "great", "image", "has", "no", "form"}
</pre>
<p>We want to find the longest subsequence possible of items that are found in both <i>a</i> and <i>b</i> in the same order. The LCS of <i>a</i> and <i>b</i> is</p>
<dl>
<dd>"The", "great", "has", "no"</dd>
</dl>
<p>Now consider two more sequences:</p>
<pre>
let <i>c</i> := array {1, 2, 4, 8, 16, 32}
let <i>d</i> := array {1, 2, 3, 32, 8}
</pre>
<p>Here, there are two longest common subsequences of <i>c</i> and <i>d</i>:</p>
<dl>
<dd>1, 2, 32; and</dd>
<dd>1, 2, 8</dd>
</dl>
<p>Note that</p>
<dl>
<dd>1, 2, 32, 8</dd>
</dl>
<p>is <i>not</i> a common subsequence, because it is only a valid subsequence of <i>d</i> and not <i>c</i> (because <i>c</i> has 8 before the 32). Thus, we can conclude that for some cases, solutions to the LCS problem are not unique. If we had more information about the sequences available we might prefer one subsequence to another: for example, if the sequences were lines of text in computer programs, we might choose the subsequences that would keep function definitions or paired comment delimiters intact (instead of choosing delimiters that were not paired in the syntax).</p>
<p>On the top level, our problem is to implement the following function</p>
<pre>
// <i>lcs -- returns the longest common subsequence of a and b</i>
function <b>lcs</b>(array <i>a</i>, array <i>b</i>): array
</pre>
<p>which takes in two arrays as input and outputs the subsequence array.</p>
<p>How do you solve this problem? You could start by noticing that if the two sequences start with the same word, then the longest common subsequence always contains that word. You can automatically put that word on your list, and you would have just reduced the problem to finding the longest common subset of the rest of the two lists. Thus, the problem was made smaller, which is good because it shows progress was made.</p>
<p>But if the two lists do not begin with the same word, then one, or both, of the first element in <i>a</i> or the first element in <i>b</i> do not belong in the longest common subsequence. But yet, one of them might be. How do you determine which one, if any, to add?</p>
<p>The solution can be thought in terms of the back tracking methodology: Try it both ways and see! Either way, the two sub-problems are manipulating smaller lists, so you know that the recursion will eventually terminate. Whichever trial results in the longer common subsequence is the winner.</p>
<p>Instead of "throwing it away" by deleting the item from the array we use array slices. For example, the slice</p>
<dl>
<dd><i>a</i>[1,..,5]</dd>
</dl>
<p>represents the elements</p>
<dl>
<dd>{<i>a</i>[1], <i>a</i>[2], <i>a</i>[3], <i>a</i>[4], <i>a</i>[5]}</dd>
</dl>
<p>of the array as an array itself. If your language doesn't support slices you'll have to pass beginning and/or ending indices along with the full array. Here, the slices are only of the form</p>
<dl>
<dd><i>a</i>[1,..]</dd>
</dl>
<p>which, when using 0 as the index to the first element in the array, results in an array slice that doesn't have the 0th element. (Thus, a non-sliced version of this algorithm would only need to pass the beginning valid index around instead, and that value would have to be subtracted from the complete array's length to get the pseudo-slice's length.)</p>
<pre>
// <i>lcs -- returns the longest common subsequence of a and b</i>
function <b>lcs</b>(array <i>a</i>, array <i>b</i>): array
  if <i>a</i>.length == 0 OR <i>b</i>.length == 0:
    <i>// if we're at the end of either list, then the lcs is empty</i>
    
    return new array {}
  else-if <i>a</i>[0] == <i>b</i>[0]:
    <i>// if the start element is the same in both, then it is on the lcs,</i>
    <i>// so we just recurse on the remainder of both lists.</i>
    
    return append(new array {<i>a</i>[0]}, <b>lcs</b>(<i>a</i>[1,..], <i>b</i>[1,..]))
  else
    <i>// we don't know which list we should discard from. Try both ways,</i>
    <i>// pick whichever is better.</i>
    
    let <i>discard_a</i> := <b>lcs</b>(<i>a</i>[1,..], <i>b</i>)
    let <i>discard_b</i> := <b>lcs</b>(<i>a</i>, <i>b</i>[1,..])
    
    if <i>discard_a</i>.length &gt; <i>discard_b</i>.length:
      let <i>result</i> := <i>discard_a</i>
    else
      let <i>result</i> := <i>discard_b</i>
    fi
    return <i>result</i>
  fi
end
</pre>
<h2><span class="mw-headline" id="Shortest_Path_Problem_.28exhaustive_version.29">Shortest Path Problem (exhaustive version)</span></h2>
<p>To be improved as Dijkstra's algorithm in a later section.</p>
<h2><span class="mw-headline" id="Largest_Independent_Set">Largest Independent Set</span></h2>
<h2><span class="mw-headline" id="Bounding_Searches">Bounding Searches</span></h2>
<p>If you've already found something "better" and you're on a branch that will never be as good as the one you already saw, you can terminate that branch early. (Example to use: sum of numbers beginning with 1 2, and then each number following is a sum of any of the numbers plus the last number. Show performance improvements.)</p>
<h2><span class="mw-headline" id="Constrained_3-Coloring">Constrained 3-Coloring</span></h2>
<p>This problem doesn't have immediate self-similarity, so the problem first needs to be generalized. Methodology: If there's no self-similarity, try to generalize the problem until it has it.</p>
<h2><span class="mw-headline" id="Traveling_Salesperson_Problem">Traveling Salesperson Problem</span></h2>
<p>Here, backtracking is one of the best solutions known.</p>
<p><br /></p>
<h1><span class="mw-headline" id="Dynamic_Programming">Dynamic Programming</span></h1>
<p><b>Dynamic programming</b> can be thought of as an optimization technique for particular classes of backtracking algorithms where subproblems are repeatedly solved. Note that the term <i>dynamic</i> in dynamic programming should not be confused with dynamic programming languages, like Scheme or Lisp. Nor should the term <i>programming</i> be confused with the act of writing computer programs. In the context of algorithms, dynamic programming always refers to the technique of filling in a table with values computed from other table values. (It's dynamic because the values in the table are filled in by the algorithm based on other values of the table, and it's programming in the sense of setting things in a table, like how television programming is concerned with when to broadcast what shows.)</p>
<h2><span class="mw-headline" id="Fibonacci_Numbers">Fibonacci Numbers</span></h2>
<p>Before presenting the dynamic programming technique, it will be useful to first show a related technique, called <b>memoization</b>, on a toy example: The Fibonacci numbers. What we want is a routine to compute the <i>n</i>th Fibonacci number:</p>
<pre>
<i>// fib -- compute Fibonacci(n)</i>
function <b>fib</b>(integer <i>n</i>): integer
</pre>
<p>By definition, the <i>n</i>th Fibonacci number, denoted <img class="tex" alt="\textrm{F}_n" src="//upload.wikimedia.org/math/2/b/6/2b62a1786c55d0f4bd1392e5698ddeae.png" /> is</p>
<dl>
<dd><img class="tex" alt="\textrm{F}_0 = 0" src="//upload.wikimedia.org/math/3/2/0/320c31a0e1c5992e108fd6fafbc7e116.png" /></dd>
<dd><img class="tex" alt="\textrm{F}_1 = 1" src="//upload.wikimedia.org/math/3/7/e/37e516e560cefe66e15a3d7cc4ef0c7c.png" /></dd>
<dd><img class="tex" alt="\textrm{F}_n = \textrm{F}_{n-1} + \textrm{F}_{n-2}" src="//upload.wikimedia.org/math/c/1/9/c199668f5ac39af59ec892527a3a8cda.png" /></dd>
</dl>
<p>How would one create a good algorithm for finding the nth Fibonacci-number? Let's begin with the naive algorithm, which codes the mathematical definition:</p>
<pre>
<i>// fib -- compute Fibonacci(n)</i>
function <b>fib</b>(integer <i>n</i>): integer
  assert (n &gt;= 0)
  if <i>n</i> == 0: return 0 fi
  if <i>n</i> == 1: return 1 fi
  
  return <b>fib</b>(<i>n</i> - 1) + <b>fib</b>(<i>n</i> - 2)
end
</pre>
<div id="toc"><small>This code sample is also available in <a href="/wiki/Ada_Programming/Algorithms#Simple_Implementation" title="Ada Programming/Algorithms">Ada</a>.</small></div>
<p>Note that this is a toy example because there is already a mathematically closed form for <img class="tex" alt="\textrm{F}_n" src="//upload.wikimedia.org/math/2/b/6/2b62a1786c55d0f4bd1392e5698ddeae.png" />:</p>
<dl>
<dd><img class="tex" alt="F(n) = {\phi^n - (1 -\phi)^{n} \over \sqrt{5}}" src="//upload.wikimedia.org/math/b/d/e/bde083789da8779ef179982bad6f6745.png" /></dd>
</dl>
<p>where:</p>
<dl>
<dd><img class="tex" alt="\phi = {1 + \sqrt{5} \over 2}" src="//upload.wikimedia.org/math/d/2/6/d261ff480362f4ee9f0dcb9299db11b3.png" /></dd>
</dl>
<p>This latter equation is known as the <a href="//en.wikipedia.org/wiki/golden_ratio" class="extiw" title="w:golden ratio">Golden Ratio</a>. Thus, a program could efficiently calculate <img class="tex" alt="\textrm{F}_n" src="//upload.wikimedia.org/math/2/b/6/2b62a1786c55d0f4bd1392e5698ddeae.png" /> for even very large <i>n</i>. However, it's instructive to understand what's so inefficient about the current algorithm.</p>
<p>To analyze the running time of <tt>fib</tt> we should look at a call tree for something even as small as the sixth Fibonacci number:</p>
<p><a href="/wiki/File:Algorithms-F6CallTree.png" class="image"><img alt="Algorithms-F6CallTree.png" src="//upload.wikimedia.org/wikibooks/en/3/37/Algorithms-F6CallTree.png" width="604" height="219" /></a></p>
<p>Every leaf of the call tree has the value 0 or 1, and the sum of these values is the final result. So, for any <i>n,</i> the number of leaves in the call tree is actually <img class="tex" alt="\textrm{F}_n" src="//upload.wikimedia.org/math/2/b/6/2b62a1786c55d0f4bd1392e5698ddeae.png" /> itself! The closed form thus tells us that the number of leaves in <tt><b>fib</b>(<i>n</i>)</tt> is approximately equal to</p>
<dl>
<dd><img class="tex" alt="\left(\frac{1 + \sqrt{5}}{2}\right)^n\approx 1.618^n = 2^{\lg (1.618^n)} = 2^{n \lg (1.618)} \approx 2^{0.69 n}." src="//upload.wikimedia.org/math/2/6/9/26957ebee60168dd01c3fdc083befeec.png" /></dd>
</dl>
<p>(Note the algebraic manipulation used above to make the base of the exponent the number 2.) This means that there are far too many leaves, particularly considering the repeated patterns found in the call tree above.</p>
<p>One optimization we can make is to save a result in a table once it's already been computed, so that the same result needs to be computed only once. The optimization process is called memoization and conforms to the following methodology:</p>
<table width="80%">
<tr>
<td style="background-color: #FFFFEE; border: solid 1px #FFC92E; padding: 1em;" valign="top"><b>Memoization Methodology</b><br />
<ol>
<li>Start with a backtracking algorithm</li>
<li>Look up the problem in a table; if there's a valid entry for it, return that value</li>
<li>Otherwise, compute the problem recursively, and then store the result in the table before returning the value</li>
</ol>
</td>
</tr>
</table>
<p>Consider the solution presented in the backtracking chapter for the Longest Common Subsequence problem. In the execution of that algorithm, many common subproblems were computed repeatedly. As an optimization, we can compute these subproblems once and then store the result to read back later. A recursive memoization algorithm can be turned "bottom-up" into an iterative algorithm that fills in a table of solutions to subproblems. Some of the subproblems solved might not be needed by the end result (and that is where dynamic programming differs from memoization), but dynamic programming can be very efficient because the iterative version can better use the cache and have less call overhead. Asymptotically, dynamic programming and memoization have the same complexity.</p>
<p>So how would a fibonacci program using memoization work? Consider the following program (<i>f</i>[<i>n</i>] contains the <i>n</i>th Fibonacci-number if has been calculated, -1 otherwise):</p>
<pre>
function <b>fib</b>(integer <i>n</i>): integer
  if <i>n</i> == 0 <b>or</b> n == 1:
    return <i>n</i>
  else-if <i>f</i>[<i>n</i>] != -1:
    return <i>f</i>[<i>n</i>]
  else
    <i>f</i>[<i>n</i>] = <b>fib</b>(<i>n</i> - 1) + <b>fib</b>(<i>n</i> - 2)
    return <i>f</i>[<i>n</i>]
  fi
end
</pre>
<div id="toc"><small>This code sample is also available in <a href="/wiki/Ada_Programming/Algorithms#Cached_Implementation" title="Ada Programming/Algorithms">Ada</a>.</small></div>
<p>The code should be pretty obvious. If the value of fib(n) already has been calculated it's stored in f[n] and then returned instead of calculating it again. That means all the copies of the sub-call trees are removed from the calculation.</p>
<p><a href="/wiki/File:Algorithms-F6CallTreeMemoized.PNG" class="image"><img alt="Algorithms-F6CallTreeMemoized.PNG" src="//upload.wikimedia.org/wikibooks/en/f/fb/Algorithms-F6CallTreeMemoized.PNG" width="604" height="219" /></a></p>
<p>The values in the blue boxes are values that already have been calculated and the calls can thus be skipped. It is thus a lot faster than the straight-forward recursive algorithm. Since every value less than n is calculated once, and only once, the first time you execute it, the asymptotic running time is <img class="tex" alt="O (n)" src="//upload.wikimedia.org/math/7/b/a/7ba55e7c64a9405a0b39a1107e90ca94.png" />. Any other calls to it will take <img class="tex" alt="O (1)" src="//upload.wikimedia.org/math/5/e/0/5e079a28737d5dd019a3b8f6133ee55e.png" /> since the values have been precalculated (assuming each subsequent call's argument is less than n).</p>
<p>The algorithm does consume a lot of memory. When we calculate fib(<i>n</i>), the values fib(0) to fib(n) are stored in main memory. Can this be improved? Yes it can, although the <img class="tex" alt="O(1)" src="//upload.wikimedia.org/math/5/e/0/5e079a28737d5dd019a3b8f6133ee55e.png" /> running time of subsequent calls are obviously lost since the values aren't stored. Since the value of fib(<i>n</i>) only depends on fib(<i>n-1</i>) and fib(<i>n-2</i>) we can discard the other values by going bottom-up. If we want to calculate fib(<i>n</i>), we first calculate fib(2) = fib(0) + fib(1). Then we can calculate fib(3) by adding fib(1) and fib(2). After that, fib(0) and fib(1) can be discarded, since we don't need them to calculate any more values. From fib(2) and fib(3) we calculate fib(4) and discard fib(2), then we calculate fib(5) and discard fib(3), etc. etc. The code goes something like this:</p>
<pre>
function <b>fib</b>(integer <i>n</i>): integer
  if <i>n</i> == 0 <b>or</b> n == 1:
    return <i>n</i>
  fi

  let <i>u</i> := 0
  let <i>v</i> := 1

  for <i>i</i> := 2 to <i>n</i>:
    let <i>t</i> := <i>u</i> + <i>v</i>
    <i>u</i> := <i>v</i>
    <i>v</i> := <i>t</i>
  repeat
  
  return <i>v</i>
end
</pre>
<div id="toc"><small>This code sample is also available in <a href="/wiki/Ada_Programming/Algorithms#Memory_Optimized_Implementation" title="Ada Programming/Algorithms">Ada</a>.</small></div>
<p>We can modify the code to store the values in an array for subsequent calls, but the point is that we don't <i>have</i> to. This method is typical for dynamic programming. First we identify what subproblems need to be solved in order to solve the entire problem, and then we calculate the values bottom-up using an iterative process.</p>
<h2><span class="mw-headline" id="Longest_Common_Subsequence_.28DP_version.29">Longest Common Subsequence (DP version)</span></h2>
<p>This will remind us of the backtracking version and then improve it via memoization. Finally, the recursive algorithm will be made iterative and be full-fledged DP. [TODO: write this section]</p>
<h2><span class="mw-headline" id="Matrix_Chain_Multiplication">Matrix Chain Multiplication</span></h2>
<p>Suppose that you need to multiply a series of <img class="tex" alt="n" src="//upload.wikimedia.org/math/7/b/8/7b8b965ad4bca0e41ab51de7b31363a1.png" /> matrices <img class="tex" alt="M_1,\ldots, M_n" src="//upload.wikimedia.org/math/0/d/e/0dec4587d96aba0617cb96a667606ff2.png" /> together to form a product matrix <img class="tex" alt="P" src="//upload.wikimedia.org/math/4/4/c/44c29edb103a2872f519ad0c9a0fdaaa.png" />:</p>
<dl>
<dd><img class="tex" alt="P = M_1\cdot M_2 \cdots M_{n-1}\cdot M_n" src="//upload.wikimedia.org/math/3/c/2/3c2bce3fd3622d42cb053a05e399bce2.png" /></dd>
</dl>
<p>This will require <img class="tex" alt="n-1" src="//upload.wikimedia.org/math/a/4/3/a438673491daae8148eae77373b6a467.png" /> multiplications, but what is the fastest way we can form this product? Matrix multiplication is associative, that is,</p>
<dl>
<dd><img class="tex" alt="(A\cdot B)\cdot C = A\cdot (B\cdot C)" src="//upload.wikimedia.org/math/a/4/a/a4a6fb9c1d3cf53e2b25dd7d7a382c82.png" /></dd>
</dl>
<p>for any <img class="tex" alt="A, B, C" src="//upload.wikimedia.org/math/c/e/0/ce04be1226e56f48da55b6c130d45b94.png" />, and so we have some choice in what multiplication we perform first. (Note that matrix multiplication is <i>not</i> commutative, that is, it does not hold in general that <img class="tex" alt="A\cdot B = B\cdot A" src="//upload.wikimedia.org/math/4/d/2/4d25559f97a5baea78134b786ea9553e.png" />.)</p>
<p>Because you can only multiply two matrices at a time the product <img class="tex" alt="M_1\cdot M_2\cdot M_3\cdot M_4" src="//upload.wikimedia.org/math/8/a/7/8a78bcbc84c14eb7a68c6af8f599ba27.png" /> can be paranthesized in these ways:</p>
<dl>
<dd><img class="tex" alt="((M_1 M_2) M_3) M_4" src="//upload.wikimedia.org/math/9/a/d/9ad0290f84f10ca4694845a3d803a199.png" /></dd>
<dd><img class="tex" alt="(M_1 (M_2 M_3)) M_4" src="//upload.wikimedia.org/math/0/b/d/0bdf6255ea86c36017ec8762076903ba.png" /></dd>
<dd><img class="tex" alt="M_1 ((M_2 M_3) M_4)" src="//upload.wikimedia.org/math/1/b/b/1bb2c25f38b41a515f26b008ea3308a5.png" /></dd>
<dd><img class="tex" alt="(M_1 M_2) (M_3 M_4)" src="//upload.wikimedia.org/math/7/a/4/7a4215b90f6830a115c4cf3699521fbb.png" /></dd>
<dd><img class="tex" alt="M_1 (M_2 (M_3 M_4))" src="//upload.wikimedia.org/math/b/3/d/b3ddfa576b919c1eca80237589a1dfa0.png" /></dd>
</dl>
<p>Two matrices <img class="tex" alt="M_1" src="//upload.wikimedia.org/math/f/2/d/f2da4ca1b046da32d73b4ecc49d58680.png" /> and <img class="tex" alt="M_2" src="//upload.wikimedia.org/math/3/4/a/34a392a9e27dd596c3ed3292b990712f.png" /> can be multiplied if the number of columns in <img class="tex" alt="M_1" src="//upload.wikimedia.org/math/f/2/d/f2da4ca1b046da32d73b4ecc49d58680.png" /> equals the number of rows in <img class="tex" alt="M_2" src="//upload.wikimedia.org/math/3/4/a/34a392a9e27dd596c3ed3292b990712f.png" />. The number of rows in their product will equal the number rows in <img class="tex" alt="M_1" src="//upload.wikimedia.org/math/f/2/d/f2da4ca1b046da32d73b4ecc49d58680.png" /> and the number of columns will equal the number of columns in <img class="tex" alt="M_2" src="//upload.wikimedia.org/math/3/4/a/34a392a9e27dd596c3ed3292b990712f.png" />. That is, if the dimensions of <img class="tex" alt="M_1" src="//upload.wikimedia.org/math/f/2/d/f2da4ca1b046da32d73b4ecc49d58680.png" /> is <img class="tex" alt="a \times b" src="//upload.wikimedia.org/math/2/d/1/2d1dc88200d501549f9d6edae3d6c195.png" /> and <img class="tex" alt="M_2" src="//upload.wikimedia.org/math/3/4/a/34a392a9e27dd596c3ed3292b990712f.png" /> has dimensions <img class="tex" alt="b \times c" src="//upload.wikimedia.org/math/6/5/7/657389c8d4e6654c5eebad2f5bf82752.png" /> their product will have dimensions <img class="tex" alt="a \times c" src="//upload.wikimedia.org/math/5/c/7/5c7ec5b32c36eacca278668ecc18cb88.png" />.</p>
<p>To multiply two matrices with each other we use a function called matrix-multiply that takes two matrices and returns their product. We will leave implementation of this function alone for the moment as it is not the focus of this chapter (how to multiply two matrices in the fastest way has been under intensive study for several years [TODO: propose this topic for the <i>Advanced</i> book]). The time this function takes to multiply two matrices of size <img class="tex" alt="a \times b" src="//upload.wikimedia.org/math/2/d/1/2d1dc88200d501549f9d6edae3d6c195.png" /> and <img class="tex" alt="b \times c" src="//upload.wikimedia.org/math/6/5/7/657389c8d4e6654c5eebad2f5bf82752.png" /> is proportional to the number of scalar multiplications, which is proportional to <img class="tex" alt="a b c" src="//upload.wikimedia.org/math/9/0/0/900150983cd24fb0d6963f7d28e17f72.png" />. Thus, paranthezation matters: Say that we have three matrices <img class="tex" alt="M_1" src="//upload.wikimedia.org/math/f/2/d/f2da4ca1b046da32d73b4ecc49d58680.png" />, <img class="tex" alt="M_2" src="//upload.wikimedia.org/math/3/4/a/34a392a9e27dd596c3ed3292b990712f.png" /> and <img class="tex" alt="M_3" src="//upload.wikimedia.org/math/e/4/7/e47fdbf0968587d24cc2817c16b2ba15.png" />. <img class="tex" alt="M_1" src="//upload.wikimedia.org/math/f/2/d/f2da4ca1b046da32d73b4ecc49d58680.png" /> has dimensions <img class="tex" alt="5 \times 100" src="//upload.wikimedia.org/math/f/f/1/ff138afefd80e558fd6d0650c5ed584b.png" />, <img class="tex" alt="M_2" src="//upload.wikimedia.org/math/3/4/a/34a392a9e27dd596c3ed3292b990712f.png" /> has dimensions <img class="tex" alt="100 \times 100" src="//upload.wikimedia.org/math/1/0/1/1010487f977eb234f3e40bd658b7bcfc.png" /> and <img class="tex" alt="M_3" src="//upload.wikimedia.org/math/e/4/7/e47fdbf0968587d24cc2817c16b2ba15.png" /> has dimensions <img class="tex" alt="100 \times 50" src="//upload.wikimedia.org/math/2/e/1/2e10ca6c50aa3dfe622a5350970d39ad.png" />. Let's paranthezise them in the two possible ways and see which way requires the least amount of multiplications. The two ways are</p>
<dl>
<dd><img class="tex" alt="((M_1 M_2) M_3)" src="//upload.wikimedia.org/math/6/2/4/624a462e588485e047db81007a5afa61.png" />, and</dd>
<dd><img class="tex" alt="(M_1 (M_2 M_3))" src="//upload.wikimedia.org/math/0/a/9/0a9ed2da219cc7bab47d32d5e9d7b770.png" />.</dd>
</dl>
<p>To form the product in the first way requires 75000 scalar multiplications (5*100*100=50000 to form product <img class="tex" alt="(M_1 M_2)" src="//upload.wikimedia.org/math/7/4/9/749a9031a65d7d25853987bf4dd321be.png" /> and another 5*100*50=25000 for the last multiplications.) This might seem like a lot, but in comparison to the 525000 scalar multiplications required by the second parenthesization (50*100*100=500000 plus 5*50*100=25000) it is miniscule! You can see why determining the parenthesization is important: imagine what would happen if we needed to multiply 50 matrices!</p>
<h3><span class="mw-headline" id="Forming_a_Recursive_Solution">Forming a Recursive Solution</span></h3>
<p>Note that we concentrate on finding a how many scalar multiplications are needed instead of the actual order. This is because once we have found a working algorithm to find the amount it is trivial to create an algorithm for the actual parenthesization. It will, however, be discussed in the end.</p>
<p>So how would an algorithm for the optimum parenthesization look? By the chapter title you might expect that a dynamic programming method is in order (not to give the answer away or anything). So how would a dynamic programming method work? Because dynamic programming algorithms are based on optimal substructure, what would the optimal substructure in this problem be?</p>
<p>Suppose that the optimal way to parenthesize</p>
<dl>
<dd><img class="tex" alt="M_1 M_2 \dots M_n" src="//upload.wikimedia.org/math/1/8/f/18f0fa99c21c064844735ca7a70d05bc.png" /></dd>
</dl>
<p>splits the product at <img class="tex" alt="k" src="//upload.wikimedia.org/math/8/c/e/8ce4b16b22b58894aa86c421e8759df3.png" />:</p>
<dl>
<dd><img class="tex" alt="(M_1 M_2 \dots M_k)(M_{k+1} M_{k+2} \dots M_n)" src="//upload.wikimedia.org/math/5/4/5/54528282ebc1be7fc0e6328a3c1801ab.png" />.</dd>
</dl>
<p>Then the optimal solution contains the optimal solutions to the two subproblems</p>
<dl>
<dd><img class="tex" alt="(M_1 \dots M_k)" src="//upload.wikimedia.org/math/a/9/f/a9f21546d1aff539a13d77edfef760d8.png" /></dd>
<dd><img class="tex" alt="(M_{k+1} \dots M_n)" src="//upload.wikimedia.org/math/a/e/4/ae4cb612b4c77b9ceff22e633e6ca28f.png" /></dd>
</dl>
<p>That is, just in accordance with the fundamental principle of dynamic programming, the solution to the problem depends on the solution of smaller sub-problems.</p>
<p>Let's say that it takes <img class="tex" alt="c(n)" src="//upload.wikimedia.org/math/6/f/9/6f92aad59cd2c0646a2f0c5844875990.png" /> scalar multiplications to multiply matrices <img class="tex" alt="M_n" src="//upload.wikimedia.org/math/1/5/4/1547a74739c1e2b6be3ebe927017bfbb.png" /> and <img class="tex" alt="M_{n+1}" src="//upload.wikimedia.org/math/b/5/3/b5325dfd3bcbec5eebd582dcd42a0923.png" />, and <img class="tex" alt="f(m,n)" src="//upload.wikimedia.org/math/a/5/3/a53a7f70857529f682edcff165e899a4.png" /> is the number of scalar multiplications to be performed in an optimal parenthesization of the matrices <img class="tex" alt="M_m \dots M_n" src="//upload.wikimedia.org/math/2/b/6/2b6baadb8faab6f829922c9d1367066b.png" />. The definition of <img class="tex" alt="f(m,n)" src="//upload.wikimedia.org/math/a/5/3/a53a7f70857529f682edcff165e899a4.png" /> is the first step toward a solution.</p>
<p>When <img class="tex" alt="n-m=1" src="//upload.wikimedia.org/math/2/f/e/2feb6fcae2322bed80afb0b8775e614b.png" />, the formulation is trivial; it is just <img class="tex" alt="c(m)" src="//upload.wikimedia.org/math/6/3/8/638fd40dab714afadb4bd56d7dde521c.png" />. But what is it when the distance is larger? Using the observation above, we can derive a formulation. Suppose an optimal solution to the problem divides the matrices at matrices k and k+1 (i.e. <img class="tex" alt="(M_m \dots M_k)(M_{k+1} \dots M_n)" src="//upload.wikimedia.org/math/d/8/c/d8c2c886f78f954c2946e6443deaefcb.png" />) then the number of scalar multiplications are.</p>
<dl>
<dd><img class="tex" alt="f(m,k) + f(k+1,n) + c(k)" src="//upload.wikimedia.org/math/c/5/9/c5998d17549dde20dc4eca0e2dccc602.png" /></dd>
</dl>
<p>That is, the amount of time to form the first product, the amount of time it takes to form the second product, and the amount of time it takes to multiply them together. But what is this optimal value k? The answer is, of course, the value that makes the above formula assume its minimum value. We can thus form the complete definition for the function:</p>
<dl>
<dd><img class="tex" alt="f(m,n) = \begin{cases} \min_{m \le k &lt; n}f(m,k) + f(k+1,n) + c(k) &amp; \mbox{if } n-m&gt;1 \\ 0 &amp; \mbox{if } n=m\end{cases}" src="//upload.wikimedia.org/math/0/1/b/01b376c226b97035f2be64bf5d87f3ea.png" /></dd>
</dl>
<p>A straight-forward recursive solution to this would look something like this <i>(the language is <a class="external text" href="http://en.wikipedia.org/wiki/Wikipedia:Wikicode">Wikicode</a>)</i>:</p>
<pre>
function <b>f</b>(<i>m</i>, <i>n</i>) {

    if <i>m</i> == <i>n</i>
        return 0

    let <i>minCost</i> := <img class="tex" alt="\infty" src="//upload.wikimedia.org/math/d/2/4/d245777abca64ece2d5d7ca0d19fddb6.png" />

    for <i>k</i> := <i>m</i> to <i>n</i> - 1 {
        v := <b>f</b>(<i>m</i>, <i>k</i>) + <b>f</b>(<i>k</i> + 1, <i>n</i>) + <i>c</i>(<i>k</i>)
        if <i>v</i> &lt; <i>minCost</i>
            <i>minCost</i> := <i>v</i>
    }
    return <i>minCost</i>
}
</pre>
<p>This rather simple solution is, unfortunately, not a very good one. It spends mountains of time recomputing data and its running time is exponential.</p>
<div style="clear: both"></div>
<table style="background: #ffd; border: 1px solid #aaaaaa; padding: 6pt; margin: 12pt 8%; width: 60%; margin: auto;" class="notice noprint notice-todo">
<tr>
<td style="width: 58px;">
<div class="floatleft"><img alt="Clipboard" src="//upload.wikimedia.org/wikipedia/commons/thumb/1/1f/Clipboard.svg/45px-Clipboard.svg.png" width="45" height="45" srcset="//upload.wikimedia.org/wikipedia/commons/thumb/1/1f/Clipboard.svg/68px-Clipboard.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/1/1f/Clipboard.svg/90px-Clipboard.svg.png 2x" /></div>
</td>
<td>
<p><b>To do:</b><br />
write an analysis of the straight-forward-recursion method</p>
</td>
</tr>
</table>
<div style="clear: both"></div>
<div style="clear: both"></div>
<table style="background: #ffd; border: 1px solid #aaaaaa; padding: 6pt; margin: 12pt 8%; width: 60%; margin: auto;" class="notice noprint notice-todo">
<tr>
<td style="width: 58px;">
<div class="floatleft"><img alt="Clipboard" src="//upload.wikimedia.org/wikipedia/commons/thumb/1/1f/Clipboard.svg/45px-Clipboard.svg.png" width="45" height="45" srcset="//upload.wikimedia.org/wikipedia/commons/thumb/1/1f/Clipboard.svg/68px-Clipboard.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/1/1f/Clipboard.svg/90px-Clipboard.svg.png 2x" /></div>
</td>
<td>
<p><b>To do:</b><br />
write a memoization version</p>
</td>
</tr>
</table>
<div style="clear: both"></div>
<p>Using the same adaptation as above we get:</p>
<pre>
function <b>f</b>(<i>m</i>, <i>n</i>) {

    if <i>m</i> == <i>n</i>
        return 0

    else-if <i>f</i>[<i>m,n</i>] != -1:
      return <i>f</i>[<i>m,n</i>]
    fi

    let <i>minCost</i> := <img class="tex" alt="\infty" src="//upload.wikimedia.org/math/d/2/4/d245777abca64ece2d5d7ca0d19fddb6.png" />

    for <i>k</i> := <i>m</i> to <i>n</i> - 1 {
        v := <b>f</b>(<i>m</i>, <i>k</i>) + <b>f</b>(<i>k</i> + 1, <i>n</i>) + <i>c</i>(<i>k</i>)
        if <i>v</i> &lt; <i>minCost</i>
            <i>minCost</i> := <i>v</i>
    }
    <i>f</i>[<i>m,n</i>]=minCost
    return <i>minCost</i>
}
</pre>
<div style="clear: both"></div>
<table style="background: #ffd; border: 1px solid #aaaaaa; padding: 6pt; margin: 12pt 8%; width: 60%; margin: auto;" class="notice noprint notice-todo">
<tr>
<td style="width: 58px;">
<div class="floatleft"><img alt="Clipboard" src="//upload.wikimedia.org/wikipedia/commons/thumb/1/1f/Clipboard.svg/45px-Clipboard.svg.png" width="45" height="45" srcset="//upload.wikimedia.org/wikipedia/commons/thumb/1/1f/Clipboard.svg/68px-Clipboard.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/1/1f/Clipboard.svg/90px-Clipboard.svg.png 2x" /></div>
</td>
<td>
<p><b>To do:</b><br />
write a full-fledged DP version</p>
</td>
</tr>
</table>
<div style="clear: both"></div>
<h2><span class="mw-headline" id="Parsing_Any_Context-Free_Grammar">Parsing Any Context-Free Grammar</span></h2>
<p>Note that special types of context-free grammars can be parsed much more efficiently than this technique, but in terms of generality, the DP method is the only way to go.</p>
<p><br /></p>
<h1><span class="mw-headline" id="Greedy_Algorithms">Greedy Algorithms</span></h1>
<p>In the backtracking algorithms we looked at, we saw algorithms that found decision points and recursed over all options from that decision point. A <b>greedy algorithm</b> can be thought of as a backtracking algorithm where at each decision point "the best" option is already known and thus can be picked without having to recurse over any of the alternative options.</p>
<p>The name "greedy" comes from the fact that the algorithms make decisions based on a single criterion, instead of a global analysis that would take into account the decision's effect on further steps. As we will see, such a backtracking analysis will be unnecessary in the case of greedy algorithms, so it is not greedy in the sense of causing harm for only short-term gain.</p>
<p>Unlike backtracking algorithms, greedy algorithms can't be made for every problem. Not every problem is "solvable" using greedy algorithms. Viewing the finding solution to an optimization problem as a hill climbing problem greedy algorithms can be used for only those hills where at every point taking the steepest step would lead to the peak always.</p>
<p>Greedy algorithms tend to be very efficient and can be implemented in a relatively straightforward fashion. Many a times in O(n) complexity as there would be a single choice at every point. However, most attempts at creating a correct greedy algorithm fail unless a precise proof of the algorithm's correctness is first demonstrated. When a greedy strategy fails to produce optimal results on all inputs, we instead refer to it as a heuristic instead of an algorithm. Heuristics can be useful when speed is more important than exact results (for example, when "good enough" results are sufficient).</p>
<h2><span class="mw-headline" id="Event_Scheduling_Problem">Event Scheduling Problem</span></h2>
<p>The first problem we'll look at that can be solved with a greedy algorithm is the event scheduling problem. We are given a set of events that have a start time and finish time, and we need to produce a subset of these events such that no events intersect each other (that is, having overlapping times), and that we have the maximum number of events scheduled as possible.</p>
<p>Here is a formal statement of the problem:</p>
<dl>
<dd><i>Input</i>: <i>events</i>: a set of intervals <img class="tex" alt="(s_i, f_i)" src="//upload.wikimedia.org/math/d/1/0/d10f9a5fab981939bf27aafd71cf7653.png" /> where <img class="tex" alt="s_i" src="//upload.wikimedia.org/math/e/5/a/e5a7472d780a5a032c7775cc5e3ce901.png" /> is the start time, and <img class="tex" alt="f_i" src="//upload.wikimedia.org/math/d/b/b/dbb3b84cea7e7015fb1a591964fbd918.png" /> is the finish time.</dd>
<dd><i>Solution</i>: A subset <i>S</i> of <i>Events</i>.</dd>
<dd><i>Constraint</i>: No events can intersect (start time exclusive). That is, for all intervals <img class="tex" alt="i=(s_i, f_i), j=(s_j, f_j)" src="//upload.wikimedia.org/math/a/b/7/ab764cda65ce85e57e34c554f39a33d7.png" /> where <img class="tex" alt="s_i &lt; s_j" src="//upload.wikimedia.org/math/5/9/f/59fb1c995d82f4ebfb9410249ed96d3a.png" /> it holds that <img class="tex" alt="f_i\le s_j" src="//upload.wikimedia.org/math/9/4/c/94c75f92873378f40478925a23e4d3af.png" />.</dd>
<dd><i>Objective</i>: Maximize the number of scheduled events, i.e. maximize the size of the set <i>S</i>.</dd>
</dl>
<p>We first begin with a backtracking solution to the problem:</p>
<pre>
<i>// event-schedule -- schedule as many non-conflicting events as possible</i>
function <b>event-schedule</b>(<i>events</i> array of <i>s</i>[1..<i>n</i>], <i>j</i>[1..<i>n</i>]): set
  if <i>n</i> == 0: return <img class="tex" alt="\emptyset" src="//upload.wikimedia.org/math/4/d/f/4df085f70a97244c977b6ff20b1952b4.png" /> fi
  if <i>n</i> == 1: return {<i>events</i>[1]} fi
  let <i>event</i> := <i>events</i>[1]
  let <i>S1</i> := union(<b>event-schedule</b>(<i>events</i> - set of conflicting events), <i>event</i>)
  let <i>S2</i> := <b>event-schedule</b>(<i>events</i> - {<i>event</i>})
  if <i>S1</i>.size() &gt;= <i>S2</i>.size():
    return <i>S1</i>
  else
    return <i>S2</i>
  fi
end
</pre>
<p>The above algorithm will faithfully find the largest set of non-conflicting events. It brushes aside details of how the set</p>
<dl>
<dd><i>events</i> - set of conflicting events</dd>
</dl>
<p>is computed, but it would require <img class="tex" alt="O(n)" src="//upload.wikimedia.org/math/7/b/a/7ba55e7c64a9405a0b39a1107e90ca94.png" /> time. Because the algorithm makes two recursive calls on itself, each with an argument of size <img class="tex" alt="n - 1" src="//upload.wikimedia.org/math/a/4/3/a438673491daae8148eae77373b6a467.png" />, and because removing conflicts takes linear time, a recurrence for the time this algorithm takes is:</p>
<dl>
<dd><img class="tex" alt="T(n) = 2\cdot T(n - 1) + O(n)" src="//upload.wikimedia.org/math/7/6/3/7631b7bcfd14d8be580a738ae6bdecf1.png" /></dd>
</dl>
<p>which is <img class="tex" alt="O(2^{n})" src="//upload.wikimedia.org/math/a/5/b/a5bab29729331b95aeebc96eda2906ad.png" />.</p>
<div style="clear: both"></div>
<table style="background: #ffd; border: 1px solid #aaaaaa; padding: 6pt; margin: 12pt 8%; width: 60%; margin: auto;" class="notice noprint notice-todo">
<tr>
<td style="width: 58px;">
<div class="floatleft"><img alt="Clipboard" src="//upload.wikimedia.org/wikipedia/commons/thumb/1/1f/Clipboard.svg/45px-Clipboard.svg.png" width="45" height="45" srcset="//upload.wikimedia.org/wikipedia/commons/thumb/1/1f/Clipboard.svg/68px-Clipboard.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/1/1f/Clipboard.svg/90px-Clipboard.svg.png 2x" /></div>
</td>
<td>
<p><b>To do:</b><br />
a tighter bound is possible</p>
</td>
</tr>
</table>
<div style="clear: both"></div>
<p>But suppose instead of picking just the first element in the array we used some other criterion. The aim is to just pick the "right" one so that we wouldn't need two recursive calls. First, let's consider the greedy strategy of picking the shortest events first, until we can add no more events without conflicts. The idea here is that the shortest events would likely interfere less than other events.</p>
<p>There are scenarios were picking the shortest event first produces the optimal result. However, here's a scenario where that strategy is sub-optimal:</p>
<p><a href="/wiki/File:AlgorithmsShortestFirst.png" class="image"><img alt="AlgorithmsShortestFirst.png" src="//upload.wikimedia.org/wikibooks/en/d/db/AlgorithmsShortestFirst.png" width="358" height="140" /></a></p>
<p>Above, the optimal solution is to pick event A and C, instead of just B alone. Perhaps instead of the shortest event we should pick the events that have the least number of conflicts. This strategy seems more direct, but it fails in this scenario:</p>
<p><a href="/wiki/File:AlgorithmsLeastConflicts.png" class="image"><img alt="AlgorithmsLeastConflicts.png" src="//upload.wikimedia.org/wikibooks/en/f/fd/AlgorithmsLeastConflicts.png" width="358" height="238" /></a></p>
<p>Above, we can maximize the number of events by picking A, B, C, D, and E. However, the events with the least conflicts are 6, 2 and 7, 3. But picking one of 6, 2 and one of 7, 3 means that we cannot pick B, C and D, which includes three events instead of just two.</p>
<h2><span class="mw-headline" id="Dijkstra.27s_Shortest_Path_Algorithm">Dijkstra's Shortest Path Algorithm</span></h2>
<p>With two (high-level, pseudocode) transformations, Dijsktra's algorithm can be derived from the much less efficient backtracking algorithm. The trick here is to prove the transformations maintain correctness, but that's the whole insight into Dijkstra's algorithm anyway. [TODO: important to note the paradox that to solve this problem it's easier to solve a more-general version. That is, shortest path from s to all nodes, not just to t. Worthy of its own colored box.]</p>
<p>To see the workings of Dijkstra's Shortest Path Algorithm, take an example:</p>
<p>There is a start and end node, with 2 paths between them&#160;; one path has cost 30 on first hop, then 10 on last hop to the target node, with total cost 40. Another path cost 10 on first hop, 10 on second hop, and 40 on last hop, with total cost 60.</p>
<p>The start node is given distance zero so it can be at the front of a shortest distance queue, all the other nodes are given infinity or a large number e.g. 32767 .</p>
<p>This makes the start node the first current node in the queue.</p>
<p>With each iteration, the current node is the first node of a shortest path queue. It looks at all nodes adjacent to the current node;</p>
<p>For the case of the start node, in the first path it will find a node of distance 30, and in the second path, an adjacent node of distance 10. The current nodes distance , which is zero at the beginning, is added to distances of the adjacent nodes, and the distances from the start node of each node are updated , so the nodes will be 30+0 = 30 in the 1st path , and 10+0=10 in the 2nd path.</p>
<p>Importantly, also updated is a previous pointer attribute for each node, so each node will point back to the current node, which is the start node for these two nodes.</p>
<p>Each node's priority is updated in the priority queue using the new distance.</p>
<p>That ends one iteration. The current node was removed from the queue before examining its adjacent nodes.</p>
<p>In the next iteration, the front of the queue will be the node in the second path of distance 10, and it has only one adjacent node of distance 10, and that adjacent node will distance will be updated from 32767 to 10 (the current node distance) + 10 ( the distance from the current node) = 20.</p>
<p>In the next iteration, the second path node of cost 20 will be examined, and it has one adjacent hop of 40 to the target node, and the target nodes distance is updated from 32767 to 20 + 40 = 60 . The target node has its priority updated.</p>
<p>In the next iteration, the shortest path node will be the first path node of cost 30, and the target node has not been yet removed from the queue. It is also adjacent to the target node, with the total distance cost of 30 + 10 = 40.</p>
<p>Since 40 is less than 60, the previous calculated distance of the target node, the target node distance is updated to 40, and the previous pointer of the target node is updated to the node on the first path.</p>
<p>In the final iteration, the shortest path node is the target node, and the loop exits.</p>
<p>Looking at the previous pointers starting with the target node, a shortest path can be reverse constructed as a list to the start node.</p>
<p>Given the above example, what kind of data structures are needed for the nodes and the algorithm&#160;?</p>
<p><br /></p>
<div dir="ltr" class="mw-geshi mw-code mw-content-ltr">
<div class="python source-python">
<pre class="de1">
<span class="co1"># author , copyright under GFDL</span>
<span class="kw1">class</span> Node :
    <span class="kw1">def</span> <span class="kw4">__init__</span><span class="br0">(</span><span class="kw2">self</span><span class="sy0">,</span> label<span class="sy0">,</span> distance <span class="sy0">=</span> <span class="nu0">32767</span> <span class="br0">)</span>: 
	<span class="co1"># a bug in constructor, uses a shared map initializer </span>
        <span class="co1"># , adjacency_distance_map = {} ):</span>
      <span class="kw2">self</span>.<span class="me1">label</span> <span class="sy0">=</span> label
 
      <span class="kw2">self</span>.<span class="me1">adjacent</span> <span class="sy0">=</span> <span class="br0">{</span><span class="br0">}</span>  <span class="co1"># this is an adjacency map, with keys nodes, and values the adjacent distance</span>
 
      <span class="kw2">self</span>.<span class="me1">distance</span> <span class="sy0">=</span> distance   <span class="co1"># this is the updated distance from the start node, used as the node's priority</span>
      <span class="co1"># default distance is 32767</span>
 
      <span class="kw2">self</span>.<span class="me1">shortest_previous</span> <span class="sy0">=</span> <span class="kw2">None</span>  <span class="co1">#this the last shortest distance adjacent node</span>
 
    <span class="co1"># the logic is that the last adjacent distance added is recorded , for any distances of the same node added</span>
    <span class="kw1">def</span> add_adjacent<span class="br0">(</span><span class="kw2">self</span><span class="sy0">,</span> local_distance<span class="sy0">,</span> node<span class="br0">)</span>:
       <span class="kw2">self</span>.<span class="me1">adjacent</span><span class="br0">[</span>node<span class="br0">]</span><span class="sy0">=</span>local_distance
       <span class="kw1">print</span> <span class="st0">"adjacency to "</span><span class="sy0">,</span> <span class="kw2">self</span>.<span class="me1">label</span><span class="sy0">,</span> <span class="st0">" of "</span><span class="sy0">,</span> <span class="kw2">self</span>.<span class="me1">adjacent</span><span class="br0">[</span>node<span class="br0">]</span><span class="sy0">,</span> <span class="st0">" to "</span><span class="sy0">,</span> \
		node.<span class="me1">label</span>
 
    <span class="kw1">def</span> get_adjacent<span class="br0">(</span><span class="kw2">self</span><span class="br0">)</span> :
        <span class="kw1">return</span> <span class="kw2">self</span>.<span class="me1">adjacent</span>.<span class="me1">iteritems</span><span class="br0">(</span><span class="br0">)</span>      
 
    <span class="kw1">def</span> update_shortest<span class="br0">(</span> <span class="kw2">self</span><span class="sy0">,</span> node<span class="br0">)</span>:
	new_distance <span class="sy0">=</span> node.<span class="me1">adjacent</span><span class="br0">[</span><span class="kw2">self</span><span class="br0">]</span> + node.<span class="me1">distance</span>
 
	<span class="co1">#DEBUG</span>
	<span class="kw1">print</span> <span class="st0">"for node "</span><span class="sy0">,</span> node.<span class="me1">label</span><span class="sy0">,</span> <span class="st0">" updating "</span><span class="sy0">,</span> <span class="kw2">self</span>.<span class="me1">label</span><span class="sy0">,</span> \
		<span class="st0">" with distance "</span><span class="sy0">,</span> node.<span class="me1">distance</span> <span class="sy0">,</span> \
		<span class="st0">" and adjacent distance "</span><span class="sy0">,</span> node.<span class="me1">adjacent</span><span class="br0">[</span><span class="kw2">self</span><span class="br0">]</span>
 
	updated <span class="sy0">=</span> <span class="kw2">False</span>
        <span class="co1"># node's adjacency map gives the adjacent distance for this node</span>
        <span class="co1"># the new distance for the path to this (self)node is the adjacent distance plus the other node's distance</span>
        <span class="kw1">if</span> new_distance <span class="sy0">&lt;</span> <span class="kw2">self</span>.<span class="me1">distance</span> :
                <span class="co1"># if it is the shortest distance then record the distance, and make the previous node that node</span>
		<span class="kw2">self</span>.<span class="me1">distance</span> <span class="sy0">=</span> new_distance
	        <span class="kw2">self</span>.<span class="me1">shortest_previous</span><span class="sy0">=</span> node  
		updated <span class="sy0">=</span> <span class="kw2">True</span>
	<span class="kw1">return</span> updated
 
MAX_IN_PQ <span class="sy0">=</span> <span class="nu0">100000</span>   
<span class="kw1">class</span> PQ:
       <span class="kw1">def</span> <span class="kw4">__init__</span><span class="br0">(</span><span class="kw2">self</span> <span class="sy0">,</span>  sign  <span class="sy0">=</span> -<span class="nu0">1</span> <span class="br0">)</span>: 
          <span class="kw2">self</span>.<span class="me1">q</span> <span class="sy0">=</span> <span class="br0">[</span><span class="kw2">None</span> <span class="br0">]</span> * MAX_IN_PQ <span class="co1"># make the array preallocated</span>
          <span class="kw2">self</span>.<span class="me1">sign</span> <span class="sy0">=</span> sign  <span class="co1"># a negative sign is a minimum priority queue</span>
          <span class="kw2">self</span>.<span class="me1">end</span> <span class="sy0">=</span> <span class="nu0">1</span> <span class="co1"># this is the next slot of the array (self.q) to be used , </span>
          <span class="kw2">self</span>.<span class="kw2">map</span> <span class="sy0">=</span> <span class="br0">{</span><span class="br0">}</span>
 
       <span class="kw1">def</span>  insert<span class="br0">(</span> <span class="kw2">self</span><span class="sy0">,</span>  priority<span class="sy0">,</span> data<span class="br0">)</span>:
           <span class="kw2">self</span>.<span class="me1">q</span><span class="br0">[</span><span class="kw2">self</span>.<span class="me1">end</span><span class="br0">]</span> <span class="sy0">=</span> <span class="br0">(</span>priority<span class="sy0">,</span> data<span class="br0">)</span>
           <span class="co1"># sift up after insert</span>
           p <span class="sy0">=</span> <span class="kw2">self</span>.<span class="me1">end</span>
           <span class="kw2">self</span>.<span class="me1">end</span> <span class="sy0">=</span> <span class="kw2">self</span>.<span class="me1">end</span> + <span class="nu0">1</span>    
           <span class="kw2">self</span>.<span class="me1">sift_up</span><span class="br0">(</span>p<span class="br0">)</span>       
 
       <span class="kw1">def</span> sift_up<span class="br0">(</span><span class="kw2">self</span><span class="sy0">,</span> p<span class="br0">)</span>:
           <span class="co1"># p is the current node's position</span>
           <span class="co1"># q[p][0] is the priority, q[p][1] is the item or node</span>
 
           <span class="co1"># while the parent exists ( p &gt;= 1) , and parent's priority is less than the current node's priority</span>
           <span class="kw1">while</span>  p / <span class="nu0">2</span> <span class="sy0">!=</span> <span class="nu0">0</span> <span class="kw1">and</span>  <span class="kw2">self</span>.<span class="me1">q</span><span class="br0">[</span>p/<span class="nu0">2</span><span class="br0">]</span><span class="br0">[</span><span class="nu0">0</span><span class="br0">]</span>*<span class="kw2">self</span>.<span class="me1">sign</span>  <span class="sy0">&lt;</span> <span class="kw2">self</span>.<span class="me1">q</span><span class="br0">[</span>p<span class="br0">]</span><span class="br0">[</span><span class="nu0">0</span><span class="br0">]</span>*<span class="kw2">self</span>.<span class="me1">sign</span>:
              <span class="co1"># swap the parent and the current node, and make the current node's position the parent's position</span>
              tmp <span class="sy0">=</span> <span class="kw2">self</span>.<span class="me1">q</span><span class="br0">[</span>p<span class="br0">]</span>
              <span class="kw2">self</span>.<span class="me1">q</span><span class="br0">[</span>p<span class="br0">]</span> <span class="sy0">=</span> <span class="kw2">self</span>.<span class="me1">q</span><span class="br0">[</span>p/<span class="nu0">2</span><span class="br0">]</span>
              <span class="kw2">self</span>.<span class="me1">q</span><span class="br0">[</span>p/<span class="nu0">2</span><span class="br0">]</span> <span class="sy0">=</span> tmp
	      <span class="kw2">self</span>.<span class="kw2">map</span><span class="br0">[</span><span class="kw2">self</span>.<span class="me1">q</span><span class="br0">[</span>p<span class="br0">]</span><span class="br0">[</span><span class="nu0">1</span><span class="br0">]</span><span class="br0">]</span> <span class="sy0">=</span> p
              p <span class="sy0">=</span> p/<span class="nu0">2</span>
 
           <span class="co1"># this map's the node to the position in the priority queue</span>
           <span class="kw2">self</span>.<span class="kw2">map</span><span class="br0">[</span><span class="kw2">self</span>.<span class="me1">q</span><span class="br0">[</span>p<span class="br0">]</span><span class="br0">[</span><span class="nu0">1</span><span class="br0">]</span><span class="br0">]</span> <span class="sy0">=</span> p
 
           <span class="kw1">return</span> p
 
 
       <span class="kw1">def</span> remove_top<span class="br0">(</span><span class="kw2">self</span><span class="br0">)</span>:
 
            <span class="kw1">if</span>  <span class="kw2">self</span>.<span class="me1">end</span> <span class="sy0">==</span> <span class="nu0">1</span> :
              <span class="kw1">return</span> <span class="br0">(</span>-<span class="nu0">1</span><span class="sy0">,</span> <span class="kw2">None</span><span class="br0">)</span>
 
            <span class="br0">(</span>priority<span class="sy0">,</span> node<span class="br0">)</span> <span class="sy0">=</span> <span class="kw2">self</span>.<span class="me1">q</span><span class="br0">[</span><span class="nu0">1</span><span class="br0">]</span>
            <span class="co1"># put the end of the heap at the top of the heap, and sift it down to adjust the heap</span>
            <span class="co1"># after the heap's top has been removed. this takes log2(N) time, where N iis the size of the heap.</span>
 
            <span class="kw2">self</span>.<span class="me1">q</span><span class="br0">[</span><span class="nu0">1</span><span class="br0">]</span> <span class="sy0">=</span> <span class="kw2">self</span>.<span class="me1">q</span><span class="br0">[</span><span class="kw2">self</span>.<span class="me1">end</span>-<span class="nu0">1</span><span class="br0">]</span>
            <span class="kw2">self</span>.<span class="me1">end</span> <span class="sy0">=</span> <span class="kw2">self</span>.<span class="me1">end</span> - <span class="nu0">1</span>
 
            <span class="kw2">self</span>.<span class="me1">sift_down</span><span class="br0">(</span><span class="nu0">1</span><span class="br0">)</span>
 
            <span class="kw1">return</span> <span class="br0">(</span>priority<span class="sy0">,</span> node<span class="br0">)</span>
 
       <span class="kw1">def</span> sift_down<span class="br0">(</span><span class="kw2">self</span><span class="sy0">,</span> p<span class="br0">)</span>:
           <span class="kw1">while</span> <span class="nu0">1</span>:
             l <span class="sy0">=</span> p * <span class="nu0">2</span>
 
             <span class="co1"># if the left child's position is more than the size of the heap, </span>
             <span class="co1"># then left and right children don't exist</span>
             <span class="kw1">if</span> <span class="br0">(</span> l <span class="sy0">&gt;</span> <span class="kw2">self</span>.<span class="me1">end</span><span class="br0">)</span> :
               <span class="kw1">break</span>
 
             r<span class="sy0">=</span> l + <span class="nu0">1</span>
             <span class="co1"># the selected child node should have the greatest priority</span>
             t <span class="sy0">=</span> l
             <span class="kw1">if</span> r <span class="sy0">&lt;</span> <span class="kw2">self</span>.<span class="me1">end</span> <span class="kw1">and</span> <span class="kw2">self</span>.<span class="me1">q</span><span class="br0">[</span>r<span class="br0">]</span><span class="br0">[</span><span class="nu0">0</span><span class="br0">]</span>*<span class="kw2">self</span>.<span class="me1">sign</span> <span class="sy0">&gt;</span> <span class="kw2">self</span>.<span class="me1">q</span><span class="br0">[</span>l<span class="br0">]</span><span class="br0">[</span><span class="nu0">0</span><span class="br0">]</span>*<span class="kw2">self</span>.<span class="me1">sign</span> :
               t <span class="sy0">=</span> r
             <span class="kw1">print</span> <span class="st0">"checking for sift down of "</span><span class="sy0">,</span> <span class="kw2">self</span>.<span class="me1">q</span><span class="br0">[</span>p<span class="br0">]</span><span class="br0">[</span><span class="nu0">1</span><span class="br0">]</span>.<span class="me1">label</span><span class="sy0">,</span> <span class="kw2">self</span>.<span class="me1">q</span><span class="br0">[</span>p<span class="br0">]</span><span class="br0">[</span><span class="nu0">0</span><span class="br0">]</span><span class="sy0">,</span> <span class="st0">" vs child "</span><span class="sy0">,</span> <span class="kw2">self</span>.<span class="me1">q</span><span class="br0">[</span>t<span class="br0">]</span><span class="br0">[</span><span class="nu0">1</span><span class="br0">]</span>.<span class="me1">label</span><span class="sy0">,</span> <span class="kw2">self</span>.<span class="me1">q</span><span class="br0">[</span>t<span class="br0">]</span><span class="br0">[</span><span class="nu0">0</span><span class="br0">]</span>
             <span class="co1"># if the selected child with the greatest priority has a higher priority than the current node</span>
             <span class="kw1">if</span> <span class="kw2">self</span>.<span class="me1">q</span><span class="br0">[</span>t<span class="br0">]</span> <span class="br0">[</span><span class="nu0">0</span><span class="br0">]</span> * <span class="kw2">self</span>. <span class="me1">sign</span>  <span class="sy0">&gt;</span>  <span class="kw2">self</span>.<span class="me1">q</span> <span class="br0">[</span>p<span class="br0">]</span> <span class="br0">[</span><span class="nu0">0</span><span class="br0">]</span> * <span class="kw2">self</span>.<span class="me1">sign</span> :
               <span class="co1"># swap the current node with that child, and update the mapping of the child node to its new position</span>
               tmp <span class="sy0">=</span> <span class="kw2">self</span>. <span class="me1">q</span> <span class="br0">[</span> t <span class="br0">]</span>
               <span class="kw2">self</span>. <span class="me1">q</span> <span class="br0">[</span> t <span class="br0">]</span> <span class="sy0">=</span> <span class="kw2">self</span>.<span class="me1">q</span> <span class="br0">[</span> p <span class="br0">]</span>
               <span class="kw2">self</span>. <span class="me1">q</span> <span class="br0">[</span> p <span class="br0">]</span> <span class="sy0">=</span> tmp
               <span class="kw2">self</span>.<span class="kw2">map</span> <span class="br0">[</span> tmp <span class="br0">[</span><span class="nu0">1</span> <span class="br0">]</span> <span class="br0">]</span> <span class="sy0">=</span> p
               p <span class="sy0">=</span> t
             <span class="kw1">else</span>: <span class="kw1">break</span>    <span class="co1"># end the swap if the greatest priority child has a lesser priority than the current node</span>
 
           <span class="co1"># after the sift down, update the new position of the current node.</span>
           <span class="kw2">self</span>.<span class="kw2">map</span> <span class="br0">[</span> <span class="kw2">self</span>.<span class="me1">q</span><span class="br0">[</span>p<span class="br0">]</span><span class="br0">[</span><span class="nu0">1</span><span class="br0">]</span> <span class="br0">]</span> <span class="sy0">=</span> p
           <span class="kw1">return</span> p
 
       <span class="kw1">def</span>  update_priority<span class="br0">(</span><span class="kw2">self</span><span class="sy0">,</span> priority<span class="sy0">,</span> data <span class="br0">)</span> :
 
            p <span class="sy0">=</span> <span class="kw2">self</span>. <span class="kw2">map</span><span class="br0">[</span> data <span class="br0">]</span>
	    <span class="kw1">print</span> <span class="st0">"priority prior update"</span><span class="sy0">,</span> p<span class="sy0">,</span> <span class="st0">"for priority"</span><span class="sy0">,</span> priority<span class="sy0">,</span> <span class="st0">" previous priority"</span><span class="sy0">,</span> <span class="kw2">self</span>.<span class="me1">q</span><span class="br0">[</span>p<span class="br0">]</span><span class="br0">[</span><span class="nu0">0</span><span class="br0">]</span>
            <span class="kw1">if</span> p <span class="kw1">is</span> <span class="kw2">None</span> : 
               <span class="kw1">return</span> -<span class="nu0">1</span>
 
            <span class="kw2">self</span>.<span class="me1">q</span><span class="br0">[</span>p<span class="br0">]</span>  <span class="sy0">=</span> <span class="br0">(</span>priority<span class="sy0">,</span> <span class="kw2">self</span>.<span class="me1">q</span><span class="br0">[</span>p<span class="br0">]</span><span class="br0">[</span><span class="nu0">1</span><span class="br0">]</span><span class="br0">)</span>
            p <span class="sy0">=</span> <span class="kw2">self</span>.<span class="me1">sift_up</span><span class="br0">(</span>p<span class="br0">)</span>
            p <span class="sy0">=</span> <span class="kw2">self</span>.<span class="me1">sift_down</span><span class="br0">(</span>p<span class="br0">)</span>
	    <span class="kw1">print</span> <span class="st0">"updated "</span><span class="sy0">,</span> <span class="kw2">self</span>.<span class="me1">q</span><span class="br0">[</span>p<span class="br0">]</span><span class="br0">[</span><span class="nu0">1</span><span class="br0">]</span>.<span class="me1">label</span> <span class="sy0">,</span> p<span class="sy0">,</span> <span class="st0">"priority now "</span><span class="sy0">,</span> <span class="kw2">self</span>.<span class="me1">q</span><span class="br0">[</span>p<span class="br0">]</span><span class="br0">[</span><span class="nu0">0</span><span class="br0">]</span>
 
            <span class="kw1">return</span> p
 
<span class="kw1">class</span> NoPathToTargetNode <span class="br0">(</span> BaseException<span class="br0">)</span>:
  <span class="kw1">pass</span>
 
<span class="kw1">def</span> test_1<span class="br0">(</span><span class="br0">)</span> :
     st <span class="sy0">=</span>  Node<span class="br0">(</span><span class="st0">'start'</span><span class="sy0">,</span> <span class="nu0">0</span><span class="br0">)</span>
     p1a <span class="sy0">=</span>  Node<span class="br0">(</span><span class="st0">'p1a'</span><span class="br0">)</span>
     p1b <span class="sy0">=</span>  Node<span class="br0">(</span><span class="st0">'p1b'</span><span class="br0">)</span>
     p2a <span class="sy0">=</span>  Node<span class="br0">(</span><span class="st0">'p2a'</span><span class="br0">)</span>
     p2b <span class="sy0">=</span>  Node<span class="br0">(</span><span class="st0">'p2b'</span><span class="br0">)</span>
     p2c <span class="sy0">=</span> Node<span class="br0">(</span><span class="st0">'p2c'</span><span class="br0">)</span>
     p2d <span class="sy0">=</span> Node<span class="br0">(</span><span class="st0">'p2d'</span><span class="br0">)</span> 
     targ <span class="sy0">=</span>  Node<span class="br0">(</span><span class="st0">'target'</span><span class="br0">)</span>
     st.<span class="me1">add_adjacent</span> <span class="br0">(</span> <span class="nu0">30</span><span class="sy0">,</span> p1a<span class="br0">)</span>
     <span class="co1">#st.add_adjacent ( 10, p2a)</span>
     st.<span class="me1">add_adjacent</span> <span class="br0">(</span> <span class="nu0">20</span><span class="sy0">,</span> p2a<span class="br0">)</span>
     <span class="co1">#p1a.add_adjacent(10, targ)</span>
     p1a.<span class="me1">add_adjacent</span><span class="br0">(</span><span class="nu0">40</span><span class="sy0">,</span> targ<span class="br0">)</span>
     p1a.<span class="me1">add_adjacent</span><span class="br0">(</span><span class="nu0">10</span><span class="sy0">,</span> p1b<span class="br0">)</span>
     p1b.<span class="me1">add_adjacent</span><span class="br0">(</span><span class="nu0">10</span><span class="sy0">,</span> targ<span class="br0">)</span>
     <span class="co1"># testing alternative</span>
     <span class="co1">#p1b.add_adjacent(20, targ)</span>
     p2a.<span class="me1">add_adjacent</span><span class="br0">(</span><span class="nu0">10</span><span class="sy0">,</span> p2b<span class="br0">)</span>
     p2b.<span class="me1">add_adjacent</span><span class="br0">(</span><span class="nu0">5</span><span class="sy0">,</span>p2c<span class="br0">)</span>
     p2c.<span class="me1">add_adjacent</span><span class="br0">(</span><span class="nu0">5</span><span class="sy0">,</span>p2d<span class="br0">)</span>
     <span class="co1">#p2d.add_adjacent(5,targ)</span>
     <span class="co1">#chooses the alternate path</span>
     p2d.<span class="me1">add_adjacent</span><span class="br0">(</span><span class="nu0">15</span><span class="sy0">,</span>targ<span class="br0">)</span>
     pq <span class="sy0">=</span>  PQ<span class="br0">(</span><span class="br0">)</span>
 
     <span class="co1"># st.distance is 0, but the other's have default starting distance 32767</span>
     pq.<span class="me1">insert</span><span class="br0">(</span> st.<span class="me1">distance</span><span class="sy0">,</span> st<span class="br0">)</span>
     pq.<span class="me1">insert</span><span class="br0">(</span> p1a.<span class="me1">distance</span><span class="sy0">,</span> p1a<span class="br0">)</span>
     pq.<span class="me1">insert</span><span class="br0">(</span> p2a.<span class="me1">distance</span><span class="sy0">,</span> p2a<span class="br0">)</span>
     pq.<span class="me1">insert</span><span class="br0">(</span> p2b.<span class="me1">distance</span><span class="sy0">,</span> p2b<span class="br0">)</span>
     pq.<span class="me1">insert</span><span class="br0">(</span>targ.<span class="me1">distance</span><span class="sy0">,</span> targ<span class="br0">)</span>
     pq.<span class="me1">insert</span><span class="br0">(</span> p2c.<span class="me1">distance</span><span class="sy0">,</span> p2c<span class="br0">)</span>
     pq.<span class="me1">insert</span><span class="br0">(</span> p2d.<span class="me1">distance</span><span class="sy0">,</span> p2d<span class="br0">)</span>
 
     pq.<span class="me1">insert</span><span class="br0">(</span>p1b.<span class="me1">distance</span><span class="sy0">,</span> p1b<span class="br0">)</span>
 
     node <span class="sy0">=</span> <span class="kw2">None</span>
 
     <span class="kw1">while</span>  node <span class="sy0">!=</span>  targ :
      <span class="br0">(</span>pr<span class="sy0">,</span> node <span class="br0">)</span> <span class="sy0">=</span> pq.<span class="me1">remove_top</span><span class="br0">(</span><span class="br0">)</span>
      <span class="co1">#debug</span>
      <span class="kw1">print</span> <span class="st0">"node "</span><span class="sy0">,</span> node.<span class="me1">label</span><span class="sy0">,</span> <span class="st0">" removed from top "</span>
      <span class="kw1">if</span>  node <span class="kw1">is</span> <span class="kw2">None</span>:
               <span class="kw1">print</span> <span class="st0">"target node not in queue"</span>
               <span class="kw1">raise</span> 
      <span class="kw1">elif</span> pr <span class="sy0">==</span> <span class="nu0">32767</span>:
               <span class="kw1">print</span> <span class="st0">"max distance encountered so no further nodes updated. No path to target node."</span>
               <span class="kw1">raise</span> NoPathToTargetNode
 
      <span class="co1"># update the distance to the start node using this node's distance to all of the nodes adjacent to it, and update its priority if </span>
      <span class="co1"># a shorter distance was found for an adjacent node ( .update_shortest(..) returns true ).</span>
      <span class="co1"># this is the greedy part of the dijsktra's algorithm, always greedy for the shortest distance using the priority queue.</span>
      <span class="kw1">for</span> adj_node <span class="sy0">,</span> dist <span class="kw1">in</span> node.<span class="me1">get_adjacent</span><span class="br0">(</span><span class="br0">)</span>:
        <span class="co1">#debug</span>
        <span class="kw1">print</span> <span class="st0">"updating adjacency from "</span><span class="sy0">,</span> node.<span class="me1">label</span><span class="sy0">,</span> <span class="st0">" to "</span><span class="sy0">,</span> adj_node.<span class="me1">label</span>
        <span class="kw1">if</span> adj_node.<span class="me1">update_shortest</span><span class="br0">(</span> node <span class="br0">)</span>:
		pq.<span class="me1">update_priority</span><span class="br0">(</span>  adj_node.<span class="me1">distance</span><span class="sy0">,</span> adj_node<span class="br0">)</span> 
 
      <span class="kw1">print</span> <span class="st0">"node and targ "</span><span class="sy0">,</span> node<span class="sy0">,</span> targ <span class="sy0">,</span> node <span class="sy0">&lt;&gt;</span> targ 
     <span class="kw1">print</span> <span class="st0">"length of path"</span><span class="sy0">,</span> targ.<span class="me1">distance</span>
     <span class="kw1">print</span> <span class="st0">" shortest path"</span>
 
     <span class="co1">#create a reverse list from the target node, through the shortes path nodes to the start node</span>
     node <span class="sy0">=</span> targ
 
     path <span class="sy0">=</span> <span class="br0">[</span><span class="br0">]</span>
     <span class="kw1">while</span> node <span class="sy0">&lt;&gt;</span> <span class="kw2">None</span> :
        path.<span class="me1">append</span><span class="br0">(</span>node<span class="br0">)</span>
        node <span class="sy0">=</span> node. <span class="me1">shortest_previous</span>
 
     <span class="kw1">for</span> node <span class="kw1">in</span> <span class="kw2">reversed</span><span class="br0">(</span>path<span class="br0">)</span>:  <span class="co1"># new iterator version of list.reverse()</span>
        <span class="kw1">print</span> node.<span class="me1">label</span>
 
<span class="kw1">if</span> __name__ <span class="sy0">==</span> <span class="st0">"__main__"</span>:
  test_1<span class="br0">(</span><span class="br0">)</span>
</pre></div>
</div>
<h2><span class="mw-headline" id="Minimum_spanning_tree">Minimum spanning tree</span></h2>
<table class="plainlinks noprint messagebox notice" style="width:250px; float:right; clear:right; margin:0px; margin-left:10px;">
<tr style="vertical-align:middle;">
<td style="padding:0.1em; text-align:center; vertical-align:middle; width:45px; border:none;"><img alt="Wikipedia-logo.png" src="//upload.wikimedia.org/wikipedia/commons/thumb/6/63/Wikipedia-logo.png/40px-Wikipedia-logo.png" width="40" height="40" srcset="//upload.wikimedia.org/wikipedia/commons/thumb/6/63/Wikipedia-logo.png/60px-Wikipedia-logo.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/6/63/Wikipedia-logo.png/80px-Wikipedia-logo.png 2x" /></td>
<td style="color:black; text-align:left; vertical-align:middle; padding:0.5em; padding-left:0em; border:none;">
<p><a href="//en.wikipedia.org/wiki/" class="extiw" title="w:">Wikipedia</a> has related information at <a class="external text" href="//en.wikipedia.org/wiki/Minimum_spanning_tree"><i><b>Minimum spanning tree</b></i></a></p>
</td>
</tr>
</table>
<p><br /></p>
<h1><span class="mw-headline" id="Hill_Climbing">Hill Climbing</span></h1>
<p><b>Hill climbing</b> is a technique for certain classes of optimization problems. The idea is to start with a sub-optimal solution to a problem (i.e., <i>start at the base of a hill</i>) and then repeatedly improve the solution (<i>walk up the hill</i>) until some condition is maximized (<i>the top of the hill is reached</i>).</p>
<table width="80%">
<tr>
<td style="background-color: #FFFFEE; border: solid 1px #FFC92E; padding: 1em;" valign="top"><b>Hill-Climbing Methodology</b><br />
<ol>
<li>Construct a sub-optimal solution that meets the constraints of the problem</li>
<li>Take the solution and make an improvement upon it</li>
<li>Repeatedly improve the solution until no more improvements are necessary/possible</li>
</ol>
</td>
</tr>
</table>
<p>One of the most popular hill-climbing problems is the network flow problem. Although network flow may sound somewhat specific it is important because it has high expressive power: for example, many algorithmic problems encountered in practice can actually be considered special cases of network flow. After covering a simple example of the hill-climbing approach for a numerical problem we cover network flow and then present examples of applications of network flow.</p>
<h2><span class="mw-headline" id="Newton.27s_Root_Finding_Method">Newton's Root Finding Method</span></h2>
<div class="thumb tright">
<div class="thumbinner" style="width:302px;"><a href="/wiki/File:Newton_iteration.png" class="image"><img alt="" src="//upload.wikimedia.org/wikipedia/commons/thumb/f/f0/Newton_iteration.png/300px-Newton_iteration.png" width="300" height="247" class="thumbimage" srcset="//upload.wikimedia.org/wikipedia/commons/thumb/f/f0/Newton_iteration.png/450px-Newton_iteration.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/f/f0/Newton_iteration.png/600px-Newton_iteration.png 2x" /></a>
<div class="thumbcaption">
<div class="magnify"><a href="/wiki/File:Newton_iteration.png" class="internal" title="Enlarge"><img src="//bits.wikimedia.org/static-1.23wmf7/skins/common/images/magnify-clip.png" width="15" height="11" alt="" /></a></div>
An illustration of Newton's method: The zero of the <i>f(x)</i> function is at <i>x</i>. We see that the guess <i>x<sub>n+1</sub></i> is a better guess than <i>x<sub>n</sub></i> because it is closer to <i>x</i>. (<i>from <a href="//en.wikipedia.org/wiki/Newton%27s_method" class="extiw" title="w:Newton's method">Wikipedia</a></i>)</div>
</div>
</div>
<p>Newton's Root Finding Method is a three-centuries-old algorithm for finding numerical approximations to roots of a function (that is a point <img class="tex" alt="x" src="//upload.wikimedia.org/math/9/d/d/9dd4e461268c8034f5c8564e155c67a6.png" /> where the function <img class="tex" alt="f(x)" src="//upload.wikimedia.org/math/5/0/b/50bbd36e1fd2333108437a2ca378be62.png" /> becomes zero), starting from an initial guess. You need to know the function <img class="tex" alt="f(x)\," src="//upload.wikimedia.org/math/5/5/0/550f51512f9bb16a0f613ae65e1d3088.png" /> and its first derivative <img class="tex" alt="f'(x)\," src="//upload.wikimedia.org/math/b/2/b/b2bf76697fa80b174e04943d1777bcf6.png" /> for this algorithm. The idea is the following: In the vicinity of the initial guess <img class="tex" alt="x_0" src="//upload.wikimedia.org/math/0/b/2/0b21a666a81629962ade8afd967826ed.png" /> we can form the Taylor expansion of the function</p>
<dl>
<dd><img class="tex" alt="f(x)=f(x_0+\epsilon)\," src="//upload.wikimedia.org/math/a/3/d/a3dd5b3a5f64ad46380c13edb8d8151d.png" /><img class="tex" alt="\approx f(x_0)+\epsilon f'(x_0)" src="//upload.wikimedia.org/math/9/4/1/941664c61c5c7ee64aec8d04d8df1581.png" /><img class="tex" alt="+\frac{\epsilon^2}{2} f''(x_0)+..." src="//upload.wikimedia.org/math/b/3/5/b358a1cb96f734c2c6a4791ee180cc2c.png" /></dd>
</dl>
<p>which gives a good approximation to the function near <img class="tex" alt="x_0" src="//upload.wikimedia.org/math/0/b/2/0b21a666a81629962ade8afd967826ed.png" />. Taking only the first two terms on the right hand side, setting them equal to zero, and solving for <img class="tex" alt="\epsilon" src="//upload.wikimedia.org/math/c/5/0/c50b9e82e318d4c163e4b1b060f7daf5.png" />, we obtain</p>
<dl>
<dd><img class="tex" alt="\epsilon=-\frac{f(x_0)}{f'(x_0)}" src="//upload.wikimedia.org/math/c/a/6/ca6dd883a103f85d31d6026ec39411f8.png" /></dd>
</dl>
<p>which we can use to construct a better solution</p>
<dl>
<dd><img class="tex" alt="x_1=x_0+\epsilon=x_0-\frac{f(x_0)}{f'(x_0)}." src="//upload.wikimedia.org/math/b/8/5/b856f37cba71272dac9cb76ce208253a.png" /></dd>
</dl>
<p>This new solution can be the starting point for applying the same procedure again. Thus, in general a better approximation can be constructed by repeatedly applying</p>
<dl>
<dd><img class="tex" alt="x_{n+1}=x_n-\frac{f(x_n)}{f'(x_n)}." src="//upload.wikimedia.org/math/4/1/c/41cb7e4f10c06202b86e92c9e1125a81.png" /></dd>
</dl>
<p>As shown in the illustration, this is nothing else but the construction of the zero from the tangent at the initial guessing point. In general, Newton's root finding method converges quadratically, except when the first derivative of the solution <img class="tex" alt="f'(x)=0\," src="//upload.wikimedia.org/math/a/c/b/acbe5f509f3b03f4f0e4ddf0a5056360.png" /> vanishes at the root.</p>
<p>Coming back to the "Hill climbing" analogy, we could apply Newton's root finding method not to the function <img class="tex" alt="f(x)\," src="//upload.wikimedia.org/math/5/5/0/550f51512f9bb16a0f613ae65e1d3088.png" />, but to its first derivative <img class="tex" alt="f'(x)\," src="//upload.wikimedia.org/math/b/2/b/b2bf76697fa80b174e04943d1777bcf6.png" />, that is look for <img class="tex" alt="x" src="//upload.wikimedia.org/math/9/d/d/9dd4e461268c8034f5c8564e155c67a6.png" /> such that <img class="tex" alt="f'(x)=0\," src="//upload.wikimedia.org/math/a/c/b/acbe5f509f3b03f4f0e4ddf0a5056360.png" />. This would give the extremal positions of the function, its maxima and minima. Starting Newton's method close enough to a maximum this way, we climb the hill.</p>
<p>Instead of regarding continuous functions, the hill-climbing method can also be applied to discrete networks.</p>
<h2><span class="mw-headline" id="Network_Flow">Network Flow</span></h2>
<p>Suppose you have a directed graph (possibly with cycles) with one vertex labeled as the source and another vertex labeled as the destination or the "sink". The source vertex only has edges coming out of it, with no edges going into it. Similarly, the destination vertex only has edges going into it, with no edges coming out of it. We can assume that the graph fully connected with no dead-ends; i.e., for every vertex (except the source and the sink), there is at least one edge going into the vertex and one edge going out of it.</p>
<p>We assign a "capacity" to each edge, and initially we'll consider only integral-valued capacities. The following graph meets our requirements, where "s" is the source and "t" is the destination:</p>
<p><a href="/wiki/File:Algorithms-NetFlow1.png" class="image"><img alt="Algorithms-NetFlow1.png" src="//upload.wikimedia.org/wikibooks/en/9/98/Algorithms-NetFlow1.png" width="443" height="280" /></a></p>
<p>We'd like now to imagine that we have some series of inputs arriving at the source that we want to carry on the edges over to the sink. The number of units we can send on an edge at a time must be less than or equal to the edge's capacity. You can think of the vertices as cities and the edges as roads between the cities and we want to send as many cars from the source city to the destination city as possible. The constraint is that we cannot send more cars down a road than its capacity can handle.</p>
<p><b>The goal of network flow</b> is to send as much traffic from <img class="tex" alt="s" src="//upload.wikimedia.org/math/0/3/c/03c7c0ace395d80182db07ae2c30f034.png" /> to <img class="tex" alt="t" src="//upload.wikimedia.org/math/e/3/5/e358efa489f58062f10dd7316b65649e.png" /> as each street can bear.</p>
<p>To organize the traffic routes, we can build a list of different paths from city <img class="tex" alt="s" src="//upload.wikimedia.org/math/0/3/c/03c7c0ace395d80182db07ae2c30f034.png" /> to city <img class="tex" alt="t" src="//upload.wikimedia.org/math/e/3/5/e358efa489f58062f10dd7316b65649e.png" />. Each path has a carrying capacity equal to the smallest capacity value for any edge on the path; for example, consider the following path <img class="tex" alt="p" src="//upload.wikimedia.org/math/8/3/8/83878c91171338902e0fe0fb97a8c47a.png" />:</p>
<p><a href="/wiki/File:Algorithms-NetFlow2.png" class="image"><img alt="Algorithms-NetFlow2.png" src="//upload.wikimedia.org/wikibooks/en/4/46/Algorithms-NetFlow2.png" width="443" height="290" /></a></p>
<p>Even though the final edge of <img class="tex" alt="p" src="//upload.wikimedia.org/math/8/3/8/83878c91171338902e0fe0fb97a8c47a.png" /> has a capacity of 8, that edge only has one car traveling on it because the edge before it only has a capacity of 1 (thus, that edge is at full capacity). After using this path, we can compute the <b>residual graph</b> by subtracting 1 from the capacity of each edge:</p>
<p><a href="/wiki/File:Algorithms-NetFlow3.png" class="image"><img alt="Algorithms-NetFlow3.png" src="//upload.wikimedia.org/wikibooks/en/3/32/Algorithms-NetFlow3.png" width="443" height="280" /></a></p>
<p>(We subtracted 1 from the capacity of each edge in <img class="tex" alt="p" src="//upload.wikimedia.org/math/8/3/8/83878c91171338902e0fe0fb97a8c47a.png" /> because 1 was the carrying capacity of <img class="tex" alt="p" src="//upload.wikimedia.org/math/8/3/8/83878c91171338902e0fe0fb97a8c47a.png" />.) We can say that path <img class="tex" alt="p" src="//upload.wikimedia.org/math/8/3/8/83878c91171338902e0fe0fb97a8c47a.png" /> has a flow of 1. Formally, a <b>flow</b> is an assignment <img class="tex" alt="f(e)" src="//upload.wikimedia.org/math/6/5/3/653ffcb912ba48b85050f5b382ddf94b.png" /> of values to the set of edges in the graph <img class="tex" alt="G = (V, E)" src="//upload.wikimedia.org/math/9/e/9/9e9992d6bf50b7580f971487c466a8cb.png" /> such that:</p>
<dl>
<dd>1. <img class="tex" alt="\forall e\in E: f(e)\in\R" src="//upload.wikimedia.org/math/8/0/f/80f8652530b57b53fe476665f6925293.png" /></dd>
<dd>2. <img class="tex" alt="\forall (u,v)\in E: f((u,v)) = -f((v,u))" src="//upload.wikimedia.org/math/a/d/0/ad0d6d860b855c29cdc53619e737c290.png" /></dd>
<dd>3. <img class="tex" alt="\forall u\in V, u\ne s,t: \sum_{v\in V}f(u,v) = 0" src="//upload.wikimedia.org/math/c/9/b/c9b6eb1aab7e1cd626ae196ef006b1dd.png" /></dd>
<dd>4. <img class="tex" alt="\forall e\in E: f(e)\le c(e)" src="//upload.wikimedia.org/math/e/1/8/e18544f9618f690082a7e9c7ecea7c52.png" /></dd>
</dl>
<p>Where <img class="tex" alt="s" src="//upload.wikimedia.org/math/0/3/c/03c7c0ace395d80182db07ae2c30f034.png" /> is the source node and <img class="tex" alt="t" src="//upload.wikimedia.org/math/e/3/5/e358efa489f58062f10dd7316b65649e.png" /> is the sink node, and <img class="tex" alt="c(e)\ge 0" src="//upload.wikimedia.org/math/6/e/f/6efe269944c66a2ac599909ac79c2906.png" /> is the capacity of edge <img class="tex" alt="e" src="//upload.wikimedia.org/math/e/1/6/e1671797c52e15f763380b45e841ec32.png" />. We define the value of a flow <img class="tex" alt="f" src="//upload.wikimedia.org/math/8/f/a/8fa14cdd754f91cc6554c9e71929cce7.png" /> to be:</p>
<dl>
<dd><img class="tex" alt="\textrm{Value}(f) = \sum_{v\in V} f((s, v))" src="//upload.wikimedia.org/math/3/e/e/3ee4db2aab71af66ddcdedcf4f23994b.png" /></dd>
</dl>
<p>The goal of network flow is to find an <img class="tex" alt="f" src="//upload.wikimedia.org/math/8/f/a/8fa14cdd754f91cc6554c9e71929cce7.png" /> such that <img class="tex" alt="\textrm{Value}(f)" src="//upload.wikimedia.org/math/0/8/3/08395e38b0fb8ba0944b8d835aa7e0e0.png" /> is maximal. To be maximal means that there is no other flow assignment that obeys the constraints 1-4 that would have a higher value. The traffic example can describe what the four flow constraints mean:</p>
<ol>
<li><img class="tex" alt="\forall e\in E: f(e)\in\R" src="//upload.wikimedia.org/math/8/0/f/80f8652530b57b53fe476665f6925293.png" />. This rule simply defines a flow to be a function from edges in the graph to real numbers. The function is defined for every edge in the graph. You could also consider the "function" to simply be a mapping: Every edge can be an index into an array and the value of the array at an edge is the value of the flow function at that edge.</li>
<li><img class="tex" alt="\forall (u,v)\in E: f((u,v)) = -f((v,u))" src="//upload.wikimedia.org/math/a/d/0/ad0d6d860b855c29cdc53619e737c290.png" />. This rule says that if there is some traffic flowing from node <i>u</i> to node <i>v</i> then there should be considered negative that amount flowing from <i>v</i> to <i>u</i>. For example, if two cars are flowing from city <i>u</i> to city <i>v</i>, then negative two cars are going in the other direction. Similarly, if three cars are going from city <i>u</i> to city <i>v</i> and two cars are going city <i>v</i> to city <i>u</i> then the net effect is the same as if one car was going from city <i>u</i> to city <i>v</i> and no cars are going from city <i>v</i> to city <i>u</i>.</li>
<li><img class="tex" alt="\forall u\in V, u\ne s,t: \sum_{v\in V}f(u,v) = 0" src="//upload.wikimedia.org/math/c/9/b/c9b6eb1aab7e1cd626ae196ef006b1dd.png" />. This rule says that the net flow (except for the source and the destination) should be neutral. That is, you won't ever have more cars going into a city than you would have coming out of the city. New cars can only come from the source, and cars can only be stored in the destination. Similarly, whatever flows out of <i>s</i> must eventually flow into <i>t</i>. Note that if a city has three cars coming into it, it could send two cars to one city and the remaining car to a different city. Also, a city might have cars coming into it from multiple sources (although all are ultimately from city <i>s</i>).</li>
<li><img class="tex" alt="\forall e\in E: f(e)\le c(e)" src="//upload.wikimedia.org/math/e/1/8/e18544f9618f690082a7e9c7ecea7c52.png" />.</li>
</ol>
<h2><span class="mw-headline" id="The_Ford-Fulkerson_Algorithm">The Ford-Fulkerson Algorithm</span></h2>
<p>The following algorithm computes the maximal flow for a given graph with non-negative capacities. What the algorithm does can be easy to understand, but it's non-trivial to show that it terminates and provides an optimal solution.</p>
<pre>
function <b>net-flow</b>(graph (<i>V</i>, <i>E</i>), node <i>s</i>, node <i>t</i>, cost <i>c</i>): flow
  initialize <i>f</i>(<i>e</i>) := 0 for all <i>e</i> in <i>E</i>
  loop while not <i>done</i>
    for all <i>e</i> in <i>E</i>:                         <i>// compute residual capacities</i>
      let <i>cf</i>(<i>e</i>) := <i>c</i>(<i>e</i>) - <i>f</i>(<i>e</i>)
    repeat
    
    let <i>Gf</i> := (<i>V</i>, {<i>e</i> : <i>e</i> in <i>E</i> and <i>cf</i>(<i>e</i>) &gt; 0})

    find a path <i>p</i> from <i>s</i> to <i>t</i> in <i>Gf</i>         <i>// e.g., use depth first search</i>
    if no path <i>p</i> exists: signal <i>done</i>

    let <i>path-capacities</i> := map(<i>p</i>, <i>cf</i>)       <i>// a path is a set of edges</i>
    let <i>m</i> := min-val-of(<i>path-capacities</i>)    <i>// smallest residual capacity of p</i>
    for all (<i>u</i>, <i>v</i>) in <i>p</i>:                    <i>// maintain flow constraints</i>
      <i>f</i>((<i>u</i>, <i>v</i>)) := <i>f</i>((<i>u</i>, <i>v</i>)) + <i>m</i>
      <i>f</i>((<i>v</i>, <i>u</i>)) := <i>f</i>((<i>v</i>, <i>u</i>)) - <i>m</i>
    repeat
  repeat
end
</pre>
<div style="clear: both"></div>
<table style="background: #ffd; border: 1px solid #aaaaaa; padding: 6pt; margin: 12pt 8%; width: 60%; margin: auto;" class="notice noprint notice-todo">
<tr>
<td style="width: 58px;">
<div class="floatleft"><img alt="Clipboard" src="//upload.wikimedia.org/wikipedia/commons/thumb/1/1f/Clipboard.svg/45px-Clipboard.svg.png" width="45" height="45" srcset="//upload.wikimedia.org/wikipedia/commons/thumb/1/1f/Clipboard.svg/68px-Clipboard.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/1/1f/Clipboard.svg/90px-Clipboard.svg.png 2x" /></div>
</td>
<td>
<p><b>To do:</b><br />
explain, hopefully using pictures, what the algorithm is doing. Explain its run time. Prove that it is optimal. Show an optimization, by "remembering" the Depth First Search to cut down the time the algorithm takes.</p>
</td>
</tr>
</table>
<div style="clear: both"></div>
<h2><span class="mw-headline" id="Applications_of_Network_Flow">Applications of Network Flow</span></h2>
<p>1. finding out maximum bi - partite matching . 2. finding out min cut of a graph .</p>
<h1><span class="mw-headline" id="Ada_Implementation">Ada Implementation</span></h1>
<h2><span class="mw-headline" id="Introduction_3">Introduction</span></h2>
<p>Welcome to the Ada implementations of the <a href="/wiki/Algorithms" title="Algorithms">Algorithms</a> Wikibook. For those who are new to <a href="/wiki/Ada_Programming" title="Ada Programming">Ada Programming</a> a few notes:</p>
<ul>
<li>All examples are fully functional with all the needed input and output operations. However, only the code needed to outline the algorithms at hand is copied into the text - the full samples are available via the download links. <small>(Note: It can take up to 48 hours until the cvs is updated)</small>.</li>
<li>We seldom use predefined types in the sample code but define special types suitable for the algorithms at hand.</li>
<li>Ada allows for default function parameters; however, we always fill in and name all parameters, so the reader can see which options are available.</li>
<li>We seldom use shortcuts - like using the attributes <a href="/wiki/Ada_Programming/Attributes/%27Image" title="Ada Programming/Attributes/'Image"><font style="color:teal">Image</font></a> or <a href="/wiki/Ada_Programming/Attributes/%27Value" title="Ada Programming/Attributes/'Value"><font style="color:teal">Value</font></a> for String &lt;=&gt; Integer conversions.</li>
</ul>
<p>All these rules make the code more elaborate than perhaps needed. However, we also hope it makes the code easier to understand</p>
<p><br /></p>
<h2><span class="mw-headline" id="Chapter_1:_Introduction">Chapter 1: Introduction</span></h2>
<p>The following subprograms are implementations of the <a href="/wiki/Algorithms/Introduction#Inventing_an_Algorithm" title="Algorithms/Introduction"><i>Inventing an Algorithm</i> examples</a>.</p>
<h3><span class="mw-headline" id="To_Lower">To Lower</span></h3>
<p>The Ada example code does not append to the array as the algorithms. Instead we create an empty array of the desired length and then replace the characters inside.</p>
<div style="background-color: snow; border: solid 1px PeachPuff; padding: 1em;">File: to_lower_1.adb <small>(<a rel="nofollow" class="external text" href="http://wikibook-ada.svn.sourceforge.net/viewvc/wikibook-ada/trunk/demos/Source/to_lower_1.adb?view=markup">view</a>, <a rel="nofollow" class="external text" href="http://wikibook-ada.svn.sourceforge.net/viewvc/*checkout*/wikibook-ada/trunk/demos/Source/to_lower_1.adb">plain text</a>, <a rel="nofollow" class="external text" href="https://sourceforge.net/project/showfiles.php?group_id=124904">download page</a>, <a rel="nofollow" class="external text" href="http://wikibook-ada.sourceforge.net/html/index.html">browse all</a>)</small></div>
<pre>
  <a href="/wiki/Ada_Programming/Keywords/function" title="Ada Programming/Keywords/function"><tt style="color:DodgerBlue; text-decoration:none; font-weight:bold;">function</tt></a> To_Lower (C : Character) <a href="/wiki/Ada_Programming/Keywords/return" title="Ada Programming/Keywords/return"><tt style="color:DodgerBlue; text-decoration:none; font-weight:bold;">return</tt></a> Character <a href="/wiki/Ada_Programming/Keywords/renames" title="Ada Programming/Keywords/renames"><tt style="color:DodgerBlue; text-decoration:none; font-weight:bold;">renames</tt></a>
     Ada.Characters.Handling.To_Lower;

  --  tolower - translates all alphabetic, uppercase characters
  --  in str to lowercase
  <a href="/wiki/Ada_Programming/Keywords/function" title="Ada Programming/Keywords/function"><tt style="color:DodgerBlue; text-decoration:none; font-weight:bold;">function</tt></a> To_Lower (Str : String) <a href="/wiki/Ada_Programming/Keywords/return" title="Ada Programming/Keywords/return"><tt style="color:DodgerBlue; text-decoration:none; font-weight:bold;">return</tt></a> String <a href="/wiki/Ada_Programming/Keywords/is" title="Ada Programming/Keywords/is"><tt style="color:DodgerBlue; text-decoration:none; font-weight:bold;">is</tt></a>
     Result : String (Str'<a href="/wiki/Ada_Programming/Attributes/%27Range" title="Ada Programming/Attributes/'Range"><font style="color:teal">Range</font></a>);
  <a href="/wiki/Ada_Programming/Keywords/begin" title="Ada Programming/Keywords/begin"><tt style="color:DodgerBlue; text-decoration:none; font-weight:bold;">begin</tt></a>
     <a href="/wiki/Ada_Programming/Keywords/for" title="Ada Programming/Keywords/for"><tt style="color:DodgerBlue; text-decoration:none; font-weight:bold;">for</tt></a> C <a href="/wiki/Ada_Programming/Keywords/in" title="Ada Programming/Keywords/in"><tt style="color:DodgerBlue; text-decoration:none; font-weight:bold;">in</tt></a>  Str'<a href="/wiki/Ada_Programming/Attributes/%27Range" title="Ada Programming/Attributes/'Range"><font style="color:teal">Range</font></a> <a href="/wiki/Ada_Programming/Keywords/loop" title="Ada Programming/Keywords/loop"><tt style="color:DodgerBlue; text-decoration:none; font-weight:bold;">loop</tt></a>
        Result (C) := To_Lower (Str (C));
     <a href="/wiki/Ada_Programming/Keywords/end" title="Ada Programming/Keywords/end"><tt style="color:DodgerBlue; text-decoration:none; font-weight:bold;">end</tt></a> <a href="/wiki/Ada_Programming/Keywords/loop" title="Ada Programming/Keywords/loop"><tt style="color:DodgerBlue; text-decoration:none; font-weight:bold;">loop</tt></a>;
     <a href="/wiki/Ada_Programming/Keywords/return" title="Ada Programming/Keywords/return"><tt style="color:DodgerBlue; text-decoration:none; font-weight:bold;">return</tt></a> Result;
  <a href="/wiki/Ada_Programming/Keywords/end" title="Ada Programming/Keywords/end"><tt style="color:DodgerBlue; text-decoration:none; font-weight:bold;">end</tt></a> To_Lower;
</pre>
<p>Would the append approach be impossible with Ada? No, but it would be significantly more complex and slower.</p>
<h3><span class="mw-headline" id="Equal_Ignore_Case">Equal Ignore Case</span></h3>
<div style="background-color: snow; border: solid 1px PeachPuff; padding: 1em;">File: to_lower_2.adb <small>(<a rel="nofollow" class="external text" href="http://wikibook-ada.svn.sourceforge.net/viewvc/wikibook-ada/trunk/demos/Source/to_lower_2.adb?view=markup">view</a>, <a rel="nofollow" class="external text" href="http://wikibook-ada.svn.sourceforge.net/viewvc/*checkout*/wikibook-ada/trunk/demos/Source/to_lower_2.adb">plain text</a>, <a rel="nofollow" class="external text" href="https://sourceforge.net/project/showfiles.php?group_id=124904">download page</a>, <a rel="nofollow" class="external text" href="http://wikibook-ada.sourceforge.net/html/index.html">browse all</a>)</small></div>
<pre>
  --  equal-ignore-case -- returns true if s or t are equal,
  --  ignoring case
  <a href="/wiki/Ada_Programming/Keywords/function" title="Ada Programming/Keywords/function"><tt style="color:DodgerBlue; text-decoration:none; font-weight:bold;">function</tt></a> Equal_Ignore_Case
    (S    : String;
     T    : String)
     <a href="/wiki/Ada_Programming/Keywords/return" title="Ada Programming/Keywords/return"><tt style="color:DodgerBlue; text-decoration:none; font-weight:bold;">return</tt></a> Boolean
  <a href="/wiki/Ada_Programming/Keywords/is" title="Ada Programming/Keywords/is"><tt style="color:DodgerBlue; text-decoration:none; font-weight:bold;">is</tt></a>
     O : <a href="/wiki/Ada_Programming/Keywords/constant" title="Ada Programming/Keywords/constant"><tt style="color:DodgerBlue; text-decoration:none; font-weight:bold;">constant</tt></a> Integer := S'<a href="/wiki/Ada_Programming/Attributes/%27First" title="Ada Programming/Attributes/'First"><font style="color:teal">First</font></a> - T'<a href="/wiki/Ada_Programming/Attributes/%27First" title="Ada Programming/Attributes/'First"><font style="color:teal">First</font></a>;
  <a href="/wiki/Ada_Programming/Keywords/begin" title="Ada Programming/Keywords/begin"><tt style="color:DodgerBlue; text-decoration:none; font-weight:bold;">begin</tt></a>
     <a href="/wiki/Ada_Programming/Keywords/if" title="Ada Programming/Keywords/if"><tt style="color:DodgerBlue; text-decoration:none; font-weight:bold;">if</tt></a> T'<a href="/wiki/Ada_Programming/Attributes/%27Length" title="Ada Programming/Attributes/'Length"><font style="color:teal">Length</font></a> /= S'<a href="/wiki/Ada_Programming/Attributes/%27Length" title="Ada Programming/Attributes/'Length"><font style="color:teal">Length</font></a> <a href="/wiki/Ada_Programming/Keywords/then" title="Ada Programming/Keywords/then"><tt style="color:DodgerBlue; text-decoration:none; font-weight:bold;">then</tt></a>
        <a href="/wiki/Ada_Programming/Keywords/return" title="Ada Programming/Keywords/return"><tt style="color:DodgerBlue; text-decoration:none; font-weight:bold;">return</tt></a> False;  --  if they aren't the same length, they
                       --  aren't equal
     <a href="/wiki/Ada_Programming/Keywords/else" title="Ada Programming/Keywords/else"><tt style="color:DodgerBlue; text-decoration:none; font-weight:bold;">else</tt></a>
        <a href="/wiki/Ada_Programming/Keywords/for" title="Ada Programming/Keywords/for"><tt style="color:DodgerBlue; text-decoration:none; font-weight:bold;">for</tt></a> I <a href="/wiki/Ada_Programming/Keywords/in" title="Ada Programming/Keywords/in"><tt style="color:DodgerBlue; text-decoration:none; font-weight:bold;">in</tt></a>  S'<a href="/wiki/Ada_Programming/Attributes/%27Range" title="Ada Programming/Attributes/'Range"><font style="color:teal">Range</font></a> <a href="/wiki/Ada_Programming/Keywords/loop" title="Ada Programming/Keywords/loop"><tt style="color:DodgerBlue; text-decoration:none; font-weight:bold;">loop</tt></a>
           <a href="/wiki/Ada_Programming/Keywords/if" title="Ada Programming/Keywords/if"><tt style="color:DodgerBlue; text-decoration:none; font-weight:bold;">if</tt></a> To_Lower (S (I)) /=
              To_Lower (T (I + O))
           <a href="/wiki/Ada_Programming/Keywords/then" title="Ada Programming/Keywords/then"><tt style="color:DodgerBlue; text-decoration:none; font-weight:bold;">then</tt></a>
              <a href="/wiki/Ada_Programming/Keywords/return" title="Ada Programming/Keywords/return"><tt style="color:DodgerBlue; text-decoration:none; font-weight:bold;">return</tt></a> False;
           <a href="/wiki/Ada_Programming/Keywords/end" title="Ada Programming/Keywords/end"><tt style="color:DodgerBlue; text-decoration:none; font-weight:bold;">end</tt></a> <a href="/wiki/Ada_Programming/Keywords/if" title="Ada Programming/Keywords/if"><tt style="color:DodgerBlue; text-decoration:none; font-weight:bold;">if</tt></a>;
        <a href="/wiki/Ada_Programming/Keywords/end" title="Ada Programming/Keywords/end"><tt style="color:DodgerBlue; text-decoration:none; font-weight:bold;">end</tt></a> <a href="/wiki/Ada_Programming/Keywords/loop" title="Ada Programming/Keywords/loop"><tt style="color:DodgerBlue; text-decoration:none; font-weight:bold;">loop</tt></a>;
     <a href="/wiki/Ada_Programming/Keywords/end" title="Ada Programming/Keywords/end"><tt style="color:DodgerBlue; text-decoration:none; font-weight:bold;">end</tt></a> <a href="/wiki/Ada_Programming/Keywords/if" title="Ada Programming/Keywords/if"><tt style="color:DodgerBlue; text-decoration:none; font-weight:bold;">if</tt></a>;
     <a href="/wiki/Ada_Programming/Keywords/return" title="Ada Programming/Keywords/return"><tt style="color:DodgerBlue; text-decoration:none; font-weight:bold;">return</tt></a> True;
  <a href="/wiki/Ada_Programming/Keywords/end" title="Ada Programming/Keywords/end"><tt style="color:DodgerBlue; text-decoration:none; font-weight:bold;">end</tt></a> Equal_Ignore_Case;
</pre>
<p><br /></p>
<p><br /></p>
<h2><span class="mw-headline" id="Chapter_6:_Dynamic_Programming">Chapter 6: Dynamic Programming</span></h2>
<h3><span class="mw-headline" id="Fibonacci_numbers_2">Fibonacci numbers</span></h3>
<p>The following codes are implementations of the <a href="/wiki/Algorithms/Dynamic_Programming#Fibonacci_Numbers" title="Algorithms/Dynamic Programming">Fibonacci-Numbers examples</a>.</p>
<h4><span class="mw-headline" id="Simple_Implementation">Simple Implementation</span></h4>
<div style="background-color: snow; border: solid 1px PeachPuff; padding: 1em;">File: fibonacci_1.adb <small>(<a rel="nofollow" class="external text" href="http://wikibook-ada.svn.sourceforge.net/viewvc/wikibook-ada/trunk/demos/Source/fibonacci_1.adb?view=markup">view</a>, <a rel="nofollow" class="external text" href="http://wikibook-ada.svn.sourceforge.net/viewvc/*checkout*/wikibook-ada/trunk/demos/Source/fibonacci_1.adb">plain text</a>, <a rel="nofollow" class="external text" href="https://sourceforge.net/project/showfiles.php?group_id=124904">download page</a>, <a rel="nofollow" class="external text" href="http://wikibook-ada.sourceforge.net/html/index.html">browse all</a>)</small></div>
<pre>
...
</pre>
<p>To calculate Fibonacci numbers negative values are not needed so we define an integer type which starts at 0. With the integer type defined you can calculate up until <code>Fib (87)</code>. <code>Fib (88)</code> will result in an <code>Constraint_Error</code>.</p>
<pre>
  <a href="/wiki/Ada_Programming/Keywords/type" title="Ada Programming/Keywords/type"><tt style="color:DodgerBlue; text-decoration:none; font-weight:bold;">type</tt></a> Integer_Type <a href="/wiki/Ada_Programming/Keywords/is" title="Ada Programming/Keywords/is"><tt style="color:DodgerBlue; text-decoration:none; font-weight:bold;">is</tt></a> <a href="/wiki/Ada_Programming/Keywords/range" title="Ada Programming/Keywords/range"><tt style="color:DodgerBlue; text-decoration:none; font-weight:bold;">range</tt></a> 0 .. 999_999_999_999_999_999;
</pre>
<p>You might notice that there is not equivalence for the <code>assert (n &gt;= 0)</code> from the original example. Ada will test the correctness of the parameter <i>before</i> the function is called.</p>
<pre>
  <a href="/wiki/Ada_Programming/Keywords/function" title="Ada Programming/Keywords/function"><tt style="color:DodgerBlue; text-decoration:none; font-weight:bold;">function</tt></a> Fib (n : Integer_Type) <a href="/wiki/Ada_Programming/Keywords/return" title="Ada Programming/Keywords/return"><tt style="color:DodgerBlue; text-decoration:none; font-weight:bold;">return</tt></a> Integer_Type <a href="/wiki/Ada_Programming/Keywords/is" title="Ada Programming/Keywords/is"><tt style="color:DodgerBlue; text-decoration:none; font-weight:bold;">is</tt></a>
  <a href="/wiki/Ada_Programming/Keywords/begin" title="Ada Programming/Keywords/begin"><tt style="color:DodgerBlue; text-decoration:none; font-weight:bold;">begin</tt></a>
     <a href="/wiki/Ada_Programming/Keywords/if" title="Ada Programming/Keywords/if"><tt style="color:DodgerBlue; text-decoration:none; font-weight:bold;">if</tt></a> n = 0 <a href="/wiki/Ada_Programming/Keywords/then" title="Ada Programming/Keywords/then"><tt style="color:DodgerBlue; text-decoration:none; font-weight:bold;">then</tt></a>
        <a href="/wiki/Ada_Programming/Keywords/return" title="Ada Programming/Keywords/return"><tt style="color:DodgerBlue; text-decoration:none; font-weight:bold;">return</tt></a> 0;
     <a href="/wiki/Ada_Programming/Keywords/elsif" title="Ada Programming/Keywords/elsif"><tt style="color:DodgerBlue; text-decoration:none; font-weight:bold;">elsif</tt></a> n = 1 <a href="/wiki/Ada_Programming/Keywords/then" title="Ada Programming/Keywords/then"><tt style="color:DodgerBlue; text-decoration:none; font-weight:bold;">then</tt></a>
        <a href="/wiki/Ada_Programming/Keywords/return" title="Ada Programming/Keywords/return"><tt style="color:DodgerBlue; text-decoration:none; font-weight:bold;">return</tt></a> 1;
     <a href="/wiki/Ada_Programming/Keywords/else" title="Ada Programming/Keywords/else"><tt style="color:DodgerBlue; text-decoration:none; font-weight:bold;">else</tt></a>
        <a href="/wiki/Ada_Programming/Keywords/return" title="Ada Programming/Keywords/return"><tt style="color:DodgerBlue; text-decoration:none; font-weight:bold;">return</tt></a> Fib (n - 1) + Fib (n - 2);
     <a href="/wiki/Ada_Programming/Keywords/end" title="Ada Programming/Keywords/end"><tt style="color:DodgerBlue; text-decoration:none; font-weight:bold;">end</tt></a> <a href="/wiki/Ada_Programming/Keywords/if" title="Ada Programming/Keywords/if"><tt style="color:DodgerBlue; text-decoration:none; font-weight:bold;">if</tt></a>;
  <a href="/wiki/Ada_Programming/Keywords/end" title="Ada Programming/Keywords/end"><tt style="color:DodgerBlue; text-decoration:none; font-weight:bold;">end</tt></a> Fib;

...
</pre>
<h4><span class="mw-headline" id="Cached_Implementation">Cached Implementation</span></h4>
<div style="background-color: snow; border: solid 1px PeachPuff; padding: 1em;">File: fibonacci_2.adb <small>(<a rel="nofollow" class="external text" href="http://wikibook-ada.svn.sourceforge.net/viewvc/wikibook-ada/trunk/demos/Source/fibonacci_2.adb?view=markup">view</a>, <a rel="nofollow" class="external text" href="http://wikibook-ada.svn.sourceforge.net/viewvc/*checkout*/wikibook-ada/trunk/demos/Source/fibonacci_2.adb">plain text</a>, <a rel="nofollow" class="external text" href="https://sourceforge.net/project/showfiles.php?group_id=124904">download page</a>, <a rel="nofollow" class="external text" href="http://wikibook-ada.sourceforge.net/html/index.html">browse all</a>)</small></div>
<pre>
...
</pre>
<p>For this implementation we need a special cache type can also store a -1 as "not calculated" marker</p>
<pre>
  <a href="/wiki/Ada_Programming/Keywords/type" title="Ada Programming/Keywords/type"><tt style="color:DodgerBlue; text-decoration:none; font-weight:bold;">type</tt></a> Cache_Type <a href="/wiki/Ada_Programming/Keywords/is" title="Ada Programming/Keywords/is"><tt style="color:DodgerBlue; text-decoration:none; font-weight:bold;">is</tt></a> <a href="/wiki/Ada_Programming/Keywords/range" title="Ada Programming/Keywords/range"><tt style="color:DodgerBlue; text-decoration:none; font-weight:bold;">range</tt></a> -1 .. 999_999_999_999_999_999;
</pre>
<p>The actual type for calculating the fibonacci numbers continues to start at 0. As it is a <a href="/wiki/Ada_Programming/Keywords/subtype" title="Ada Programming/Keywords/subtype"><tt style="color:DodgerBlue; text-decoration:none; font-weight:bold;">subtype</tt></a> of the cache type Ada will automatically convert between the two. <small>(the conversion is - of course - checked for validity)</small></p>
<pre>
  <a href="/wiki/Ada_Programming/Keywords/subtype" title="Ada Programming/Keywords/subtype"><tt style="color:DodgerBlue; text-decoration:none; font-weight:bold;">subtype</tt></a> Integer_Type <a href="/wiki/Ada_Programming/Keywords/is" title="Ada Programming/Keywords/is"><tt style="color:DodgerBlue; text-decoration:none; font-weight:bold;">is</tt></a> Cache_Type <a href="/wiki/Ada_Programming/Keywords/range" title="Ada Programming/Keywords/range"><tt style="color:DodgerBlue; text-decoration:none; font-weight:bold;">range</tt></a>
     0 .. Cache_Type'<a href="/wiki/Ada_Programming/Attributes/%27Last" title="Ada Programming/Attributes/'Last"><font style="color:teal">Last</font></a>;
</pre>
<p>In order to know how large the cache need to be we first read the actual value from the command line.</p>
<pre>
  Value : <a href="/wiki/Ada_Programming/Keywords/constant" title="Ada Programming/Keywords/constant"><tt style="color:DodgerBlue; text-decoration:none; font-weight:bold;">constant</tt></a> Integer_Type :=
     Integer_Type'Value (Ada.Command_Line.Argument (1));
</pre>
<p>The Cache array starts with element 2 since Fib (0) and Fib (1) are constants and ends with the value we want to calculate.</p>
<pre>
  <a href="/wiki/Ada_Programming/Keywords/type" title="Ada Programming/Keywords/type"><tt style="color:DodgerBlue; text-decoration:none; font-weight:bold;">type</tt></a> Cache_Array <a href="/wiki/Ada_Programming/Keywords/is" title="Ada Programming/Keywords/is"><tt style="color:DodgerBlue; text-decoration:none; font-weight:bold;">is</tt></a>
     <a href="/wiki/Ada_Programming/Keywords/array" title="Ada Programming/Keywords/array"><tt style="color:DodgerBlue; text-decoration:none; font-weight:bold;">array</tt></a> (Integer_Type <a href="/wiki/Ada_Programming/Keywords/range" title="Ada Programming/Keywords/range"><tt style="color:DodgerBlue; text-decoration:none; font-weight:bold;">range</tt></a> 2 .. Value) <a href="/wiki/Ada_Programming/Keywords/of" title="Ada Programming/Keywords/of"><tt style="color:DodgerBlue; text-decoration:none; font-weight:bold;">of</tt></a> Cache_Type;
</pre>
<p>The Cache is initialized to the first valid value of the cache type — this is <code>-1</code>.</p>
<pre>
  F : Cache_Array := (<a href="/wiki/Ada_Programming/Keywords/others" title="Ada Programming/Keywords/others"><tt style="color:DodgerBlue; text-decoration:none; font-weight:bold;">others</tt></a> =&gt; Cache_Type'First);
</pre>
<p>What follows is the actual algorithm.</p>
<pre>
  <a href="/wiki/Ada_Programming/Keywords/function" title="Ada Programming/Keywords/function"><tt style="color:DodgerBlue; text-decoration:none; font-weight:bold;">function</tt></a> Fib (N : Integer_Type) <a href="/wiki/Ada_Programming/Keywords/return" title="Ada Programming/Keywords/return"><tt style="color:DodgerBlue; text-decoration:none; font-weight:bold;">return</tt></a> Integer_Type <a href="/wiki/Ada_Programming/Keywords/is" title="Ada Programming/Keywords/is"><tt style="color:DodgerBlue; text-decoration:none; font-weight:bold;">is</tt></a>
  <a href="/wiki/Ada_Programming/Keywords/begin" title="Ada Programming/Keywords/begin"><tt style="color:DodgerBlue; text-decoration:none; font-weight:bold;">begin</tt></a>
     <a href="/wiki/Ada_Programming/Keywords/if" title="Ada Programming/Keywords/if"><tt style="color:DodgerBlue; text-decoration:none; font-weight:bold;">if</tt></a> N = 0 <a href="/wiki/Ada_Programming/Keywords/or" title="Ada Programming/Keywords/or"><tt style="color:DodgerBlue; text-decoration:none; font-weight:bold;">or</tt></a> <a href="/wiki/Ada_Programming/Keywords/else" title="Ada Programming/Keywords/else"><tt style="color:DodgerBlue; text-decoration:none; font-weight:bold;">else</tt></a> N = 1 <a href="/wiki/Ada_Programming/Keywords/then" title="Ada Programming/Keywords/then"><tt style="color:DodgerBlue; text-decoration:none; font-weight:bold;">then</tt></a>
        <a href="/wiki/Ada_Programming/Keywords/return" title="Ada Programming/Keywords/return"><tt style="color:DodgerBlue; text-decoration:none; font-weight:bold;">return</tt></a> N;
     <a href="/wiki/Ada_Programming/Keywords/elsif" title="Ada Programming/Keywords/elsif"><tt style="color:DodgerBlue; text-decoration:none; font-weight:bold;">elsif</tt></a> F (N) /= Cache_Type'First <a href="/wiki/Ada_Programming/Keywords/then" title="Ada Programming/Keywords/then"><tt style="color:DodgerBlue; text-decoration:none; font-weight:bold;">then</tt></a>
        <a href="/wiki/Ada_Programming/Keywords/return" title="Ada Programming/Keywords/return"><tt style="color:DodgerBlue; text-decoration:none; font-weight:bold;">return</tt></a> F (N);
     <a href="/wiki/Ada_Programming/Keywords/else" title="Ada Programming/Keywords/else"><tt style="color:DodgerBlue; text-decoration:none; font-weight:bold;">else</tt></a>
        F (N) := Fib (N - 1) + Fib (N - 2);
        <a href="/wiki/Ada_Programming/Keywords/return" title="Ada Programming/Keywords/return"><tt style="color:DodgerBlue; text-decoration:none; font-weight:bold;">return</tt></a> F (N);
     <a href="/wiki/Ada_Programming/Keywords/end" title="Ada Programming/Keywords/end"><tt style="color:DodgerBlue; text-decoration:none; font-weight:bold;">end</tt></a> <a href="/wiki/Ada_Programming/Keywords/if" title="Ada Programming/Keywords/if"><tt style="color:DodgerBlue; text-decoration:none; font-weight:bold;">if</tt></a>;
  <a href="/wiki/Ada_Programming/Keywords/end" title="Ada Programming/Keywords/end"><tt style="color:DodgerBlue; text-decoration:none; font-weight:bold;">end</tt></a> Fib;

...
</pre>
<p>This implementation is faithful to the original from the <a href="/wiki/Algorithms" title="Algorithms">Algorithms</a> book. However, in Ada you would normally do it a little different:</p>
<div style="background-color: snow; border: solid 1px PeachPuff; padding: 1em;">File: fibonacci_3.adb <small>(<a rel="nofollow" class="external text" href="http://wikibook-ada.svn.sourceforge.net/viewvc/wikibook-ada/trunk/demos/Source/fibonacci_3.adb?view=markup">view</a>, <a rel="nofollow" class="external text" href="http://wikibook-ada.svn.sourceforge.net/viewvc/*checkout*/wikibook-ada/trunk/demos/Source/fibonacci_3.adb">plain text</a>, <a rel="nofollow" class="external text" href="https://sourceforge.net/project/showfiles.php?group_id=124904">download page</a>, <a rel="nofollow" class="external text" href="http://wikibook-ada.sourceforge.net/html/index.html">browse all</a>)</small></div>
<p>when you use a slightly larger array which also stores the elements 0 and 1 and initializes them to the correct values</p>
<pre>
  <a href="/wiki/Ada_Programming/Keywords/type" title="Ada Programming/Keywords/type"><tt style="color:DodgerBlue; text-decoration:none; font-weight:bold;">type</tt></a> Cache_Array <a href="/wiki/Ada_Programming/Keywords/is" title="Ada Programming/Keywords/is"><tt style="color:DodgerBlue; text-decoration:none; font-weight:bold;">is</tt></a>
     <a href="/wiki/Ada_Programming/Keywords/array" title="Ada Programming/Keywords/array"><tt style="color:DodgerBlue; text-decoration:none; font-weight:bold;">array</tt></a> (Integer_Type <a href="/wiki/Ada_Programming/Keywords/range" title="Ada Programming/Keywords/range"><tt style="color:DodgerBlue; text-decoration:none; font-weight:bold;">range</tt></a> 0 .. Value) <a href="/wiki/Ada_Programming/Keywords/of" title="Ada Programming/Keywords/of"><tt style="color:DodgerBlue; text-decoration:none; font-weight:bold;">of</tt></a> Cache_Type;

  F : Cache_Array :=
     (0      =&gt; 0,
      1      =&gt; 1,
      <a href="/wiki/Ada_Programming/Keywords/others" title="Ada Programming/Keywords/others"><tt style="color:DodgerBlue; text-decoration:none; font-weight:bold;">others</tt></a> =&gt; Cache_Type'First);
</pre>
<p>and then you can remove the first <a href="/wiki/Ada_Programming/Keywords/if" title="Ada Programming/Keywords/if"><tt style="color:DodgerBlue; text-decoration:none; font-weight:bold;">if</tt></a> path.</p>
<pre>
<strike>     <a href="/wiki/Ada_Programming/Keywords/if" title="Ada Programming/Keywords/if"><tt style="color:DodgerBlue; text-decoration:none; font-weight:bold;">if</tt></a> N = 0 <a href="/wiki/Ada_Programming/Keywords/or" title="Ada Programming/Keywords/or"><tt style="color:DodgerBlue; text-decoration:none; font-weight:bold;">or</tt></a> <a href="/wiki/Ada_Programming/Keywords/else" title="Ada Programming/Keywords/else"><tt style="color:DodgerBlue; text-decoration:none; font-weight:bold;">else</tt></a> N = 1 <a href="/wiki/Ada_Programming/Keywords/then" title="Ada Programming/Keywords/then"><tt style="color:DodgerBlue; text-decoration:none; font-weight:bold;">then</tt></a>
        <a href="/wiki/Ada_Programming/Keywords/return" title="Ada Programming/Keywords/return"><tt style="color:DodgerBlue; text-decoration:none; font-weight:bold;">return</tt></a> N;
     els</strike><a href="/wiki/Ada_Programming/Keywords/if" title="Ada Programming/Keywords/if"><tt style="color:DodgerBlue; text-decoration:none; font-weight:bold;">if</tt></a> F (N) /= Cache_Type'First <a href="/wiki/Ada_Programming/Keywords/then" title="Ada Programming/Keywords/then"><tt style="color:DodgerBlue; text-decoration:none; font-weight:bold;">then</tt></a>
</pre>
<p>This will save about 45% of the execution-time <small>(measured on Linux i686)</small> while needing only two more elements in the cache array.</p>
<h4><span class="mw-headline" id="Memory_Optimized_Implementation">Memory Optimized Implementation</span></h4>
<p>This version looks just like the original in WikiCode.</p>
<div style="background-color: snow; border: solid 1px PeachPuff; padding: 1em;">File: fibonacci_4.adb <small>(<a rel="nofollow" class="external text" href="http://wikibook-ada.svn.sourceforge.net/viewvc/wikibook-ada/trunk/demos/Source/fibonacci_4.adb?view=markup">view</a>, <a rel="nofollow" class="external text" href="http://wikibook-ada.svn.sourceforge.net/viewvc/*checkout*/wikibook-ada/trunk/demos/Source/fibonacci_4.adb">plain text</a>, <a rel="nofollow" class="external text" href="https://sourceforge.net/project/showfiles.php?group_id=124904">download page</a>, <a rel="nofollow" class="external text" href="http://wikibook-ada.sourceforge.net/html/index.html">browse all</a>)</small></div>
<pre>
  <a href="/wiki/Ada_Programming/Keywords/type" title="Ada Programming/Keywords/type"><tt style="color:DodgerBlue; text-decoration:none; font-weight:bold;">type</tt></a> Integer_Type <a href="/wiki/Ada_Programming/Keywords/is" title="Ada Programming/Keywords/is"><tt style="color:DodgerBlue; text-decoration:none; font-weight:bold;">is</tt></a> <a href="/wiki/Ada_Programming/Keywords/range" title="Ada Programming/Keywords/range"><tt style="color:DodgerBlue; text-decoration:none; font-weight:bold;">range</tt></a> 0 .. 999_999_999_999_999_999;

  <a href="/wiki/Ada_Programming/Keywords/function" title="Ada Programming/Keywords/function"><tt style="color:DodgerBlue; text-decoration:none; font-weight:bold;">function</tt></a> Fib (N : Integer_Type) <a href="/wiki/Ada_Programming/Keywords/return" title="Ada Programming/Keywords/return"><tt style="color:DodgerBlue; text-decoration:none; font-weight:bold;">return</tt></a> Integer_Type <a href="/wiki/Ada_Programming/Keywords/is" title="Ada Programming/Keywords/is"><tt style="color:DodgerBlue; text-decoration:none; font-weight:bold;">is</tt></a>
     U : Integer_Type := 0;
     V : Integer_Type := 1;
  <a href="/wiki/Ada_Programming/Keywords/begin" title="Ada Programming/Keywords/begin"><tt style="color:DodgerBlue; text-decoration:none; font-weight:bold;">begin</tt></a>
     <a href="/wiki/Ada_Programming/Keywords/for" title="Ada Programming/Keywords/for"><tt style="color:DodgerBlue; text-decoration:none; font-weight:bold;">for</tt></a> I <a href="/wiki/Ada_Programming/Keywords/in" title="Ada Programming/Keywords/in"><tt style="color:DodgerBlue; text-decoration:none; font-weight:bold;">in</tt></a>  2 .. N <a href="/wiki/Ada_Programming/Keywords/loop" title="Ada Programming/Keywords/loop"><tt style="color:DodgerBlue; text-decoration:none; font-weight:bold;">loop</tt></a>
        Calculate_Next : <a href="/wiki/Ada_Programming/Keywords/declare" title="Ada Programming/Keywords/declare"><tt style="color:DodgerBlue; text-decoration:none; font-weight:bold;">declare</tt></a>
           T : <a href="/wiki/Ada_Programming/Keywords/constant" title="Ada Programming/Keywords/constant"><tt style="color:DodgerBlue; text-decoration:none; font-weight:bold;">constant</tt></a> Integer_Type := U + V;
        <a href="/wiki/Ada_Programming/Keywords/begin" title="Ada Programming/Keywords/begin"><tt style="color:DodgerBlue; text-decoration:none; font-weight:bold;">begin</tt></a>
           U := V;
           V := T;
        <a href="/wiki/Ada_Programming/Keywords/end" title="Ada Programming/Keywords/end"><tt style="color:DodgerBlue; text-decoration:none; font-weight:bold;">end</tt></a> Calculate_Next;
     <a href="/wiki/Ada_Programming/Keywords/end" title="Ada Programming/Keywords/end"><tt style="color:DodgerBlue; text-decoration:none; font-weight:bold;">end</tt></a> <a href="/wiki/Ada_Programming/Keywords/loop" title="Ada Programming/Keywords/loop"><tt style="color:DodgerBlue; text-decoration:none; font-weight:bold;">loop</tt></a>;
     <a href="/wiki/Ada_Programming/Keywords/return" title="Ada Programming/Keywords/return"><tt style="color:DodgerBlue; text-decoration:none; font-weight:bold;">return</tt></a> V;
  <a href="/wiki/Ada_Programming/Keywords/end" title="Ada Programming/Keywords/end"><tt style="color:DodgerBlue; text-decoration:none; font-weight:bold;">end</tt></a> Fib;
</pre>
<h4><span class="mw-headline" id="No_64_bit_integers">No 64 bit integers</span></h4>
<p>Your Ada compiler does not support 64 bit integer numbers? Then you could try to use <a href="/wiki/Ada_Programming/Types/delta" title="Ada Programming/Types/delta">decimal numbers</a> instead. Using decimal numbers results in a slower program <small>(takes about three times as long)</small> but the result will be the same.</p>
<p>The following example shows you how to define a suitable decimal type. Do experiment with the <a href="/wiki/Ada_Programming/Keywords/digits" title="Ada Programming/Keywords/digits"><tt style="color:DodgerBlue; text-decoration:none; font-weight:bold;">digits</tt></a> and <a href="/wiki/Ada_Programming/Keywords/range" title="Ada Programming/Keywords/range"><tt style="color:DodgerBlue; text-decoration:none; font-weight:bold;">range</tt></a> parameters until you get the optimum out of your Ada compiler.</p>
<div style="background-color: snow; border: solid 1px PeachPuff; padding: 1em;">File: fibonacci_5.adb <small>(<a rel="nofollow" class="external text" href="http://wikibook-ada.svn.sourceforge.net/viewvc/wikibook-ada/trunk/demos/Source/fibonacci_5.adb?view=markup">view</a>, <a rel="nofollow" class="external text" href="http://wikibook-ada.svn.sourceforge.net/viewvc/*checkout*/wikibook-ada/trunk/demos/Source/fibonacci_5.adb">plain text</a>, <a rel="nofollow" class="external text" href="https://sourceforge.net/project/showfiles.php?group_id=124904">download page</a>, <a rel="nofollow" class="external text" href="http://wikibook-ada.sourceforge.net/html/index.html">browse all</a>)</small></div>
<pre>
  <a href="/wiki/Ada_Programming/Keywords/type" title="Ada Programming/Keywords/type"><tt style="color:DodgerBlue; text-decoration:none; font-weight:bold;">type</tt></a> Integer_Type <a href="/wiki/Ada_Programming/Keywords/is" title="Ada Programming/Keywords/is"><tt style="color:DodgerBlue; text-decoration:none; font-weight:bold;">is</tt></a> <a href="/wiki/Ada_Programming/Keywords/delta" title="Ada Programming/Keywords/delta"><tt style="color:DodgerBlue; text-decoration:none; font-weight:bold;">delta</tt></a> 1.0 <a href="/wiki/Ada_Programming/Keywords/digits" title="Ada Programming/Keywords/digits"><tt style="color:DodgerBlue; text-decoration:none; font-weight:bold;">digits</tt></a> 18 <a href="/wiki/Ada_Programming/Keywords/range" title="Ada Programming/Keywords/range"><tt style="color:DodgerBlue; text-decoration:none; font-weight:bold;">range</tt></a>
     0.0 .. 999_999_999_999_999_999.0;
</pre>
<p>You should know that floating point numbers are unsuitable for the calculation of fibonacci numbers. They will not report an error condition when the number calculated becomes too large — instead they will lose in precision which makes the result meaningless.</p>
<p><br /></p>
<p><br /></p>
<h1><span class="mw-headline" id="GNU_Free_Documentation_License">GNU Free Documentation License</span></h1>
<table class="metadata plainlinks ambox ambox-style" style="">
<tr>
<td class="mbox-image">
<div style="width: 52px;"><img alt="Caution" src="//upload.wikimedia.org/wikipedia/commons/thumb/7/74/Ambox_warning_yellow.svg/40px-Ambox_warning_yellow.svg.png" width="40" height="34" srcset="//upload.wikimedia.org/wikipedia/commons/thumb/7/74/Ambox_warning_yellow.svg/60px-Ambox_warning_yellow.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/7/74/Ambox_warning_yellow.svg/80px-Ambox_warning_yellow.svg.png 2x" /></div>
</td>
<td class="mbox-text" style="">As of July 15, 2009 Wikibooks has moved to a dual-licensing system that supersedes the previous GFDL only licensing. In short, this means that text licensed under the GFDL only can no longer be imported to Wikibooks, retroactive to 1 November 2008. Additionally, Wikibooks text might or might not now be exportable under the GFDL depending on whether or not any content was added and not removed since July 15.</td>
</tr>
</table>
<p>Version 1.3, 3 November 2008 Copyright (C) 2000, 2001, 2002, 2007, 2008 Free Software Foundation, Inc. &lt;<a rel="nofollow" class="external free" href="http://fsf.org/">http://fsf.org/</a>&gt;</p>
<p>Everyone is permitted to copy and distribute verbatim copies of this license document, but changing it is not allowed.</p>
<h2><span class="mw-headline" id="0._PREAMBLE">0. PREAMBLE</span></h2>
<p>The purpose of this License is to make a manual, textbook, or other functional and useful document "free" in the sense of freedom: to assure everyone the effective freedom to copy and redistribute it, with or without modifying it, either commercially or noncommercially. Secondarily, this License preserves for the author and publisher a way to get credit for their work, while not being considered responsible for modifications made by others.</p>
<p>This License is a kind of "copyleft", which means that derivative works of the document must themselves be free in the same sense. It complements the GNU General Public License, which is a copyleft license designed for free software.</p>
<p>We have designed this License in order to use it for manuals for free software, because free software needs free documentation: a free program should come with manuals providing the same freedoms that the software does. But this License is not limited to software manuals; it can be used for any textual work, regardless of subject matter or whether it is published as a printed book. We recommend this License principally for works whose purpose is instruction or reference.</p>
<h2><span class="mw-headline" id="1._APPLICABILITY_AND_DEFINITIONS">1. APPLICABILITY AND DEFINITIONS</span></h2>
<p>This License applies to any manual or other work, in any medium, that contains a notice placed by the copyright holder saying it can be distributed under the terms of this License. Such a notice grants a world-wide, royalty-free license, unlimited in duration, to use that work under the conditions stated herein. The "Document", below, refers to any such manual or work. Any member of the public is a licensee, and is addressed as "you". You accept the license if you copy, modify or distribute the work in a way requiring permission under copyright law.</p>
<p>A "Modified Version" of the Document means any work containing the Document or a portion of it, either copied verbatim, or with modifications and/or translated into another language.</p>
<p>A "Secondary Section" is a named appendix or a front-matter section of the Document that deals exclusively with the relationship of the publishers or authors of the Document to the Document's overall subject (or to related matters) and contains nothing that could fall directly within that overall subject. (Thus, if the Document is in part a textbook of mathematics, a Secondary Section may not explain any mathematics.) The relationship could be a matter of historical connection with the subject or with related matters, or of legal, commercial, philosophical, ethical or political position regarding them.</p>
<p>The "Invariant Sections" are certain Secondary Sections whose titles are designated, as being those of Invariant Sections, in the notice that says that the Document is released under this License. If a section does not fit the above definition of Secondary then it is not allowed to be designated as Invariant. The Document may contain zero Invariant Sections. If the Document does not identify any Invariant Sections then there are none.</p>
<p>The "Cover Texts" are certain short passages of text that are listed, as Front-Cover Texts or Back-Cover Texts, in the notice that says that the Document is released under this License. A Front-Cover Text may be at most 5 words, and a Back-Cover Text may be at most 25 words.</p>
<p>A "Transparent" copy of the Document means a machine-readable copy, represented in a format whose specification is available to the general public, that is suitable for revising the document straightforwardly with generic text editors or (for images composed of pixels) generic paint programs or (for drawings) some widely available drawing editor, and that is suitable for input to text formatters or for automatic translation to a variety of formats suitable for input to text formatters. A copy made in an otherwise Transparent file format whose markup, or absence of markup, has been arranged to thwart or discourage subsequent modification by readers is not Transparent. An image format is not Transparent if used for any substantial amount of text. A copy that is not "Transparent" is called "Opaque".</p>
<p>Examples of suitable formats for Transparent copies include plain ASCII without markup, Texinfo input format, LaTeX input format, SGML or XML using a publicly available DTD, and standard-conforming simple HTML, PostScript or PDF designed for human modification. Examples of transparent image formats include PNG, XCF and JPG. Opaque formats include proprietary formats that can be read and edited only by proprietary word processors, SGML or XML for which the DTD and/or processing tools are not generally available, and the machine-generated HTML, PostScript or PDF produced by some word processors for output purposes only.</p>
<p>The "Title Page" means, for a printed book, the title page itself, plus such following pages as are needed to hold, legibly, the material this License requires to appear in the title page. For works in formats which do not have any title page as such, "Title Page" means the text near the most prominent appearance of the work's title, preceding the beginning of the body of the text.</p>
<p>The "publisher" means any person or entity that distributes copies of the Document to the public.</p>
<p>A section "Entitled XYZ" means a named subunit of the Document whose title either is precisely XYZ or contains XYZ in parentheses following text that translates XYZ in another language. (Here XYZ stands for a specific section name mentioned below, such as "Acknowledgements", "Dedications", "Endorsements", or "History".) To "Preserve the Title" of such a section when you modify the Document means that it remains a section "Entitled XYZ" according to this definition.</p>
<p>The Document may include Warranty Disclaimers next to the notice which states that this License applies to the Document. These Warranty Disclaimers are considered to be included by reference in this License, but only as regards disclaiming warranties: any other implication that these Warranty Disclaimers may have is void and has no effect on the meaning of this License.</p>
<h2><span class="mw-headline" id="2._VERBATIM_COPYING">2. VERBATIM COPYING</span></h2>
<p>You may copy and distribute the Document in any medium, either commercially or noncommercially, provided that this License, the copyright notices, and the license notice saying this License applies to the Document are reproduced in all copies, and that you add no other conditions whatsoever to those of this License. You may not use technical measures to obstruct or control the reading or further copying of the copies you make or distribute. However, you may accept compensation in exchange for copies. If you distribute a large enough number of copies you must also follow the conditions in section 3.</p>
<p>You may also lend copies, under the same conditions stated above, and you may publicly display copies.</p>
<h2><span class="mw-headline" id="3._COPYING_IN_QUANTITY">3. COPYING IN QUANTITY</span></h2>
<p>If you publish printed copies (or copies in media that commonly have printed covers) of the Document, numbering more than 100, and the Document's license notice requires Cover Texts, you must enclose the copies in covers that carry, clearly and legibly, all these Cover Texts: Front-Cover Texts on the front cover, and Back-Cover Texts on the back cover. Both covers must also clearly and legibly identify you as the publisher of these copies. The front cover must present the full title with all words of the title equally prominent and visible. You may add other material on the covers in addition. Copying with changes limited to the covers, as long as they preserve the title of the Document and satisfy these conditions, can be treated as verbatim copying in other respects.</p>
<p>If the required texts for either cover are too voluminous to fit legibly, you should put the first ones listed (as many as fit reasonably) on the actual cover, and continue the rest onto adjacent pages.</p>
<p>If you publish or distribute Opaque copies of the Document numbering more than 100, you must either include a machine-readable Transparent copy along with each Opaque copy, or state in or with each Opaque copy a computer-network location from which the general network-using public has access to download using public-standard network protocols a complete Transparent copy of the Document, free of added material. If you use the latter option, you must take reasonably prudent steps, when you begin distribution of Opaque copies in quantity, to ensure that this Transparent copy will remain thus accessible at the stated location until at least one year after the last time you distribute an Opaque copy (directly or through your agents or retailers) of that edition to the public.</p>
<p>It is requested, but not required, that you contact the authors of the Document well before redistributing any large number of copies, to give them a chance to provide you with an updated version of the Document.</p>
<h2><span class="mw-headline" id="4._MODIFICATIONS">4. MODIFICATIONS</span></h2>
<p>You may copy and distribute a Modified Version of the Document under the conditions of sections 2 and 3 above, provided that you release the Modified Version under precisely this License, with the Modified Version filling the role of the Document, thus licensing distribution and modification of the Modified Version to whoever possesses a copy of it. In addition, you must do these things in the Modified Version:</p>
<ol type="A">
<li>Use in the Title Page (and on the covers, if any) a title distinct from that of the Document, and from those of previous versions (which should, if there were any, be listed in the History section of the Document). You may use the same title as a previous version if the original publisher of that version gives permission.</li>
<li>List on the Title Page, as authors, one or more persons or entities responsible for authorship of the modifications in the Modified Version, together with at least five of the principal authors of the Document (all of its principal authors, if it has fewer than five), unless they release you from this requirement.</li>
<li>State on the Title page the name of the publisher of the Modified Version, as the publisher.</li>
<li>Preserve all the copyright notices of the Document.</li>
<li>Add an appropriate copyright notice for your modifications adjacent to the other copyright notices.</li>
<li>Include, immediately after the copyright notices, a license notice giving the public permission to use the Modified Version under the terms of this License, in the form shown in the Addendum below.</li>
<li>Preserve in that license notice the full lists of Invariant Sections and required Cover Texts given in the Document's license notice.</li>
<li>Include an unaltered copy of this License.</li>
<li>Preserve the section Entitled "History", Preserve its Title, and add to it an item stating at least the title, year, new authors, and publisher of the Modified Version as given on the Title Page. If there is no section Entitled "History" in the Document, create one stating the title, year, authors, and publisher of the Document as given on its Title Page, then add an item describing the Modified Version as stated in the previous sentence.</li>
<li>Preserve the network location, if any, given in the Document for public access to a Transparent copy of the Document, and likewise the network locations given in the Document for previous versions it was based on. These may be placed in the "History" section. You may omit a network location for a work that was published at least four years before the Document itself, or if the original publisher of the version it refers to gives permission.</li>
<li>For any section Entitled "Acknowledgements" or "Dedications", Preserve the Title of the section, and preserve in the section all the substance and tone of each of the contributor acknowledgements and/or dedications given therein.</li>
<li>Preserve all the Invariant Sections of the Document, unaltered in their text and in their titles. Section numbers or the equivalent are not considered part of the section titles.</li>
<li>Delete any section Entitled "Endorsements". Such a section may not be included in the Modified version.</li>
<li>Do not retitle any existing section to be Entitled "Endorsements" or to conflict in title with any Invariant Section.</li>
<li>Preserve any Warranty Disclaimers.</li>
</ol>
<p>If the Modified Version includes new front-matter sections or appendices that qualify as Secondary Sections and contain no material copied from the Document, you may at your option designate some or all of these sections as invariant. To do this, add their titles to the list of Invariant Sections in the Modified Version's license notice. These titles must be distinct from any other section titles.</p>
<p>You may add a section Entitled "Endorsements", provided it contains nothing but endorsements of your Modified Version by various parties—for example, statements of peer review or that the text has been approved by an organization as the authoritative definition of a standard.</p>
<p>You may add a passage of up to five words as a Front-Cover Text, and a passage of up to 25 words as a Back-Cover Text, to the end of the list of Cover Texts in the Modified Version. Only one passage of Front-Cover Text and one of Back-Cover Text may be added by (or through arrangements made by) any one entity. If the Document already includes a cover text for the same cover, previously added by you or by arrangement made by the same entity you are acting on behalf of, you may not add another; but you may replace the old one, on explicit permission from the previous publisher that added the old one.</p>
<p>The author(s) and publisher(s) of the Document do not by this License give permission to use their names for publicity for or to assert or imply endorsement of any Modified Version.</p>
<h2><span class="mw-headline" id="5._COMBINING_DOCUMENTS">5. COMBINING DOCUMENTS</span></h2>
<p>You may combine the Document with other documents released under this License, under the terms defined in section 4 above for modified versions, provided that you include in the combination all of the Invariant Sections of all of the original documents, unmodified, and list them all as Invariant Sections of your combined work in its license notice, and that you preserve all their Warranty Disclaimers.</p>
<p>The combined work need only contain one copy of this License, and multiple identical Invariant Sections may be replaced with a single copy. If there are multiple Invariant Sections with the same name but different contents, make the title of each such section unique by adding at the end of it, in parentheses, the name of the original author or publisher of that section if known, or else a unique number. Make the same adjustment to the section titles in the list of Invariant Sections in the license notice of the combined work.</p>
<p>In the combination, you must combine any sections Entitled "History" in the various original documents, forming one section Entitled "History"; likewise combine any sections Entitled "Acknowledgements", and any sections Entitled "Dedications". You must delete all sections Entitled "Endorsements".</p>
<h2><span class="mw-headline" id="6._COLLECTIONS_OF_DOCUMENTS">6. COLLECTIONS OF DOCUMENTS</span></h2>
<p>You may make a collection consisting of the Document and other documents released under this License, and replace the individual copies of this License in the various documents with a single copy that is included in the collection, provided that you follow the rules of this License for verbatim copying of each of the documents in all other respects.</p>
<p>You may extract a single document from such a collection, and distribute it individually under this License, provided you insert a copy of this License into the extracted document, and follow this License in all other respects regarding verbatim copying of that document.</p>
<h2><span class="mw-headline" id="7._AGGREGATION_WITH_INDEPENDENT_WORKS">7. AGGREGATION WITH INDEPENDENT WORKS</span></h2>
<p>A compilation of the Document or its derivatives with other separate and independent documents or works, in or on a volume of a storage or distribution medium, is called an "aggregate" if the copyright resulting from the compilation is not used to limit the legal rights of the compilation's users beyond what the individual works permit. When the Document is included in an aggregate, this License does not apply to the other works in the aggregate which are not themselves derivative works of the Document.</p>
<p>If the Cover Text requirement of section 3 is applicable to these copies of the Document, then if the Document is less than one half of the entire aggregate, the Document's Cover Texts may be placed on covers that bracket the Document within the aggregate, or the electronic equivalent of covers if the Document is in electronic form. Otherwise they must appear on printed covers that bracket the whole aggregate.</p>
<h2><span class="mw-headline" id="8._TRANSLATION">8. TRANSLATION</span></h2>
<p>Translation is considered a kind of modification, so you may distribute translations of the Document under the terms of section 4. Replacing Invariant Sections with translations requires special permission from their copyright holders, but you may include translations of some or all Invariant Sections in addition to the original versions of these Invariant Sections. You may include a translation of this License, and all the license notices in the Document, and any Warranty Disclaimers, provided that you also include the original English version of this License and the original versions of those notices and disclaimers. In case of a disagreement between the translation and the original version of this License or a notice or disclaimer, the original version will prevail.</p>
<p>If a section in the Document is Entitled "Acknowledgements", "Dedications", or "History", the requirement (section 4) to Preserve its Title (section 1) will typically require changing the actual title.</p>
<h2><span class="mw-headline" id="9._TERMINATION">9. TERMINATION</span></h2>
<p>You may not copy, modify, sublicense, or distribute the Document except as expressly provided under this License. Any attempt otherwise to copy, modify, sublicense, or distribute it is void, and will automatically terminate your rights under this License.</p>
<p>However, if you cease all violation of this License, then your license from a particular copyright holder is reinstated (a) provisionally, unless and until the copyright holder explicitly and finally terminates your license, and (b) permanently, if the copyright holder fails to notify you of the violation by some reasonable means prior to 60 days after the cessation.</p>
<p>Moreover, your license from a particular copyright holder is reinstated permanently if the copyright holder notifies you of the violation by some reasonable means, this is the first time you have received notice of violation of this License (for any work) from that copyright holder, and you cure the violation prior to 30 days after your receipt of the notice.</p>
<p>Termination of your rights under this section does not terminate the licenses of parties who have received copies or rights from you under this License. If your rights have been terminated and not permanently reinstated, receipt of a copy of some or all of the same material does not give you any rights to use it.</p>
<h2><span class="mw-headline" id="10._FUTURE_REVISIONS_OF_THIS_LICENSE">10. FUTURE REVISIONS OF THIS LICENSE</span></h2>
<p>The Free Software Foundation may publish new, revised versions of the GNU Free Documentation License from time to time. Such new versions will be similar in spirit to the present version, but may differ in detail to address new problems or concerns. See <a rel="nofollow" class="external free" href="http://www.gnu.org/copyleft/">http://www.gnu.org/copyleft/</a>.</p>
<p>Each version of the License is given a distinguishing version number. If the Document specifies that a particular numbered version of this License "or any later version" applies to it, you have the option of following the terms and conditions either of that specified version or of any later version that has been published (not as a draft) by the Free Software Foundation. If the Document does not specify a version number of this License, you may choose any version ever published (not as a draft) by the Free Software Foundation. If the Document specifies that a proxy can decide which future versions of this License can be used, that proxy's public statement of acceptance of a version permanently authorizes you to choose that version for the Document.</p>
<h2><span class="mw-headline" id="11._RELICENSING">11. RELICENSING</span></h2>
<p>"Massive Multiauthor Collaboration Site" (or "MMC Site") means any World Wide Web server that publishes copyrightable works and also provides prominent facilities for anybody to edit those works. A public wiki that anybody can edit is an example of such a server. A "Massive Multiauthor Collaboration" (or "MMC") contained in the site means any set of copyrightable works thus published on the MMC site.</p>
<p>"CC-BY-SA" means the Creative Commons Attribution-Share Alike 3.0 license published by Creative Commons Corporation, a not-for-profit corporation with a principal place of business in San Francisco, California, as well as future copyleft versions of that license published by that same organization.</p>
<p>"Incorporate" means to publish or republish a Document, in whole or in part, as part of another Document.</p>
<p>An MMC is "eligible for relicensing" if it is licensed under this License, and if all works that were first published under this License somewhere other than this MMC, and subsequently incorporated in whole or in part into the MMC, (1) had no cover texts or invariant sections, and (2) were thus incorporated prior to November 1, 2008.</p>
<p>The operator of an MMC Site may republish an MMC contained in the site under CC-BY-SA on the same site at any time before August 1, 2009, provided the MMC is eligible for relicensing.</p>
<h1><span class="mw-headline" id="How_to_use_this_License_for_your_documents">How to use this License for your documents</span></h1>
<p>To use this License in a document you have written, include a copy of the License in the document and put the following copyright and license notices just after the title page:</p>
<dl>
<dd>Copyright (c) YEAR YOUR NAME.</dd>
<dd>Permission is granted to copy, distribute and/or modify this document</dd>
<dd>under the terms of the GNU Free Documentation License, Version 1.3</dd>
<dd>or any later version published by the Free Software Foundation;</dd>
<dd>with no Invariant Sections, no Front-Cover Texts, and no Back-Cover Texts.</dd>
<dd>A copy of the license is included in the section entitled "GNU</dd>
<dd>Free Documentation License".</dd>
</dl>
<p>If you have Invariant Sections, Front-Cover Texts and Back-Cover Texts, replace the "with...Texts." line with this:</p>
<dl>
<dd>with the Invariant Sections being LIST THEIR TITLES, with the</dd>
<dd>Front-Cover Texts being LIST, and with the Back-Cover Texts being LIST.</dd>
</dl>
<p>If you have Invariant Sections without Cover Texts, or some other combination of the three, merge those two alternatives to suit the situation.</p>
<p>If your document contains nontrivial examples of program code, we recommend releasing these examples in parallel under your choice of free software license, such as the GNU General Public License, to permit their use in free software.</p>
<h2><span class="mw-headline" id="References">References</span></h2>
<ol class="references">
<li id="cite_note-1"><span class="mw-cite-backlink"><a href="#cite_ref-1">↑</a></span> <span class="reference-text">A (mathematical) integer larger than the largest "int" directly supported by your computer's hardware is often called a "BigInt". Working with such large numbers is often called "multiple precision arithmetic". There are entire books on the various algorithms for dealing with such numbers, such as:</span>
<ul>
<li><span class="reference-text"><a rel="nofollow" class="external text" href="http://www.loria.fr/~zimmerma/mca/pub226.html">Modern Computer Arithmetic</a>, Richard Brent and Paul Zimmermann, Cambridge University Press, 2010.</span></li>
<li><span class="reference-text">Donald E. Knuth, The Art of Computer Programming , Volume 2: Seminumerical Algorithms (3rd edition), 1997.</span></li>
</ul>
<span class="reference-text">People who implement such algorithms may</span>
<ul>
<li><span class="reference-text">write a one-off implementation for one particular application</span></li>
<li><span class="reference-text">write a library that you can use for many applications, such as <a rel="nofollow" class="external text" href="http://gmplib.org/">GMP, the GNU Multiple Precision Arithmetic Library</a> or <a rel="nofollow" class="external text" href="https://mattmccutchen.net/bigint/">McCutchen's Big Integer Library</a> or various libraries <a rel="nofollow" class="external autonumber" href="http://www.leemon.com/crypto/BigInt.html">[1]</a> <a rel="nofollow" class="external autonumber" href="https://github.com/jasondavies/jsbn">[2]</a> <a rel="nofollow" class="external autonumber" href="https://github.com/libtom/libtomcrypt">[3]</a> <a rel="nofollow" class="external autonumber" href="http://www.gnu.org/software/gnu-crypto/">[4]</a> <a rel="nofollow" class="external autonumber" href="http://www.cryptopp.com/">[5]</a> used to demonstrate RSA encryption</span></li>
<li><span class="reference-text">put those algorithms in the compiler of a programming language that you can use (such as Python and Lisp) that automatically switches from standard integers to BigInts when necessary</span></li>
</ul>
</li>
</ol>


<!-- 
NewPP limit report
Parsed by mw1076
CPU time usage: 1.732 seconds
Real time usage: 11.482 seconds
Preprocessor visited node count: 2362/1000000
Preprocessor generated node count: 9232/1500000
Post‐expand include size: 254258/2048000 bytes
Template argument size: 4891/2048000 bytes
Highest expansion depth: 12/40
Expensive parser function count: 0/500
-->

<!-- Saved in parser cache with key enwikibooks:pcache:idhash:20033-0!0!0!!*!4!* and timestamp 20131220143809
 -->
<noscript><img src="//en.wikibooks.org/wiki/Special:CentralAutoLogin/start?type=1x1" alt="" title="" width="1" height="1" style="border: none; position: absolute;" /></noscript></div>								<div class="printfooter">
				Retrieved from "<a href="http://en.wikibooks.org/w/index.php?title=Algorithms/Print_version&amp;oldid=2564849">http://en.wikibooks.org/w/index.php?title=Algorithms/Print_version&amp;oldid=2564849</a>"				</div>
												<div id='catlinks' class='catlinks'><div id="mw-normal-catlinks" class="mw-normal-catlinks"><a href="/wiki/Special:Categories" title="Special:Categories">Categories</a>: <ul><li><a href="/wiki/Category:Algorithms" title="Category:Algorithms">Algorithms</a></li><li><a href="/wiki/Category:Ada_Programming" title="Category:Ada Programming">Ada Programming</a></li></ul></div></div>												<div class="visualClear"></div>
							</div>
		</div>
		<div id="mw-navigation">
			<h2>Navigation menu</h2>
			<div id="mw-head">
				<div id="p-personal" role="navigation" class="" aria-labelledby="p-personal-label">
	<h3 id="p-personal-label">Personal tools</h3>
	<ul>
<li id="pt-createaccount"><a href="/w/index.php?title=Special:UserLogin&amp;returnto=Algorithms%2FPrint+version&amp;type=signup">Create account</a></li><li id="pt-login"><a href="/w/index.php?title=Special:UserLogin&amp;returnto=Algorithms%2FPrint+version" title="You are encouraged to log in; however, it is not mandatory [o]" accesskey="o">Log in</a></li>	</ul>
</div>
				<div id="left-navigation">
					<div id="p-namespaces" role="navigation" class="vectorTabs" aria-labelledby="p-namespaces-label">
	<h3 id="p-namespaces-label">Namespaces</h3>
	<ul>
					<li  id="ca-nstab-main" class="selected"><span><a href="/wiki/Algorithms/Print_version"  title="View the content page [c]" accesskey="c">Book</a></span></li>
					<li  id="ca-talk"><span><a href="/wiki/Talk:Algorithms/Print_version"  title="Discussion about the content page [t]" accesskey="t">Discussion</a></span></li>
			</ul>
</div>
<div id="p-variants" role="navigation" class="vectorMenu emptyPortlet" aria-labelledby="p-variants-label">
	<h3 id="mw-vector-current-variant">
		</h3>
	<h3 id="p-variants-label"><span>Variants</span><a href="#"></a></h3>
	<div class="menu">
		<ul>
					</ul>
	</div>
</div>
				</div>
				<div id="right-navigation">
					<div id="p-views" role="navigation" class="vectorTabs" aria-labelledby="p-views-label">
	<h3 id="p-views-label">Views</h3>
	<ul>
					<li id="ca-view" class="collapsible"><span><a href="/w/index.php?title=Algorithms/Print_version&amp;stable=1" >Read</a></span></li>
					<li id="ca-current" class="collapsible collapsible selected"><span><a href="/w/index.php?title=Algorithms/Print_version&amp;stable=0&amp;redirect=no"  title="View this page with the pending changes [v]" accesskey="v">Latest draft</a></span></li>
					<li id="ca-edit"><span><a href="/w/index.php?title=Algorithms/Print_version&amp;action=edit"  title="You can edit this page. Please use the preview button before saving [e]" accesskey="e">Edit</a></span></li>
					<li id="ca-history" class="collapsible"><span><a href="/w/index.php?title=Algorithms/Print_version&amp;action=history"  title="Past revisions of this page [h]" accesskey="h">View history</a></span></li>
			</ul>
</div>
<div id="p-cactions" role="navigation" class="vectorMenu emptyPortlet" aria-labelledby="p-cactions-label">
	<h3 id="p-cactions-label"><span>Actions</span><a href="#"></a></h3>
	<div class="menu">
		<ul>
					</ul>
	</div>
</div>
<div id="p-search" role="search">
	<h3><label for="searchInput">Search</label></h3>
	<form action="/w/index.php" id="searchform">
				<div id="simpleSearch">
						<input name="search" placeholder="Search" title="Search Wikibooks [f]" accesskey="f" id="searchInput" />						<button type="submit" name="button" title="Search the pages for this text" id="searchButton"><img src="//bits.wikimedia.org/static-1.23wmf7/skins/vector/images/search-ltr.png?303-4" alt="Search" width="12" height="13" /></button>								<input type='hidden' name="title" value="Special:Search"/>
		</div>
	</form>
</div>
				</div>
			</div>
			<div id="mw-panel">
					<div id="p-logo" role="banner"><a style="background-image: url(//upload.wikimedia.org/wikibooks/en/b/bc/Wiki.png);" href="/wiki/Main_Page"  title="Visit the main page"></a></div>
				<div class="portal" role="navigation" id='p-Navigation' aria-labelledby='p-Navigation-label'>
	<h3 id='p-Navigation-label'>Navigation</h3>
	<div class="body">
		<ul>
			<li id="n-mainpage"><a href="/wiki/Main_Page" title="Visit the main page [z]" accesskey="z">Main Page</a></li>
			<li id="n-help"><a href="/wiki/Help:Contents" title="Find help on how to use and edit Wikibooks">Help</a></li>
			<li id="n-Browse"><a href="/wiki/Wikibooks:Card_Catalog_Office" title="Check out what Wikibooks has to offer">Browse</a></li>
			<li id="n-Cookbook"><a href="/wiki/Cookbook:Table_of_Contents" title="Learn recipes from around the world">Cookbook</a></li>
			<li id="n-Wikijunior"><a href="/wiki/Wikijunior" title="Books for children">Wikijunior</a></li>
			<li id="n-Featured-books"><a href="/wiki/Wikibooks:Featured_books" title="The best of Wikibooks">Featured books</a></li>
			<li id="n-recentchanges"><a href="/wiki/Special:RecentChanges" title="A list of recent changes in the wiki [r]" accesskey="r">Recent changes</a></li>
			<li id="n-sitesupport"><a href="//donate.wikimedia.org/wiki/Special:FundraiserRedirector?utm_source=donate&amp;utm_medium=sidebar&amp;utm_campaign=C13_en.wikibooks.org&amp;uselang=en" title="Support Wikibooks">Donations</a></li>
			<li id="n-randomrootpage"><a href="/wiki/Special:Randomrootpage">Random book</a></li>
		</ul>
	</div>
</div>
<div class="portal" role="navigation" id='p-Community' aria-labelledby='p-Community-label'>
	<h3 id='p-Community-label'>Community</h3>
	<div class="body">
		<ul>
			<li id="n-Reading-room"><a href="/wiki/Wikibooks:Reading_room" title="Discuss Wikibooks-related questions and concerns with others">Reading room</a></li>
			<li id="n-portal"><a href="/wiki/Wikibooks:Community_Portal" title="Find your way around the Wikibooks community">Community portal</a></li>
			<li id="n-currentevents"><a href="/wiki/Wikibooks:Reading_room/Bulletin_Board" title="Important community news">Bulletin Board</a></li>
			<li id="n-maintenance"><a href="/wiki/Wikibooks:Maintenance" title="Frequent tasks that you can help with">Help out!</a></li>
			<li id="n-Policies-and-guidelines"><a href="/wiki/Wikibooks:Policies_and_guidelines" title="Pages detailing important rules and procedures">Policies and guidelines</a></li>
			<li id="n-contact"><a href="/wiki/Wikibooks:Contact_us" title="Alternative methods of communication">Contact us</a></li>
		</ul>
	</div>
</div>
<div class="portal" role="navigation" id='p-tb' aria-labelledby='p-tb-label'>
	<h3 id='p-tb-label'>Tools</h3>
	<div class="body">
		<ul>
			<li id="t-whatlinkshere"><a href="/wiki/Special:WhatLinksHere/Algorithms/Print_version" title="A list of all wiki pages that link here [j]" accesskey="j">What links here</a></li>
			<li id="t-recentchangeslinked"><a href="/wiki/Special:RecentChangesLinked/Algorithms/Print_version" title="Recent changes in pages linked from this page [k]" accesskey="k">Related changes</a></li>
			<li id="t-upload"><a href="//commons.wikimedia.org/wiki/Special:UploadWizard" title="Upload files [u]" accesskey="u">Upload file</a></li>
			<li id="t-specialpages"><a href="/wiki/Special:SpecialPages" title="A list of all special pages [q]" accesskey="q">Special pages</a></li>
			<li id="t-permalink"><a href="/w/index.php?title=Algorithms/Print_version&amp;oldid=2564849" title="Permanent link to this revision of the page">Permanent link</a></li>
			<li id="t-info"><a href="/w/index.php?title=Algorithms/Print_version&amp;action=info">Page information</a></li>
<li id="t-cite"><a href="/w/index.php?title=Special:Cite&amp;page=Algorithms%2FPrint_version&amp;id=2564849" title="Information on how to cite this page">Cite this page</a></li>		</ul>
	</div>
</div>
<div class="portal" role="navigation" id='p-lang' aria-labelledby='p-lang-label'>
	<h3 id='p-lang-label'>In other languages</h3>
	<div class="body">
		<ul>
			<li class="uls-p-lang-dummy"><a href="#"></a></li>
		</ul>
	</div>
</div>
<div class="portal" role="navigation" id='p-Sister_projects' aria-labelledby='p-Sister_projects-label'>
	<h3 id='p-Sister_projects-label'>Sister projects</h3>
	<div class="body">
		<ul>
			<li id="n-Wikipedia"><a href="//en.wikipedia.org/wiki/Main_Page">Wikipedia</a></li>
			<li id="n-Wikiversity"><a href="//en.wikiversity.org/wiki/Wikiversity:Main_Page">Wikiversity</a></li>
			<li id="n-Wiktionary"><a href="//en.wiktionary.org/wiki/Wiktionary:Main_Page">Wiktionary</a></li>
			<li id="n-Wikiquote"><a href="//en.wikiquote.org/wiki/Main_Page">Wikiquote</a></li>
			<li id="n-Wikisource"><a href="//en.wikisource.org/wiki/Main_Page">Wikisource</a></li>
			<li id="n-Wikinews"><a href="//en.wikinews.org/wiki/Main_Page">Wikinews</a></li>
			<li id="n-Wikivoyage"><a href="//en.wikivoyage.org/wiki/Main_Page">Wikivoyage</a></li>
			<li id="n-Commons"><a href="//commons.wikimedia.org/wiki/Main_Page">Commons</a></li>
			<li id="n-Wikidata"><a href="//www.wikidata.org/wiki/Wikidata:Main_Page">Wikidata</a></li>
		</ul>
	</div>
</div>
<div class="portal" role="navigation" id='p-coll-print_export' aria-labelledby='p-coll-print_export-label'>
	<h3 id='p-coll-print_export-label'>Print/export</h3>
	<div class="body">
		<ul>
			<li id="coll-create_a_book"><a href="/w/index.php?title=Special:Book&amp;bookcmd=book_creator&amp;referer=Algorithms%2FPrint+version">Create a collection</a></li>
			<li id="coll-download-as-rl"><a href="/w/index.php?title=Special:Book&amp;bookcmd=render_article&amp;arttitle=Algorithms%2FPrint+version&amp;oldid=2564849&amp;writer=rl">Download as PDF</a></li>
			<li id="t-print"><a href="/w/index.php?title=Algorithms/Print_version&amp;printable=yes" title="Printable version of this page [p]" accesskey="p">Printable version</a></li>
		</ul>
	</div>
</div>
			</div>
		</div>
		<div id="footer" role="contentinfo">
							<ul id="footer-info">
											<li id="footer-info-lastmod"> This page was last modified on 10 October 2013, at 12:35.</li>
											<li id="footer-info-copyright">Text is available under the <a href="//creativecommons.org/licenses/by-sa/3.0/">Creative Commons Attribution/Share-Alike License</a>; additional terms may apply.  By using this site, you agree to the <a href="//wikimediafoundation.org/wiki/Terms_of_Use">Terms of Use</a> and <a href="//wikimediafoundation.org/wiki/Privacy_policy">Privacy Policy.</a></li>
									</ul>
							<ul id="footer-places">
											<li id="footer-places-privacy"><a href="//wikimediafoundation.org/wiki/Privacy_policy" title="wikimedia:Privacy policy">Privacy policy</a></li>
											<li id="footer-places-about"><a href="/wiki/Wikibooks:Welcome" title="Wikibooks:Welcome">About Wikibooks</a></li>
											<li id="footer-places-disclaimer"><a href="/wiki/Wikibooks:General_disclaimer" title="Wikibooks:General disclaimer">Disclaimers</a></li>
											<li id="footer-places-developers"><a class="external" href="https://www.mediawiki.org/wiki/Special:MyLanguage/How_to_contribute">Developers</a></li>
											<li id="footer-places-mobileview"><a href="//en.m.wikibooks.org/wiki/Algorithms/Print_version" class="noprint stopMobileRedirectToggle">Mobile view</a></li>
									</ul>
										<ul id="footer-icons" class="noprint">
					<li id="footer-copyrightico">
						<a href="//wikimediafoundation.org/"><img src="//bits.wikimedia.org/images/wikimedia-button.png" width="88" height="31" alt="Wikimedia Foundation"/></a>
					</li>
					<li id="footer-poweredbyico">
						<a href="//www.mediawiki.org/"><img src="//bits.wikimedia.org/static-1.23wmf7/skins/common/images/poweredby_mediawiki_88x31.png" alt="Powered by MediaWiki" width="88" height="31" /></a>
					</li>
				</ul>
						<div style="clear:both"></div>
		</div>
		<script>/*<![CDATA[*/window.jQuery && jQuery.ready();/*]]>*/</script><script>if(window.mw){
mw.loader.state({"site":"loading","user":"ready","user.groups":"ready"});
}</script>
<script>if(window.mw){
mw.loader.load(["ext.cite","mediawiki.action.view.postEdit","mobile.desktop","mediawiki.user","mediawiki.hidpi","mediawiki.page.ready","mediawiki.searchSuggest","ext.gadget.extlinks","mw.MwEmbedSupport.style","ext.wikimediaEvents.moduleStorage","ext.navigationTiming","schema.UniversalLanguageSelector","ext.uls.eventlogger","mw.PopUpMediaTransform","ext.flaggedRevs.advanced","skins.vector.collapsibleNav"],null,true);
}</script>
<script src="/w/index.php?title=MediaWiki:Gadget-commons-file.js&amp;action=raw&amp;ctype=text/javascript&amp;2172780"></script>
<script src="/w/index.php?title=MediaWiki:Gadget-toolboxcompat.js&amp;action=raw&amp;ctype=text/javascript&amp;2161931"></script>
<script src="//bits.wikimedia.org/en.wikibooks.org/load.php?debug=false&amp;lang=en&amp;modules=site&amp;only=scripts&amp;skin=vector&amp;*"></script>
<!-- Served by mw1173 in 0.149 secs. -->
	</body>
</html>
